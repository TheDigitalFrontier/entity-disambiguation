{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congruence via Entity Vector Similarity\n",
    "\n",
    "In this notebook, we calculate the centroid distance measure between vectors of each entity candidate within a single sentence. The vectors will be retrieved from Wikipedia2vec's pre-trained API, which creates vectors for the entire Wikipedia page including its relational links. Comparing two vectors in this way thus lets us make a statement about similar pages and update our prior confidence based on that.\n",
    "\n",
    "#### (i) Via Centroid Distance\n",
    "\n",
    "In Phase 4, we calculate congruence between candidates in pools for mentions in the same sentence. Congruence is defined as the average candidate distance to the centroid vector of the candidate set. This lets us compare entire sets of candidates across all mentions at a time, instead of making pairwise comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity, pairwise_distances\n",
    "from itertools import product\n",
    "\n",
    "# Progress bar\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>full_mention</th>\n",
       "      <th>wikipedia_URL</th>\n",
       "      <th>wikipedia_page_ID</th>\n",
       "      <th>wikipedia_title</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>congruent_mentions</th>\n",
       "      <th>norm_full_mention</th>\n",
       "      <th>candidate_pool_page_ids</th>\n",
       "      <th>candidate_pool_item_ids</th>\n",
       "      <th>candidate_pool_titles</th>\n",
       "      <th>candidate_pool_priors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>EU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>eu</td>\n",
       "      <td>[9317, 9239, 21347120, 9477, 1882861]</td>\n",
       "      <td>[458, 46, 211593, 1396, 363404]</td>\n",
       "      <td>['European_Union', 'Europe', 'Eu,_Seine-Mariti...</td>\n",
       "      <td>[0.9227799, 0.024651, 0.020196, 0.005346, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>German</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Germany</td>\n",
       "      <td>11867.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>german</td>\n",
       "      <td>[11867, 11884, 152735, 21212, 12674]</td>\n",
       "      <td>[183, 188, 42884, 7318, 43287]</td>\n",
       "      <td>['Germany', 'German_language', 'Germans', 'Naz...</td>\n",
       "      <td>[0.4192066, 0.2893363, 0.1470461, 0.03832, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>British</td>\n",
       "      <td>http://en.wikipedia.org/wiki/United_Kingdom</td>\n",
       "      <td>31717.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>british</td>\n",
       "      <td>[31717, 19097669, 13530298, 4721, 158019]</td>\n",
       "      <td>[145, 842438, 23666, 8680, 161885]</td>\n",
       "      <td>['United_Kingdom', 'British_people', 'Great_Br...</td>\n",
       "      <td>[0.6101256, 0.1146913, 0.0681775, 0.0366451, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>Peter Blackburn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Peter Blackburn', 'BRUSSELS', 'European Comm...</td>\n",
       "      <td>peter blackburn</td>\n",
       "      <td>[56783206, 9643132, 56873217]</td>\n",
       "      <td>[2073954, 7172840, 26634508]</td>\n",
       "      <td>['Peter_Blackburn_(badminton)', 'Peter_Blackbu...</td>\n",
       "      <td>[0.5, 0.3, 0.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>Peter Blackburn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Peter Blackburn', 'BRUSSELS', 'European Comm...</td>\n",
       "      <td>peter blackburn</td>\n",
       "      <td>[56783206, 9643132, 56873217]</td>\n",
       "      <td>[2073954, 7172840, 26634508]</td>\n",
       "      <td>['Peter_Blackburn_(badminton)', 'Peter_Blackbu...</td>\n",
       "      <td>[0.5, 0.3, 0.2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mention     full_mention                                wikipedia_URL  \\\n",
       "0       B               EU                                          NaN   \n",
       "1       B           German         http://en.wikipedia.org/wiki/Germany   \n",
       "2       B          British  http://en.wikipedia.org/wiki/United_Kingdom   \n",
       "3       B  Peter Blackburn                                          NaN   \n",
       "4       I  Peter Blackburn                                          NaN   \n",
       "\n",
       "   wikipedia_page_ID wikipedia_title  sentence_id  doc_id  \\\n",
       "0                NaN             NaN            0       0   \n",
       "1            11867.0         Germany            0       0   \n",
       "2            31717.0  United Kingdom            0       0   \n",
       "3                NaN             NaN            1       0   \n",
       "4                NaN             NaN            1       0   \n",
       "\n",
       "                                  congruent_mentions norm_full_mention  \\\n",
       "0                        ['EU', 'German', 'British']                eu   \n",
       "1                        ['EU', 'German', 'British']            german   \n",
       "2                        ['EU', 'German', 'British']           british   \n",
       "3  ['Peter Blackburn', 'BRUSSELS', 'European Comm...   peter blackburn   \n",
       "4  ['Peter Blackburn', 'BRUSSELS', 'European Comm...   peter blackburn   \n",
       "\n",
       "                     candidate_pool_page_ids  \\\n",
       "0      [9317, 9239, 21347120, 9477, 1882861]   \n",
       "1       [11867, 11884, 152735, 21212, 12674]   \n",
       "2  [31717, 19097669, 13530298, 4721, 158019]   \n",
       "3              [56783206, 9643132, 56873217]   \n",
       "4              [56783206, 9643132, 56873217]   \n",
       "\n",
       "              candidate_pool_item_ids  \\\n",
       "0     [458, 46, 211593, 1396, 363404]   \n",
       "1      [183, 188, 42884, 7318, 43287]   \n",
       "2  [145, 842438, 23666, 8680, 161885]   \n",
       "3        [2073954, 7172840, 26634508]   \n",
       "4        [2073954, 7172840, 26634508]   \n",
       "\n",
       "                               candidate_pool_titles  \\\n",
       "0  ['European_Union', 'Europe', 'Eu,_Seine-Mariti...   \n",
       "1  ['Germany', 'German_language', 'Germans', 'Naz...   \n",
       "2  ['United_Kingdom', 'British_people', 'Great_Br...   \n",
       "3  ['Peter_Blackburn_(badminton)', 'Peter_Blackbu...   \n",
       "4  ['Peter_Blackburn_(badminton)', 'Peter_Blackbu...   \n",
       "\n",
       "                               candidate_pool_priors  \n",
       "0  [0.9227799, 0.024651, 0.020196, 0.005346, 0.00...  \n",
       "1  [0.4192066, 0.2893363, 0.1470461, 0.03832, 0.0...  \n",
       "2  [0.6101256, 0.1146913, 0.0681775, 0.0366451, 0...  \n",
       "3                                    [0.5, 0.3, 0.2]  \n",
       "4                                    [0.5, 0.3, 0.2]  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base path to input\n",
    "preds_path = '../../predictions/'\n",
    "\n",
    "# Load data\n",
    "full_mentions = pd.read_csv(os.path.join(preds_path, \"anchortext_frequency_5x5.csv\"), delimiter=\",\")\n",
    "full_mentions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mentions:  13781 , Sentences:  3935\n"
     ]
    }
   ],
   "source": [
    "print(\"Mentions: \", len(full_mentions), \", Sentences: \", len(full_mentions['sentence_id'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Saved Candidate Pool\n",
    "\n",
    "Candidate pools when exported to csv are stored as the string of the list. The below function parses the string back into a list with proper formatted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demonstrate that list is string\n",
    "type(full_mentions['candidate_pool_page_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse list as string\n",
    "def parse_list_string(list_string, value_type=int):\n",
    "    \n",
    "    parsed_list = []\n",
    "    \n",
    "    # If candidate pool is empty\n",
    "    if list_string == \"[]\" or isinstance(list_string, float):\n",
    "        pass\n",
    "    # Else parse\n",
    "    else:\n",
    "        # Parses lists of titles as strings\n",
    "        if value_type==str:\n",
    "            # Eliminate bracket and parenthesis on either side, split by comma pattern\n",
    "            parsed_list = re.split(\"', '|\\\", \\\"|', \\\"|\\\", \\'\", list_string[2:-2])\n",
    "\n",
    "        # Parses lists of IDs as ints\n",
    "        elif value_type==int:\n",
    "            # Eliminate brackets and convert each number from string to int\n",
    "            parsed_list = list(map(int, list_string[1:-1].split(', ')))\n",
    "        elif value_type==float:\n",
    "            # Eliminate brackets and convert each number from string to int\n",
    "            parsed_list = list(map(float, list_string[1:-1].split(', ')))\n",
    "            \n",
    "        \n",
    "    return parsed_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['European_Union',\n",
       " 'Europe',\n",
       " 'Eu,_Seine-Maritime',\n",
       " 'Europium',\n",
       " 'Citizenship_of_the_European_Union']"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually test function\n",
    "# 0 is the hard one. See how some value is stored with '' and some with \"\". Unsure why.\n",
    "parse_list_string(full_mentions['candidate_pool_titles'][0], value_type=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9317, 9239, 21347120, 9477, 1882861]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually test function\n",
    "# 0 is the hard one. See how some value is stored with '' and some with \"\". Unsure why.\n",
    "parse_list_string(full_mentions['candidate_pool_page_ids'][0], value_type=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually test function\n",
    "parse_list_string(full_mentions['candidate_pool_page_ids'][13], value_type=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9227799, 0.024651, 0.020196, 0.005346, 0.002079]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually test function\n",
    "parse_list_string(full_mentions['candidate_pool_priors'][0], value_type=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ['Peter Blackburn', 'BRUSSELS', 'European Commission', 'German', 'British']\n",
      "After ['Peter Blackburn', 'BRUSSELS', 'European Commission', 'German', 'British']\n",
      "Before [56783206, 9643132, 56873217]\n",
      "After [56783206, 9643132, 56873217]\n",
      "Before [2073954, 7172840, 26634508]\n",
      "After [2073954, 7172840, 26634508]\n",
      "Before ['Peter_Blackburn_(badminton)', 'Peter_Blackburn_(bishop)', 'Peter_Blackburn_(MP)']\n",
      "After ['Peter_Blackburn_(badminton)', 'Peter_Blackburn_(bishop)', 'Peter_Blackburn_(MP)']\n",
      "Before [0.5, 0.3, 0.2]\n",
      "After [0.5, 0.3, 0.2]\n",
      "CPU times: user 214 ms, sys: 14.2 ms, total: 228 ms\n",
      "Wall time: 228 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "### Apply defined function to entire dataframe for all candidate pool columns\n",
    "\n",
    "column = 'congruent_mentions'\n",
    "print(\"Before\", full_mentions[column][3])\n",
    "parsed_candidate_pool = full_mentions[column].apply(parse_list_string, value_type=str)\n",
    "full_mentions[column] = parsed_candidate_pool\n",
    "print(\"After\", full_mentions[column][3])\n",
    "\n",
    "column = 'candidate_pool_page_ids'\n",
    "print(\"Before\", full_mentions[column][3])\n",
    "parsed_candidate_pool = full_mentions[column].apply(parse_list_string, value_type=int)\n",
    "full_mentions[column] = parsed_candidate_pool\n",
    "print(\"After\", full_mentions[column][3])\n",
    "\n",
    "\n",
    "column = 'candidate_pool_item_ids'\n",
    "print(\"Before\", full_mentions[column][3])\n",
    "parsed_candidate_pool = full_mentions[column].apply(parse_list_string, value_type=int)\n",
    "full_mentions[column] = parsed_candidate_pool\n",
    "print(\"After\", full_mentions[column][3])\n",
    "\n",
    "\n",
    "column = 'candidate_pool_titles'\n",
    "print(\"Before\", full_mentions[column][3])\n",
    "parsed_candidate_pool = full_mentions[column].apply(parse_list_string, value_type=str)\n",
    "full_mentions[column] = parsed_candidate_pool\n",
    "print(\"After\", full_mentions[column][3])\n",
    "\n",
    "column = 'candidate_pool_priors'\n",
    "print(\"Before\", full_mentions[column][3])\n",
    "parsed_candidate_pool = full_mentions[column].apply(parse_list_string, value_type=float)\n",
    "full_mentions[column] = parsed_candidate_pool\n",
    "print(\"After\", full_mentions[column][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Entity Vectors from Wikipedia2Vec\n",
    "\n",
    "For provided wikipedia pages, we retrieve a representative entity vector from Wikipedia2vec. This involves passing the normalized title into their get_entity_vector() function. We default to using 100d pre-trained embeddings due to the easier computational requirements, but tested results using higher dimensions as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package\n",
    "from wikipedia2vec import Wikipedia2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 99.3 ms, sys: 123 ms, total: 222 ms\n",
      "Wall time: 270 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load unzipped pkl file with word embeddings\n",
    "w2v = Wikipedia2Vec.load(\"../../embeddings/enwiki_20180420_100d.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess Coverage of Candidate Pools in Wikipedia2vec\n",
    "\n",
    "We need to measure what percent of candidates in our candidate pools successfully return a vector from Wikipedia2vec. This should conceivably be 100% given we're passing known Wikipedia pages into this package trained over Wikipedia pages, but there may be some drop-off due to different creation dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define text normalization function\n",
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    We define normalized in this notebook as:\n",
    "    - strip whitespace\n",
    "    - Spaces, not underlines\n",
    "    \"\"\"\n",
    "    return str(text).strip().replace(\"_\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13781/13781 [00:00<00:00, 15782.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia2vec returned an entity vector for 94.792% of 42,453 searches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over candidate pool titles to see what can be returned\n",
    "\n",
    "found_entity = 0\n",
    "searched_entity = 0\n",
    "\n",
    "for i in tqdm(range(len(full_mentions))):\n",
    "    \n",
    "    # Retrieve candidate pool\n",
    "    candidate_pool = full_mentions['candidate_pool_titles'][i]\n",
    "    \n",
    "    # Query for each candidate\n",
    "    for candidate in candidate_pool:\n",
    "        # Normalize candidate title to form necessary to input into Wikipedia2vec\n",
    "        candidate = normalize_text(candidate)\n",
    "        \n",
    "        # Query Wikipedia2vec get_entity_vector()\n",
    "        try:\n",
    "            entity_vector = w2v.get_entity_vector(candidate)\n",
    "        except KeyError:\n",
    "            entity_vector = None\n",
    "        \n",
    "        # Check if result\n",
    "        if entity_vector is not None:\n",
    "            found_entity += 1\n",
    "        \n",
    "        # Increment count\n",
    "        searched_entity += 1\n",
    "\n",
    "print(f\"Wikipedia2vec returned an entity vector for {round(found_entity/searched_entity*100,3)}% of {searched_entity:,} searches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand Sentence Properties\n",
    "\n",
    "First, let's get a sense for what the upper bound of congruent calculations might be per sentence as well as the distribution of counts and average priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the maximum number of congruent entities in a single sentence\n",
    "max(full_mentions['congruent_mentions'].apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What is the distribution of congruent mention counts\n",
    "plt.figure(figsize=(20,5))\n",
    "full_mentions['congruent_mentions'].apply(len).hist(bins=50)\n",
    "plt.title(\"distribution of congruent mention counts\", size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's get a sense for the average ranking of the right answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13781/13781 [00:01<00:00, 7223.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answer not present in candidate pool 6.9% of the time.\n",
      "Correct answer null 29.0% of the time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare tracking metrics\n",
    "correct_answer_rank = []\n",
    "correct_answer_prior = {0:[],1:[],2:[],3:[],4:[]}\n",
    "correct_answer_not_present = 0\n",
    "correct_answer_null = 0\n",
    "\n",
    "# Iterate over whole dataframe\n",
    "for i in tqdm(range(len(full_mentions))):\n",
    "    row = full_mentions.iloc[i]\n",
    "    correct_answer = row['wikipedia_page_ID']\n",
    "    if isinstance(row['wikipedia_title'], float):\n",
    "        correct_answer_null += 1\n",
    "    else:\n",
    "        try:\n",
    "            correct_rank = row['candidate_pool_page_ids'].index(correct_answer)\n",
    "            correct_answer_rank.append(correct_rank)\n",
    "            correct_answer_prior[correct_rank].append(row['candidate_pool_priors'][correct_rank])\n",
    "        except ValueError:\n",
    "            correct_answer_not_present += 1\n",
    "\n",
    "print(f\"Correct answer not present in candidate pool {round(correct_answer_not_present/len(full_mentions)*100,1)}% of the time.\")\n",
    "print(f\"Correct answer null {round(correct_answer_null/len(full_mentions)*100,1)}% of the time.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot rank\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.hist(correct_answer_rank, bins=20)\n",
    "plt.title(\"Ordering of Correct Answer Candidate Rank\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7008\n",
       "1    1193\n",
       "2     357\n",
       "3     207\n",
       "4      68\n",
       "dtype: int64"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Provide rank numbers\n",
    "pd.Series(correct_answer_rank).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Candidate Rank: 0 - Average Prior Confidence: 0.88239 - Median Prior Confidence: 0.95273\n",
      "Correct Candidate Rank: 1 - Average Prior Confidence: 0.17663 - Median Prior Confidence: 0.15083\n",
      "Correct Candidate Rank: 2 - Average Prior Confidence: 0.07626 - Median Prior Confidence: 0.07267\n",
      "Correct Candidate Rank: 3 - Average Prior Confidence: 0.04184 - Median Prior Confidence: 0.04132\n",
      "Correct Candidate Rank: 4 - Average Prior Confidence: 0.02394 - Median Prior Confidence: 0.01005\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean prior confidence for each rank\n",
    "for k,v in correct_answer_prior.items():\n",
    "    print(f\"Correct Candidate Rank: {k} - Average Prior Confidence: {round(np.mean(v),5)} - Median Prior Confidence: {round(np.median(v),5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When limited to sentences with 5 congruent mentions or less, 79.3% are in First Place and 13.5% are in Second, totaling 92.8% in our top two positions. Our first place candidates have median prior confidence of 0.95, but mean confidence of 0.99, suggesting that for most mentions we are highly confident in its first option, but a few are much lower and more uncertain, bringing the mean down (like a 50/50 estimate). Conversely, in second place, median is 0.15 but mean is 0.17, further suggesting those 50/50 estimates for some mentions bringing the mean up.\n",
    "\n",
    "Our hope is that congruence will be able to clarify those more evenly split prior values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Congruence Metric between Congruent Entities\n",
    "\n",
    "We need to iterate through every mention's every candidate to develop the total of all sets in entity vector form. From there, we can iterate through sets to A) create the centroid vector and B) calculate each candidate distance to the centroid. With each candidate distance, we can average into a single distance congruence measure.\n",
    "\n",
    "We do this through a series of defined functions immediately below. For a more step-by-step logical flow that might aid with understanding, please see the end of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions to Create Modular Congruent Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate candidate lists of vectors\n",
    "def get_candidate_pool_vectors(candidate_pool_titles, verbose=False):\n",
    "    \"\"\"\n",
    "    Function to return entity vectors from Wikipedia2Vec\n",
    "    Takes as input a list of page titles, representing the candidate pool\n",
    "    Normalizes each page title to match necessary input format\n",
    "    Returns entity vector or empty vector if no match\n",
    "    \"\"\"\n",
    "    # Track failed vector queries\n",
    "    no_vector_count = 0\n",
    "    candidate_pool_vectors = []\n",
    "    for candidate in candidate_pool_titles:\n",
    "        candidate = normalize_text(candidate)\n",
    "        if verbose: print(candidate)\n",
    "        try:\n",
    "            candidate_vectors = w2v.get_entity_vector(candidate)\n",
    "        except KeyError:\n",
    "            # Keep empty vector representation to maintain index locations\n",
    "            candidate_vectors = np.zeros(100)\n",
    "            no_vector_count += 1\n",
    "        candidate_pool_vectors.append(candidate_vectors)\n",
    "    \n",
    "    # Handle case where candidate pool is empty from Phase 3\n",
    "    # Add arbitrarily chosen 3 arrays of zeros\n",
    "    if len(candidate_pool_titles) == 0:\n",
    "        candidate_pool_vectors = [np.zeros(100), np.zeros(100), np.zeros(100)]\n",
    "    \n",
    "    if verbose: print(f\"Failed Wikipedia2Vec Entity Vector Queries: {no_vector_count}\")\n",
    "    return candidate_pool_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to retrieve entity vectors\n",
    "def create_entity_vector_dict(sentence_mention_ids, single_sentence_df, verbose=False):\n",
    "    \"\"\"\n",
    "    Function iterates over a provided list of congruent mentions,\n",
    "    finds the associated candidate pool for each mention\n",
    "    and returns the candidate pool in vector representation\n",
    "    \"\"\"\n",
    "    # Save vectors in dictionary\n",
    "    vector_dict = {}\n",
    "    \n",
    "    # For each full mention we are analyzing in the contextual domain\n",
    "    for m in sentence_mention_ids:\n",
    "        \n",
    "        # Retrieve candidate pool titles\n",
    "        candidate_pool_titles = single_sentence_df['candidate_pool_titles'][m]\n",
    "        if verbose: print(candidate_pool_titles)\n",
    "        \n",
    "        # Convert candidate pool titles to candidate pool vectors\n",
    "        candidate_pool_vectors = get_candidate_pool_vectors(candidate_pool_titles, verbose=verbose)\n",
    "        \n",
    "        # Save candidate pool vectors to dictionary\n",
    "        vector_dict[m] = candidate_pool_vectors\n",
    "    \n",
    "    if verbose:\n",
    "        print(vector_dict.keys())\n",
    "        for k in vector_dict.keys():\n",
    "            print(len(vector_dict[k]))\n",
    "\n",
    "    return vector_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to create every set of candidates across all mentions\n",
    "def create_candidate_combos(vector_dict, verbose=False):\n",
    "    \"\"\"\n",
    "    Function takes as input vector_dict, which represents candidate pool vectors for each mention\n",
    "    Iterates through all candidate vectors to create as product the single list of all combinations of candidates\n",
    "    Returns that list\n",
    "    \"\"\"\n",
    "    # Prepare list for combination\n",
    "    candidate_counts = [range(len(v)) for v in vector_dict.values()]\n",
    "    if verbose: print(candidate_counts)\n",
    "    \n",
    "    # Create product combination of all candidates\n",
    "    unique_combinations = list(product(*candidate_counts))\n",
    "    \n",
    "    return unique_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate centroids\n",
    "def calculate_centroid_combo_dist(unique_combinations, vector_dict, verbose=False): #todo rename?\n",
    "    \"\"\"\n",
    "    Function takes a list of all possible unique combinations of candidates in vector form,\n",
    "    - Calculates the centroid of the vectors of that combination,\n",
    "    - Calculates the distance of each candidate to the centroid\n",
    "    - Calculates the mean distance for that combination\n",
    "    Returns a list of mean distance for each candidate combination to its centroid\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare list for each combination's mean distance\n",
    "    combination_distance = []\n",
    "    \n",
    "    # For every unique combination of candidates\n",
    "    for combo in unique_combinations:\n",
    "        \n",
    "        # Translate combination from idx values to vectors\n",
    "        combo_vector = []\n",
    "        for i in range(len(combo)):\n",
    "            combo_vector.append(vector_dict[i][combo[i]]) # Retrieve the vector representation\n",
    "\n",
    "        # Calculate centroid\n",
    "        centroid = sum(combo_vector)/len(combo)\n",
    "                \n",
    "        # Calculate distance from each candidate to its combination centroid\n",
    "        candidate_distances = []\n",
    "        for candidate in combo_vector:\n",
    "#             candidate_dist = cosine_similarity(candidate.reshape(-1,1), centroid.reshape(-1,1))\n",
    "            candidate_dist = pairwise_distances(candidate.reshape(-1,1), centroid.reshape(-1,1), metric='euclidean')\n",
    "            candidate_distances.append(candidate_dist)\n",
    "        \n",
    "        # Saves mean candidate/centroid distance to list\n",
    "        combination_distance.append(np.mean(candidate_distances))\n",
    "        \n",
    "    return combination_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate average prior confidence for a combination\n",
    "def calculate_combo_prior(unique_combinations, single_sentence_df, verbose=False):\n",
    "    \"\"\"\n",
    "    Function takes as input the list of all possible unique combinations,\n",
    "    Calculates the average prior confidence for candidates in that combination,\n",
    "    Returns the list of average prior confidence for every combination\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare list of average combination prior confidence\n",
    "    combination_avg_prior = []\n",
    "    \n",
    "    # For every unique combination of candidates\n",
    "    for combo in unique_combinations:\n",
    "        \n",
    "        # Prepare combination priors\n",
    "        combination_priors = []\n",
    "        \n",
    "        # Retrieve prior confidence using idx\n",
    "        for i in range(len(combo)):\n",
    "            mention = single_sentence_df.iloc[i]\n",
    "            try:\n",
    "                prior = mention['candidate_pool_priors'][combo[i]]\n",
    "            except IndexError: # Catches error when candidate pool is empty\n",
    "                prior = 0 # Set to 0 to bring distance of None vector to centroid to 0\n",
    "            combination_priors.append(prior)\n",
    "        \n",
    "        # Save mean prior\n",
    "        combination_avg_prior.append(np.mean(combination_priors))\n",
    "\n",
    "    return combination_avg_prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congruent Predictions Function\n",
    "\n",
    "This is our main function that takes a sentence ID, calculates congruence for all candidates, updates the prior confidence from Phase 3 with that congruence and selects predictions iteratively based on that final number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate congruent predictions\n",
    "def get_congruent_predictions(sentence_id, dataframe, with_priors=True, verbose=False):\n",
    "    \"\"\"\n",
    "    Function to calculate congruence metrics over a set of entity full mentions\n",
    "    and return the predicted candidates based on the congruent metric\n",
    "    Input:\n",
    "    - Sentence ID used to filter dataframe\n",
    "    - Dataframe over which to process\n",
    "    Output:\n",
    "    - Prediction for each entity mention\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter to dataframe representing single sentence\n",
    "    # Drop duplicates necessary for sentences with the same mention included twice\n",
    "    single_sentence_df = dataframe[dataframe['sentence_id'] == sentence_id]\\\n",
    "                        .drop_duplicates(['full_mention', 'wikipedia_URL', 'wikipedia_page_ID', 'wikipedia_title'])\\\n",
    "                        .reset_index(drop=True)\n",
    "    if verbose: display(single_sentence_df)\n",
    "    \n",
    "    # Define numerical representation of congruent mention list\n",
    "    sentence_congruent_mentions = single_sentence_df['congruent_mentions'][0]\n",
    "    sentence_mention_ids = np.arange(len(sentence_congruent_mentions))\n",
    "    if verbose:\n",
    "        print(\"Congruent Mentions: \", sentence_congruent_mentions)\n",
    "        print(\"Congruent Mentions as numbers: \", sentence_mention_ids)\n",
    "    \n",
    "    # Retrieve dictionary of candidate pool vectors for each mention\n",
    "    vectors_dict = create_entity_vector_dict(sentence_mention_ids, single_sentence_df, verbose=verbose)\n",
    "    if verbose: print(\"Mentions with Vectors: \", vectors_dict.keys())\n",
    "        \n",
    "    # Create full list of all unique combinations\n",
    "    unique_combinations = create_candidate_combos(vectors_dict, verbose=verbose)\n",
    "    # todo standardize on vector or vectors\n",
    "\n",
    "    # Calculate average candidate distance to that combination's centroid for comparison\n",
    "    combination_distance = calculate_centroid_combo_dist(unique_combinations, vectors_dict, verbose=verbose)\n",
    "    \n",
    "    # Add flag for including priors\n",
    "    if with_priors:\n",
    "        \n",
    "        # Calculate average prior confidence for each combination\n",
    "        combination_avg_prior = calculate_combo_prior(unique_combinations, single_sentence_df, verbose=False)\n",
    "    \n",
    "        # Combine congruence distance with prior confidence\n",
    "        assert len(combination_distance) == len(combination_avg_prior)\n",
    "        combination_congruence = np.array(combination_distance) * np.array(combination_avg_prior)\n",
    "\n",
    "    else:\n",
    "        combination_congruence = combination_distance\n",
    "        \n",
    "    # Select combination with smallest distance metric, i.e. most congruent combination\n",
    "    select_idx = np.argmax(combination_congruence)\n",
    "    most_congruent_combination = unique_combinations[select_idx]\n",
    "    if verbose: print(\"Most Congruent Combination: \", most_congruent_combination)\n",
    "    \n",
    "    # Create predictions dictionary\n",
    "    mention_predictions = {}\n",
    "    \n",
    "    # Translate combination list into dictionary\n",
    "    for i in range(len(most_congruent_combination)):\n",
    "        mention_predictions[i] = most_congruent_combination[i]\n",
    "    if verbose: print(\"Numerical Predictions: \", mention_predictions)\n",
    "    \n",
    "    # Use mention predictions to return titles\n",
    "    readable_predictions = {}\n",
    "    for k, v in mention_predictions.items():\n",
    "        if verbose: print(k, v)\n",
    "        readable_key = sentence_congruent_mentions[k]\n",
    "        try:\n",
    "            readable_value = single_sentence_df['candidate_pool_titles'][k][v]\n",
    "            readable_id = single_sentence_df['candidate_pool_page_ids'][k][v]\n",
    "        except IndexError: # Handles case where no candidate pool was provided from Phase 3\n",
    "            readable_value = None \n",
    "            readable_id = None\n",
    "        except TypeError:\n",
    "            # Handles case where no congruence can be calculated\n",
    "            # Either due to one mention in sentence or two mentions but one with no candidate pool\n",
    "            readable_value = single_sentence_df['candidate_pool_titles'][0][0] # Just return top value from Phase 3\n",
    "            readable_id = single_sentence_df['candidate_pool_page_ids'][0][0]\n",
    "        if verbose: print(readable_key, readable_value, readable_id)\n",
    "        readable_predictions[readable_key] = (readable_value, readable_id)\n",
    "    \n",
    "    # Output dictionary with predictions for each entity mention based on congruence\n",
    "    return readable_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>full_mention</th>\n",
       "      <th>wikipedia_URL</th>\n",
       "      <th>wikipedia_page_ID</th>\n",
       "      <th>wikipedia_title</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>congruent_mentions</th>\n",
       "      <th>norm_full_mention</th>\n",
       "      <th>candidate_pool_page_ids</th>\n",
       "      <th>candidate_pool_item_ids</th>\n",
       "      <th>candidate_pool_titles</th>\n",
       "      <th>candidate_pool_priors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>EU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[EU, German, British]</td>\n",
       "      <td>eu</td>\n",
       "      <td>[9317, 9239, 21347120, 9477, 1882861]</td>\n",
       "      <td>[458, 46, 211593, 1396, 363404]</td>\n",
       "      <td>[European_Union, Europe, Eu,_Seine-Maritime, E...</td>\n",
       "      <td>[0.9227799, 0.024651, 0.020196, 0.005346, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>German</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Germany</td>\n",
       "      <td>11867.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[EU, German, British]</td>\n",
       "      <td>german</td>\n",
       "      <td>[11867, 11884, 152735, 21212, 12674]</td>\n",
       "      <td>[183, 188, 42884, 7318, 43287]</td>\n",
       "      <td>[Germany, German_language, Germans, Nazi_Germa...</td>\n",
       "      <td>[0.4192066, 0.2893363, 0.1470461, 0.03832, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>British</td>\n",
       "      <td>http://en.wikipedia.org/wiki/United_Kingdom</td>\n",
       "      <td>31717.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[EU, German, British]</td>\n",
       "      <td>british</td>\n",
       "      <td>[31717, 19097669, 13530298, 4721, 158019]</td>\n",
       "      <td>[145, 842438, 23666, 8680, 161885]</td>\n",
       "      <td>[United_Kingdom, British_people, Great_Britain...</td>\n",
       "      <td>[0.6101256, 0.1146913, 0.0681775, 0.0366451, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mention full_mention                                wikipedia_URL  \\\n",
       "0       B           EU                                          NaN   \n",
       "1       B       German         http://en.wikipedia.org/wiki/Germany   \n",
       "2       B      British  http://en.wikipedia.org/wiki/United_Kingdom   \n",
       "\n",
       "   wikipedia_page_ID wikipedia_title  sentence_id  doc_id  \\\n",
       "0                NaN             NaN            0       0   \n",
       "1            11867.0         Germany            0       0   \n",
       "2            31717.0  United Kingdom            0       0   \n",
       "\n",
       "      congruent_mentions norm_full_mention  \\\n",
       "0  [EU, German, British]                eu   \n",
       "1  [EU, German, British]            german   \n",
       "2  [EU, German, British]           british   \n",
       "\n",
       "                     candidate_pool_page_ids  \\\n",
       "0      [9317, 9239, 21347120, 9477, 1882861]   \n",
       "1       [11867, 11884, 152735, 21212, 12674]   \n",
       "2  [31717, 19097669, 13530298, 4721, 158019]   \n",
       "\n",
       "              candidate_pool_item_ids  \\\n",
       "0     [458, 46, 211593, 1396, 363404]   \n",
       "1      [183, 188, 42884, 7318, 43287]   \n",
       "2  [145, 842438, 23666, 8680, 161885]   \n",
       "\n",
       "                               candidate_pool_titles  \\\n",
       "0  [European_Union, Europe, Eu,_Seine-Maritime, E...   \n",
       "1  [Germany, German_language, Germans, Nazi_Germa...   \n",
       "2  [United_Kingdom, British_people, Great_Britain...   \n",
       "\n",
       "                               candidate_pool_priors  \n",
       "0  [0.9227799, 0.024651, 0.020196, 0.005346, 0.00...  \n",
       "1  [0.4192066, 0.2893363, 0.1470461, 0.03832, 0.0...  \n",
       "2  [0.6101256, 0.1146913, 0.0681775, 0.0366451, 0...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congruent Mentions:  ['EU', 'German', 'British']\n",
      "Congruent Mentions as numbers:  [0 1 2]\n",
      "['European_Union', 'Europe', 'Eu,_Seine-Maritime', 'Europium', 'Citizenship_of_the_European_Union']\n",
      "European Union\n",
      "Europe\n",
      "Eu, Seine-Maritime\n",
      "Europium\n",
      "Citizenship of the European Union\n",
      "Failed Wikipedia2Vec Entity Vector Queries: 0\n",
      "['Germany', 'German_language', 'Germans', 'Nazi_Germany', 'German_Empire']\n",
      "Germany\n",
      "German language\n",
      "Germans\n",
      "Nazi Germany\n",
      "German Empire\n",
      "Failed Wikipedia2Vec Entity Vector Queries: 0\n",
      "['United_Kingdom', 'British_people', 'Great_Britain', 'British_Empire', 'Kingdom_of_Great_Britain']\n",
      "United Kingdom\n",
      "British people\n",
      "Great Britain\n",
      "British Empire\n",
      "Kingdom of Great Britain\n",
      "Failed Wikipedia2Vec Entity Vector Queries: 0\n",
      "dict_keys([0, 1, 2])\n",
      "5\n",
      "5\n",
      "5\n",
      "Mentions with Vectors:  dict_keys([0, 1, 2])\n",
      "[range(0, 5), range(0, 5), range(0, 5)]\n",
      "Most Congruent Combination:  (0, 1, 0)\n",
      "Numerical Predictions:  {0: 0, 1: 1, 2: 0}\n",
      "0 0\n",
      "EU European_Union 9317\n",
      "1 1\n",
      "German German_language 11884\n",
      "2 0\n",
      "British United_Kingdom 31717\n",
      "{'EU': ('European_Union', 9317), 'German': ('German_language', 11884), 'British': ('United_Kingdom', 31717)}\n",
      "CPU times: user 188 ms, sys: 6.06 ms, total: 194 ms\n",
      "Wall time: 194 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Test out function\n",
    "sentence_id = 0\n",
    "congruent_predictions = get_congruent_predictions(sentence_id=sentence_id, dataframe=full_mentions, with_priors=True, verbose=True)\n",
    "print(congruent_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>full_mention</th>\n",
       "      <th>wikipedia_URL</th>\n",
       "      <th>wikipedia_page_ID</th>\n",
       "      <th>wikipedia_title</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>congruent_mentions</th>\n",
       "      <th>norm_full_mention</th>\n",
       "      <th>candidate_pool_page_ids</th>\n",
       "      <th>candidate_pool_item_ids</th>\n",
       "      <th>candidate_pool_titles</th>\n",
       "      <th>candidate_pool_priors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>EU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[EU, German, British]</td>\n",
       "      <td>eu</td>\n",
       "      <td>[9317, 9239, 21347120, 9477, 1882861]</td>\n",
       "      <td>[458, 46, 211593, 1396, 363404]</td>\n",
       "      <td>[European_Union, Europe, Eu,_Seine-Maritime, E...</td>\n",
       "      <td>[0.9227799, 0.024651, 0.020196, 0.005346, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>German</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Germany</td>\n",
       "      <td>11867.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[EU, German, British]</td>\n",
       "      <td>german</td>\n",
       "      <td>[11867, 11884, 152735, 21212, 12674]</td>\n",
       "      <td>[183, 188, 42884, 7318, 43287]</td>\n",
       "      <td>[Germany, German_language, Germans, Nazi_Germa...</td>\n",
       "      <td>[0.4192066, 0.2893363, 0.1470461, 0.03832, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>British</td>\n",
       "      <td>http://en.wikipedia.org/wiki/United_Kingdom</td>\n",
       "      <td>31717.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[EU, German, British]</td>\n",
       "      <td>british</td>\n",
       "      <td>[31717, 19097669, 13530298, 4721, 158019]</td>\n",
       "      <td>[145, 842438, 23666, 8680, 161885]</td>\n",
       "      <td>[United_Kingdom, British_people, Great_Britain...</td>\n",
       "      <td>[0.6101256, 0.1146913, 0.0681775, 0.0366451, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mention full_mention                                wikipedia_URL  \\\n",
       "0       B           EU                                          NaN   \n",
       "1       B       German         http://en.wikipedia.org/wiki/Germany   \n",
       "2       B      British  http://en.wikipedia.org/wiki/United_Kingdom   \n",
       "\n",
       "   wikipedia_page_ID wikipedia_title  sentence_id  doc_id  \\\n",
       "0                NaN             NaN            0       0   \n",
       "1            11867.0         Germany            0       0   \n",
       "2            31717.0  United Kingdom            0       0   \n",
       "\n",
       "      congruent_mentions norm_full_mention  \\\n",
       "0  [EU, German, British]                eu   \n",
       "1  [EU, German, British]            german   \n",
       "2  [EU, German, British]           british   \n",
       "\n",
       "                     candidate_pool_page_ids  \\\n",
       "0      [9317, 9239, 21347120, 9477, 1882861]   \n",
       "1       [11867, 11884, 152735, 21212, 12674]   \n",
       "2  [31717, 19097669, 13530298, 4721, 158019]   \n",
       "\n",
       "              candidate_pool_item_ids  \\\n",
       "0     [458, 46, 211593, 1396, 363404]   \n",
       "1      [183, 188, 42884, 7318, 43287]   \n",
       "2  [145, 842438, 23666, 8680, 161885]   \n",
       "\n",
       "                               candidate_pool_titles  \\\n",
       "0  [European_Union, Europe, Eu,_Seine-Maritime, E...   \n",
       "1  [Germany, German_language, Germans, Nazi_Germa...   \n",
       "2  [United_Kingdom, British_people, Great_Britain...   \n",
       "\n",
       "                               candidate_pool_priors  \n",
       "0  [0.9227799, 0.024651, 0.020196, 0.005346, 0.00...  \n",
       "1  [0.4192066, 0.2893363, 0.1470461, 0.03832, 0.0...  \n",
       "2  [0.6101256, 0.1146913, 0.0681775, 0.0366451, 0...  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define testing sentence_id\n",
    "single_sentence_df = full_mentions[full_mentions['sentence_id'] == sentence_id].reset_index(drop=True)\n",
    "single_sentence_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EU', 'German', 'British']\n"
     ]
    }
   ],
   "source": [
    "print(single_sentence_df['congruent_mentions'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU -> nan =? European Union\n",
      "German -> Germany =? German language\n",
      "British -> United Kingdom =? United Kingdom\n",
      "*************************************************\n",
      "This congruent experiment is 33.333% accurate comparing page titles.\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for mention, pred in congruent_predictions.items():\n",
    "    pred_title = normalize_text(pred[0])\n",
    "    true_title = single_sentence_df[single_sentence_df['full_mention'] == mention]['wikipedia_title'].values[0]\n",
    "    print(mention, \"->\", true_title, \"=?\", pred_title)\n",
    "    if single_sentence_df[single_sentence_df['full_mention'] == mention]['wikipedia_title'].values[0] == pred_title:\n",
    "        accuracy += 1\n",
    "print(\"*************************************************\")\n",
    "print(f\"This congruent experiment is {round(accuracy/len(congruent_predictions)*100,3)}% accurate comparing page titles.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU -> None =? 9317\n",
      "German -> 11867 =? 11884\n",
      "British -> 31717 =? 31717\n",
      "*************************************************\n",
      "This congruent experiment is 33.333% accurate comparing page IDs.\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for mention, pred in congruent_predictions.items():\n",
    "    pred_page_id = pred[1]\n",
    "    try:\n",
    "        true_page_id = int(single_sentence_df[single_sentence_df['full_mention'] == mention]['wikipedia_page_ID'].values[0])\n",
    "    except ValueError:\n",
    "        true_page_id = None\n",
    "    print(mention, \"->\", true_page_id, \"=?\", pred_page_id)\n",
    "    if single_sentence_df[single_sentence_df['full_mention'] == mention]['wikipedia_page_ID'].values[0] == pred_page_id:\n",
    "        accuracy += 1\n",
    "print(\"*************************************************\")\n",
    "print(f\"This congruent experiment is {round(accuracy/len(congruent_predictions)*100,3)}% accurate comparing page IDs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Congruence Predictions and Assess Accuracy over Entire Dataframe\n",
    "\n",
    "We now apply the per-sentence structure over the whole ACY dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 3,935 sentences to predict.\n"
     ]
    }
   ],
   "source": [
    "# Max sentence_id in dataframe\n",
    "max_sentence_id = len(full_mentions['sentence_id'].unique())\n",
    "print(\"We have {:,} sentences to predict.\".format(max_sentence_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate accuracy\n",
    "def calculate_accuracy(predictions, dataframe=full_mentions, verbose=False):\n",
    "    \"\"\"\n",
    "    Function to calculate accuracy over generated predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize tracker metrics\n",
    "    accurate_predictions = 0\n",
    "    accurate_present = 0\n",
    "    \n",
    "    # Iterate through each full mention\n",
    "    for row in tqdm(range(len(dataframe))):\n",
    "        mention_df = dataframe.iloc[row]\n",
    "        \n",
    "        # Save key values\n",
    "        sid = mention_df['sentence_id']\n",
    "        fm = mention_df['full_mention']\n",
    "        title = mention_df['wikipedia_title']\n",
    "        page_id = mention_df['wikipedia_page_ID']\n",
    "        candidate_pool_page_ids = mention_df['candidate_pool_page_ids']\n",
    "        \n",
    "        # Retrieve prediction\n",
    "        pred = predictions[sid][fm]\n",
    "        norm_pred_title = normalize_text(pred[0])\n",
    "        pred_page_id = pred[1]\n",
    "        \n",
    "        # Print comparison (useful for subset review)\n",
    "        if verbose:\n",
    "            print(fm, sid, \"||| True:\", title, page_id, \"==? Pred:\", norm_pred_title, pred_page_id, \"|||\",\\\n",
    "            norm_pred_title==title, pred_page_id==page_id, \" ||| Present? \", (page_id in candidate_pool_page_ids))\n",
    "        \n",
    "        # Compare true vs prediction\n",
    "        if page_id == pred_page_id:\n",
    "            accurate_predictions += 1\n",
    "        if page_id in candidate_pool_page_ids:\n",
    "            accurate_present += 1\n",
    "        \n",
    "    # Print results\n",
    "    print(\"------------------------------------------\")\n",
    "    print(\"Predictive Accuracy: {}%\".format(round(accurate_predictions/len(dataframe)*100, 3)))\n",
    "    print(\"Answer Present: {}%\".format(round(accurate_present/len(dataframe)*100, 3)))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congruence Accuracy without considering Prior Confidence\n",
    "\n",
    "We first experiment with calculating congruence accuracy without directly incorporating prior confidence. We still indirectly incorporate it since we took the Top N most confidence (highest ranked) values in Phase 3, but after creating the Top N list, we don't explicitly incorporate it in our calculation for final predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3935/3935 [09:51<00:00,  6.65it/s] \n"
     ]
    }
   ],
   "source": [
    "# Iterate over whole dataframe to produce mention predictions for each sentence\n",
    "congruent_predictions_freq_nopr = {}\n",
    "for sid in tqdm(full_mentions['sentence_id'].unique()):\n",
    "    congruent_predictions_freq_nopr[sid] = get_congruent_predictions(sid, dataframe=full_mentions,\n",
    "                                                                     with_priors=False, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13781/13781 [00:01<00:00, 7176.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Predictive Accuracy: 24.367%\n",
      "Answer Present: 64.095%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "calculate_accuracy(predictions=congruent_predictions_freq_nopr, dataframe=full_mentions, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Accuracy only with Full Mentions with Known True\n",
    "\n",
    "This is a better reflection of our success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Mentions remaining:  9785\n"
     ]
    }
   ],
   "source": [
    "# Filter dataframe to only full mentions with known true values\n",
    "known_true_mentions = full_mentions[full_mentions['wikipedia_page_ID'].notnull()].reset_index()\n",
    "print(\"Full Mentions remaining: \", len(known_true_mentions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9785/9785 [00:01<00:00, 6843.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Predictive Accuracy: 34.318%\n",
      "Answer Present: 90.271%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "calculate_accuracy(predictions=congruent_predictions_freq_nopr, dataframe=known_true_mentions, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 1689.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ID: 2364, Number of Mentions: 8\n",
      "------------------------------------------\n",
      "AUCKLAND 2364 ||| True: Auckland 18660332.0 ==? Pred: Auckland rugby league team 14059712 ||| False False  ||| Present?  True\n",
      "Auckland 2364 ||| True: Auckland 18660332.0 ==? Pred: Auckland rugby league team 14059712 ||| False False  ||| Present?  True\n",
      "North Shore 2364 ||| True: North Shore City 350800.0 ==? Pred: North Shore (Long Island) 1368673 ||| False False  ||| Present?  True\n",
      "North Shore 2364 ||| True: North Shore City 350800.0 ==? Pred: North Shore (Long Island) 1368673 ||| False False  ||| Present?  True\n",
      "New Zealand Press Association 2364 ||| True: New Zealand Press Association 3185516.0 ==? Pred: New Zealand Press Association 3185516 ||| True True  ||| Present?  True\n",
      "New Zealand Press Association 2364 ||| True: New Zealand Press Association 3185516.0 ==? Pred: New Zealand Press Association 3185516 ||| True True  ||| Present?  True\n",
      "New Zealand Press Association 2364 ||| True: New Zealand Press Association 3185516.0 ==? Pred: New Zealand Press Association 3185516 ||| True True  ||| Present?  True\n",
      "New Zealand Press Association 2364 ||| True: New Zealand Press Association 3185516.0 ==? Pred: New Zealand Press Association 3185516 ||| True True  ||| Present?  True\n",
      "------------------------------------------\n",
      "Predictive Accuracy: 50.0%\n",
      "Answer Present: 100.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter to random sentence for manual review\n",
    "rand_sid = np.random.choice(known_true_mentions['sentence_id'])\n",
    "rand_sentence_df = known_true_mentions[known_true_mentions['sentence_id'] == rand_sid]\n",
    "print(f\"Sentence ID: {rand_sid}, Number of Mentions: {len(rand_sentence_df)}\")\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "# Calculate accuracy\n",
    "calculate_accuracy(predictions=congruent_predictions_freq_nopr, dataframe=rand_sentence_df, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congruence Accuracy considering Prior Confidence\n",
    "\n",
    "Now, we directly incorporate prior confidence by combining it during the prediction process with our calculated congruent metric. This involves \"discounting\" congruence by the prior confidence we had in each combination's component candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3935/3935 [14:19<00:00,  4.58it/s] \n"
     ]
    }
   ],
   "source": [
    "# Iterate over whole dataframe to produce mention predictions for each sentence\n",
    "congruent_predictions_freq_pr = {}\n",
    "for sid in tqdm(full_mentions['sentence_id'].unique()):\n",
    "    congruent_predictions_freq_pr[sid] = get_congruent_predictions(sid, dataframe=full_mentions,\n",
    "                                                                   with_priors=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13781/13781 [00:01<00:00, 7267.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Predictive Accuracy: 50.301%\n",
      "Answer Present: 64.095%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "calculate_accuracy(predictions=congruent_predictions_freq_pr, dataframe=full_mentions, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Accuracy only with Full Mentions with Known True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9785/9785 [00:01<00:00, 7244.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Predictive Accuracy: 70.843%\n",
      "Answer Present: 90.271%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "calculate_accuracy(predictions=congruent_predictions_freq_pr, dataframe=known_true_mentions, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1243.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ID: 4123, Number of Mentions: 1\n",
      "------------------------------------------\n",
      "Turnhout 4123 ||| True: Turnhout 156847.0 ==? Pred: Turnhout 156847 ||| True True  ||| Present?  True\n",
      "------------------------------------------\n",
      "Predictive Accuracy: 100.0%\n",
      "Answer Present: 100.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter to random sentence for manual review\n",
    "rand_sid = np.random.choice(known_true_mentions['sentence_id'])\n",
    "rand_sentence_df = known_true_mentions[known_true_mentions['sentence_id'] == rand_sid]\n",
    "print(f\"Sentence ID: {rand_sid}, Number of Mentions: {len(rand_sentence_df)}\")\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "# Calculate accuracy\n",
    "calculate_accuracy(predictions=congruent_predictions_freq_pr, dataframe=rand_sentence_df, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>full_mention</th>\n",
       "      <th>wikipedia_URL</th>\n",
       "      <th>wikipedia_page_ID</th>\n",
       "      <th>wikipedia_title</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>congruent_mentions</th>\n",
       "      <th>norm_full_mention</th>\n",
       "      <th>candidate_pool_page_ids</th>\n",
       "      <th>candidate_pool_item_ids</th>\n",
       "      <th>candidate_pool_titles</th>\n",
       "      <th>candidate_pool_priors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10612</th>\n",
       "      <td>B</td>\n",
       "      <td>RMT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4123</td>\n",
       "      <td>720</td>\n",
       "      <td>[RMT, Turnhout]</td>\n",
       "      <td>rmt</td>\n",
       "      <td>[465985, 43945, 191336, 26675228]</td>\n",
       "      <td>[6979153, 179415, 2379139, 2583377]</td>\n",
       "      <td>[National_Union_of_Rail,_Maritime_and_Transpor...</td>\n",
       "      <td>[0.9315068, 0.0273973, 0.0273973, 0.0136986]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10613</th>\n",
       "      <td>B</td>\n",
       "      <td>Turnhout</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Turnhout</td>\n",
       "      <td>156847.0</td>\n",
       "      <td>Turnhout</td>\n",
       "      <td>4123</td>\n",
       "      <td>720</td>\n",
       "      <td>[RMT, Turnhout]</td>\n",
       "      <td>turnhout</td>\n",
       "      <td>[156847, 2447995, 157908, 157911, 39090401]</td>\n",
       "      <td>[271783, 1568867, 646525, 898338, 4934232]</td>\n",
       "      <td>[Turnhout, KFC_Turnhout, Battle_of_Turnhout_(1...</td>\n",
       "      <td>[0.8877193, 0.0947368, 0.0105263, 0.0035088, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mention full_mention                          wikipedia_URL  \\\n",
       "10612       B          RMT                                    NaN   \n",
       "10613       B     Turnhout  http://en.wikipedia.org/wiki/Turnhout   \n",
       "\n",
       "       wikipedia_page_ID wikipedia_title  sentence_id  doc_id  \\\n",
       "10612                NaN             NaN         4123     720   \n",
       "10613           156847.0        Turnhout         4123     720   \n",
       "\n",
       "      congruent_mentions norm_full_mention  \\\n",
       "10612    [RMT, Turnhout]               rmt   \n",
       "10613    [RMT, Turnhout]          turnhout   \n",
       "\n",
       "                           candidate_pool_page_ids  \\\n",
       "10612            [465985, 43945, 191336, 26675228]   \n",
       "10613  [156847, 2447995, 157908, 157911, 39090401]   \n",
       "\n",
       "                          candidate_pool_item_ids  \\\n",
       "10612         [6979153, 179415, 2379139, 2583377]   \n",
       "10613  [271783, 1568867, 646525, 898338, 4934232]   \n",
       "\n",
       "                                   candidate_pool_titles  \\\n",
       "10612  [National_Union_of_Rail,_Maritime_and_Transpor...   \n",
       "10613  [Turnhout, KFC_Turnhout, Battle_of_Turnhout_(1...   \n",
       "\n",
       "                                   candidate_pool_priors  \n",
       "10612       [0.9315068, 0.0273973, 0.0273973, 0.0136986]  \n",
       "10613  [0.8877193, 0.0947368, 0.0105263, 0.0035088, 0...  "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See original dataframe\n",
    "full_mentions[full_mentions['sentence_id'] == rand_sid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Turnhout',\n",
       " 'KFC_Turnhout',\n",
       " 'Battle_of_Turnhout_(1597)',\n",
       " 'Battle_of_Turnhout_(1789)',\n",
       " 'Turnhout_railway_station']"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zoom in on a full candidate pool\n",
    "full_mentions[full_mentions['sentence_id'] == rand_sid]['candidate_pool_titles'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate with *Popularity* Predictions - Known True Only\n",
    "\n",
    "We also want to see how much of an impact congruence can have on candidate pools produced via page popularity anchor link statistics. These are considered less effective because of large skews that can happen if a word is linked to a very popular page just a single time. Our hypothesis is that congruence may have a larger impact on popularity mentions and to assess this, we compare accuracy with and without prior incorporation for known trues only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>full_mention</th>\n",
       "      <th>wikipedia_URL</th>\n",
       "      <th>wikipedia_page_ID</th>\n",
       "      <th>wikipedia_title</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>congruent_mentions</th>\n",
       "      <th>norm_full_mention</th>\n",
       "      <th>candidate_pool_page_ids</th>\n",
       "      <th>candidate_pool_item_ids</th>\n",
       "      <th>candidate_pool_titles</th>\n",
       "      <th>candidate_pool_priors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>EU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>eu</td>\n",
       "      <td>[9317, 9239, 9891, 9472, 10890716]</td>\n",
       "      <td>[458, 46, 45003, 4916, 185441]</td>\n",
       "      <td>['European_Union', 'Europe', 'Entropy', 'Euro'...</td>\n",
       "      <td>[0.2245141, 0.2015168, 0.0965482, 0.0768826, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>German</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Germany</td>\n",
       "      <td>11867.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>german</td>\n",
       "      <td>[11867, 27318, 21148, 21212, 26964606]</td>\n",
       "      <td>[183, 334, 55, 7318, 40]</td>\n",
       "      <td>['Germany', 'Singapore', 'Netherlands', 'Nazi_...</td>\n",
       "      <td>[0.0558084, 0.0548498, 0.044104, 0.0268639, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>British</td>\n",
       "      <td>http://en.wikipedia.org/wiki/United_Kingdom</td>\n",
       "      <td>31717.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>british</td>\n",
       "      <td>[3434750, 31717, 19344654, 26061, 8569916]</td>\n",
       "      <td>[30, 145, 9531, 172771, 1860]</td>\n",
       "      <td>['United_States', 'United_Kingdom', 'BBC', 'Ro...</td>\n",
       "      <td>[0.1243038, 0.0660245, 0.0317426, 0.0291264, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>Peter Blackburn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Peter Blackburn', 'BRUSSELS', 'European Comm...</td>\n",
       "      <td>peter blackburn</td>\n",
       "      <td>[56783206, 56873217, 9643132]</td>\n",
       "      <td>[2073954, 26634508, 7172840]</td>\n",
       "      <td>['Peter_Blackburn_(badminton)', 'Peter_Blackbu...</td>\n",
       "      <td>[0.6296296, 0.3703704, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>Peter Blackburn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Peter Blackburn', 'BRUSSELS', 'European Comm...</td>\n",
       "      <td>peter blackburn</td>\n",
       "      <td>[56783206, 56873217, 9643132]</td>\n",
       "      <td>[2073954, 26634508, 7172840]</td>\n",
       "      <td>['Peter_Blackburn_(badminton)', 'Peter_Blackbu...</td>\n",
       "      <td>[0.6296296, 0.3703704, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mention     full_mention                                wikipedia_URL  \\\n",
       "0       B               EU                                          NaN   \n",
       "1       B           German         http://en.wikipedia.org/wiki/Germany   \n",
       "2       B          British  http://en.wikipedia.org/wiki/United_Kingdom   \n",
       "3       B  Peter Blackburn                                          NaN   \n",
       "4       I  Peter Blackburn                                          NaN   \n",
       "\n",
       "   wikipedia_page_ID wikipedia_title  sentence_id  doc_id  \\\n",
       "0                NaN             NaN            0       0   \n",
       "1            11867.0         Germany            0       0   \n",
       "2            31717.0  United Kingdom            0       0   \n",
       "3                NaN             NaN            1       0   \n",
       "4                NaN             NaN            1       0   \n",
       "\n",
       "                                  congruent_mentions norm_full_mention  \\\n",
       "0                        ['EU', 'German', 'British']                eu   \n",
       "1                        ['EU', 'German', 'British']            german   \n",
       "2                        ['EU', 'German', 'British']           british   \n",
       "3  ['Peter Blackburn', 'BRUSSELS', 'European Comm...   peter blackburn   \n",
       "4  ['Peter Blackburn', 'BRUSSELS', 'European Comm...   peter blackburn   \n",
       "\n",
       "                      candidate_pool_page_ids         candidate_pool_item_ids  \\\n",
       "0          [9317, 9239, 9891, 9472, 10890716]  [458, 46, 45003, 4916, 185441]   \n",
       "1      [11867, 27318, 21148, 21212, 26964606]        [183, 334, 55, 7318, 40]   \n",
       "2  [3434750, 31717, 19344654, 26061, 8569916]   [30, 145, 9531, 172771, 1860]   \n",
       "3               [56783206, 56873217, 9643132]    [2073954, 26634508, 7172840]   \n",
       "4               [56783206, 56873217, 9643132]    [2073954, 26634508, 7172840]   \n",
       "\n",
       "                               candidate_pool_titles  \\\n",
       "0  ['European_Union', 'Europe', 'Entropy', 'Euro'...   \n",
       "1  ['Germany', 'Singapore', 'Netherlands', 'Nazi_...   \n",
       "2  ['United_States', 'United_Kingdom', 'BBC', 'Ro...   \n",
       "3  ['Peter_Blackburn_(badminton)', 'Peter_Blackbu...   \n",
       "4  ['Peter_Blackburn_(badminton)', 'Peter_Blackbu...   \n",
       "\n",
       "                               candidate_pool_priors  \n",
       "0  [0.2245141, 0.2015168, 0.0965482, 0.0768826, 0...  \n",
       "1  [0.0558084, 0.0548498, 0.044104, 0.0268639, 0....  \n",
       "2  [0.1243038, 0.0660245, 0.0317426, 0.0291264, 0...  \n",
       "3                        [0.6296296, 0.3703704, 0.0]  \n",
       "4                        [0.6296296, 0.3703704, 0.0]  "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "full_mentions_pop = pd.read_csv(os.path.join(preds_path, \"anchortext_popularity_5x5.csv\"), delimiter=\",\")\n",
    "full_mentions_pop.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ['Peter Blackburn', 'BRUSSELS', 'European Commission', 'German', 'British']\n",
      "After ['Peter Blackburn', 'BRUSSELS', 'European Commission', 'German', 'British']\n",
      "Before [56783206, 56873217, 9643132]\n",
      "After [56783206, 56873217, 9643132]\n",
      "Before [2073954, 26634508, 7172840]\n",
      "After [2073954, 26634508, 7172840]\n",
      "Before ['Peter_Blackburn_(badminton)', 'Peter_Blackburn_(MP)', 'Peter_Blackburn_(bishop)']\n",
      "After ['Peter_Blackburn_(badminton)', 'Peter_Blackburn_(MP)', 'Peter_Blackburn_(bishop)']\n",
      "Before [0.6296296, 0.3703704, 0.0]\n",
      "After [0.6296296, 0.3703704, 0.0]\n",
      "CPU times: user 126 ms, sys: 8.27 ms, total: 134 ms\n",
      "Wall time: 132 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "### Apply defined function to entire dataframe for all candidate pool columns\n",
    "\n",
    "column = 'congruent_mentions'\n",
    "print(\"Before\", full_mentions_pop[column][3])\n",
    "parsed_candidate_pool = full_mentions_pop[column].apply(parse_list_string, value_type=str)\n",
    "full_mentions_pop[column] = parsed_candidate_pool\n",
    "print(\"After\", full_mentions_pop[column][3])\n",
    "\n",
    "column = 'candidate_pool_page_ids'\n",
    "print(\"Before\", full_mentions_pop[column][3])\n",
    "parsed_candidate_pool = full_mentions_pop[column].apply(parse_list_string, value_type=int)\n",
    "full_mentions_pop[column] = parsed_candidate_pool\n",
    "print(\"After\", full_mentions_pop[column][3])\n",
    "\n",
    "\n",
    "column = 'candidate_pool_item_ids'\n",
    "print(\"Before\", full_mentions_pop[column][3])\n",
    "parsed_candidate_pool = full_mentions_pop[column].apply(parse_list_string, value_type=int)\n",
    "full_mentions_pop[column] = parsed_candidate_pool\n",
    "print(\"After\", full_mentions_pop[column][3])\n",
    "\n",
    "\n",
    "column = 'candidate_pool_titles'\n",
    "print(\"Before\", full_mentions_pop[column][3])\n",
    "parsed_candidate_pool = full_mentions_pop[column].apply(parse_list_string, value_type=str)\n",
    "full_mentions_pop[column] = parsed_candidate_pool\n",
    "print(\"After\", full_mentions_pop[column][3])\n",
    "\n",
    "column = 'candidate_pool_priors'\n",
    "print(\"Before\", full_mentions_pop[column][3])\n",
    "parsed_candidate_pool = full_mentions_pop[column].apply(parse_list_string, value_type=float)\n",
    "full_mentions_pop[column] = parsed_candidate_pool\n",
    "print(\"After\", full_mentions_pop[column][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congruence Accuracy without considering Prior Confidence\n",
    "\n",
    "We first experiment with calculating congruence accuracy without directly incorporating prior confidence. We still indirectly incorporate it since we took the Top N most confidence (highest ranked) values in Phase 3, but after creating the Top N list, we don't explicitly incorporate it in our calculation for final predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3935/3935 [09:39<00:00,  6.79it/s] \n"
     ]
    }
   ],
   "source": [
    "# Iterate over whole dataframe to produce mention predictions for each sentence\n",
    "congruent_predictions_pop_nopr = {}\n",
    "for sid in tqdm(full_mentions['sentence_id'].unique()):\n",
    "    congruent_predictions_pop_nopr[sid] = get_congruent_predictions(sid, dataframe=full_mentions,\n",
    "                                                                     with_priors=False, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9785/9785 [00:01<00:00, 7305.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Predictive Accuracy: 34.318%\n",
      "Answer Present: 90.271%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "calculate_accuracy(predictions=congruent_predictions_pop_nopr, dataframe=known_true_mentions, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 1224.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ID: 148, Number of Mentions: 3\n",
      "------------------------------------------\n",
      "AD-DIYAR 148 ||| True: Ad-Diyar 4273826.0 ==? Pred: Ad-Diyar 4273826 ||| True True  ||| Present?  True\n",
      "Lebanon 148 ||| True: Lebanon 17771.0 ==? Pred: Lebanon national football team 1205183 ||| False False  ||| Present?  True\n",
      "Pakistan 148 ||| True: Pakistan 23235.0 ==? Pred: Pakistan national football team 1302448 ||| False False  ||| Present?  True\n",
      "------------------------------------------\n",
      "Predictive Accuracy: 33.333%\n",
      "Answer Present: 100.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter to random sentence for manual review\n",
    "rand_sid = np.random.choice(known_true_mentions['sentence_id'])\n",
    "rand_sentence_df = known_true_mentions[known_true_mentions['sentence_id'] == rand_sid]\n",
    "print(f\"Sentence ID: {rand_sid}, Number of Mentions: {len(rand_sentence_df)}\")\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "# Calculate accuracy\n",
    "calculate_accuracy(predictions=congruent_predictions_pop_nopr, dataframe=rand_sentence_df, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congruence Accuracy considering Prior Confidence\n",
    "\n",
    "Now, we directly incorporate prior confidence by combining it during the prediction process with our calculated congruent metric. This involves \"discounting\" congruence by the prior confidence we had in each combination's component candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3935/3935 [14:12<00:00,  4.62it/s] \n"
     ]
    }
   ],
   "source": [
    "# Iterate over whole dataframe to produce mention predictions for each sentence\n",
    "congruent_predictions_pop_pr = {}\n",
    "for sid in tqdm(full_mentions['sentence_id'].unique()):\n",
    "    congruent_predictions_pop_pr[sid] = get_congruent_predictions(sid, dataframe=full_mentions,\n",
    "                                                                   with_priors=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9785/9785 [00:01<00:00, 7165.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Predictive Accuracy: 70.843%\n",
      "Answer Present: 90.271%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "calculate_accuracy(predictions=congruent_predictions_pop_pr, dataframe=known_true_mentions, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 1154.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ID: 3284, Number of Mentions: 4\n",
      "------------------------------------------\n",
      "JAKARTA 3284 ||| True: Jakarta 16275.0 ==? Pred: Jakarta 16275 ||| True True  ||| Present?  True\n",
      "GMT 3284 ||| True: Greenwich Mean Time 12701.0 ==? Pred: Greenwich Mean Time 12701 ||| True True  ||| Present?  True\n",
      "Jakarta 3284 ||| True: Jakarta 16275.0 ==? Pred: Jakarta 16275 ||| True True  ||| Present?  True\n",
      "Seoul 3284 ||| True: Seoul 19159283.0 ==? Pred: Seoul 19159283 ||| True True  ||| Present?  True\n",
      "------------------------------------------\n",
      "Predictive Accuracy: 100.0%\n",
      "Answer Present: 100.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter to random sentence for manual review\n",
    "rand_sid = np.random.choice(known_true_mentions['sentence_id'])\n",
    "rand_sentence_df = known_true_mentions[known_true_mentions['sentence_id'] == rand_sid]\n",
    "print(f\"Sentence ID: {rand_sid}, Number of Mentions: {len(rand_sentence_df)}\")\n",
    "print(\"------------------------------------------\")\n",
    "\n",
    "# Calculate accuracy\n",
    "calculate_accuracy(predictions=congruent_predictions_pop_pr, dataframe=rand_sentence_df, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logical Flow Demonstration\n",
    "\n",
    "The cells below have been included as a more easily understood logical flow to understand how we designed the recursive congruence algorithm for an arbitrary length of full mentions in a sentence. We manually select a sentence and work through that. This is identical to the above but with more printed out breaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>full_mention</th>\n",
       "      <th>wikipedia_URL</th>\n",
       "      <th>wikipedia_page_ID</th>\n",
       "      <th>wikipedia_title</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>congruent_mentions</th>\n",
       "      <th>norm_full_mention</th>\n",
       "      <th>candidate_pool_page_ids</th>\n",
       "      <th>candidate_pool_item_ids</th>\n",
       "      <th>candidate_pool_titles</th>\n",
       "      <th>candidate_pool_priors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>Peter Blackburn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Peter Blackburn, BRUSSELS, European Commissio...</td>\n",
       "      <td>peter blackburn</td>\n",
       "      <td>[56783206, 9643132, 56873217]</td>\n",
       "      <td>[2073954, 7172840, 26634508]</td>\n",
       "      <td>[Peter_Blackburn_(badminton), Peter_Blackburn_...</td>\n",
       "      <td>[0.5, 0.3, 0.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>BRUSSELS</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Brussels</td>\n",
       "      <td>3708.0</td>\n",
       "      <td>Brussels</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Peter Blackburn, BRUSSELS, European Commissio...</td>\n",
       "      <td>brussels</td>\n",
       "      <td>[3708, 575501, 1437181, 269753, 4152470]</td>\n",
       "      <td>[240, 239, 1050331, 28934, 800587]</td>\n",
       "      <td>[Brussels, City_of_Brussels, R.W.D.M._Brussels...</td>\n",
       "      <td>[0.9631528, 0.0115147, 0.0037144, 0.0028973, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>European Commission</td>\n",
       "      <td>http://en.wikipedia.org/wiki/European_Commission</td>\n",
       "      <td>9974.0</td>\n",
       "      <td>European Commission</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Peter Blackburn, BRUSSELS, European Commissio...</td>\n",
       "      <td>european commission</td>\n",
       "      <td>[9974, 24468, 1130631, 1549462, 41222020]</td>\n",
       "      <td>[8880, 8882, 388354, 1780232, 16975389]</td>\n",
       "      <td>[European_Commission, President_of_the_Europea...</td>\n",
       "      <td>[0.9959089, 0.0008894, 0.0005336, 0.0003557, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>German</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Germany</td>\n",
       "      <td>11867.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Peter Blackburn, BRUSSELS, European Commissio...</td>\n",
       "      <td>german</td>\n",
       "      <td>[11867, 11884, 152735, 21212, 12674]</td>\n",
       "      <td>[183, 188, 42884, 7318, 43287]</td>\n",
       "      <td>[Germany, German_language, Germans, Nazi_Germa...</td>\n",
       "      <td>[0.4192066, 0.2893363, 0.1470461, 0.03832, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>British</td>\n",
       "      <td>http://en.wikipedia.org/wiki/United_Kingdom</td>\n",
       "      <td>31717.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Peter Blackburn, BRUSSELS, European Commissio...</td>\n",
       "      <td>british</td>\n",
       "      <td>[31717, 19097669, 13530298, 4721, 158019]</td>\n",
       "      <td>[145, 842438, 23666, 8680, 161885]</td>\n",
       "      <td>[United_Kingdom, British_people, Great_Britain...</td>\n",
       "      <td>[0.6101256, 0.1146913, 0.0681775, 0.0366451, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mention         full_mention  \\\n",
       "0       B      Peter Blackburn   \n",
       "1       B             BRUSSELS   \n",
       "2       B  European Commission   \n",
       "3       B               German   \n",
       "4       B              British   \n",
       "\n",
       "                                      wikipedia_URL  wikipedia_page_ID  \\\n",
       "0                                               NaN                NaN   \n",
       "1             http://en.wikipedia.org/wiki/Brussels             3708.0   \n",
       "2  http://en.wikipedia.org/wiki/European_Commission             9974.0   \n",
       "3              http://en.wikipedia.org/wiki/Germany            11867.0   \n",
       "4       http://en.wikipedia.org/wiki/United_Kingdom            31717.0   \n",
       "\n",
       "       wikipedia_title  sentence_id  doc_id  \\\n",
       "0                  NaN            1       0   \n",
       "1             Brussels            1       0   \n",
       "2  European Commission            1       0   \n",
       "3              Germany            1       0   \n",
       "4       United Kingdom            1       0   \n",
       "\n",
       "                                  congruent_mentions    norm_full_mention  \\\n",
       "0  [Peter Blackburn, BRUSSELS, European Commissio...      peter blackburn   \n",
       "1  [Peter Blackburn, BRUSSELS, European Commissio...             brussels   \n",
       "2  [Peter Blackburn, BRUSSELS, European Commissio...  european commission   \n",
       "3  [Peter Blackburn, BRUSSELS, European Commissio...               german   \n",
       "4  [Peter Blackburn, BRUSSELS, European Commissio...              british   \n",
       "\n",
       "                     candidate_pool_page_ids  \\\n",
       "0              [56783206, 9643132, 56873217]   \n",
       "1   [3708, 575501, 1437181, 269753, 4152470]   \n",
       "2  [9974, 24468, 1130631, 1549462, 41222020]   \n",
       "3       [11867, 11884, 152735, 21212, 12674]   \n",
       "4  [31717, 19097669, 13530298, 4721, 158019]   \n",
       "\n",
       "                   candidate_pool_item_ids  \\\n",
       "0             [2073954, 7172840, 26634508]   \n",
       "1       [240, 239, 1050331, 28934, 800587]   \n",
       "2  [8880, 8882, 388354, 1780232, 16975389]   \n",
       "3           [183, 188, 42884, 7318, 43287]   \n",
       "4       [145, 842438, 23666, 8680, 161885]   \n",
       "\n",
       "                               candidate_pool_titles  \\\n",
       "0  [Peter_Blackburn_(badminton), Peter_Blackburn_...   \n",
       "1  [Brussels, City_of_Brussels, R.W.D.M._Brussels...   \n",
       "2  [European_Commission, President_of_the_Europea...   \n",
       "3  [Germany, German_language, Germans, Nazi_Germa...   \n",
       "4  [United_Kingdom, British_people, Great_Britain...   \n",
       "\n",
       "                               candidate_pool_priors  \n",
       "0                                    [0.5, 0.3, 0.2]  \n",
       "1  [0.9631528, 0.0115147, 0.0037144, 0.0028973, 0...  \n",
       "2  [0.9959089, 0.0008894, 0.0005336, 0.0003557, 0...  \n",
       "3  [0.4192066, 0.2893363, 0.1470461, 0.03832, 0.0...  \n",
       "4  [0.6101256, 0.1146913, 0.0681775, 0.0366451, 0...  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test on manually selected sentence\n",
    "single_sentence_df = full_mentions[full_mentions['sentence_id'] == 1].drop_duplicates(['full_mention', 'wikipedia_page_ID', 'sentence_id']).reset_index(drop=True)\n",
    "single_sentence_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Peter Blackburn', 'BRUSSELS', 'European Commission', 'German', 'British']\n"
     ]
    }
   ],
   "source": [
    "# Congruent Mention\n",
    "print(single_sentence_df['congruent_mentions'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to numerical for easier recursive logic later\n",
    "sentence_mention_nums = np.arange(len(single_sentence_df['congruent_mentions'][0]))\n",
    "sentence_mention_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate candidate lists of vectors\n",
    "def get_candidate_pool_vectors(candidate_pool_titles, verbose=False):\n",
    "    \"\"\"\n",
    "    Function to return entity vectors from Wikipedia2Vec\n",
    "    Takes as input a list of page titles, representing the candidate pool\n",
    "    Normalizes each page title to match necessary input format\n",
    "    Returns entity vector or empty vector if no match\n",
    "    \"\"\"\n",
    "    # Track failed vector queries\n",
    "    no_vector_count = 0\n",
    "    candidate_pool_vectors = []\n",
    "    for candidate in candidate_pool_titles:\n",
    "        candidate = normalize_text(candidate)\n",
    "        try:\n",
    "            candidate_vectors = w2v.get_entity_vector(candidate)\n",
    "        except KeyError:\n",
    "            # Keep empty vector representation to maintain index locations\n",
    "            candidate_vectors = np.zeros(100)\n",
    "            no_vector_count += 1\n",
    "        candidate_pool_vectors.append(candidate_vectors)\n",
    "    \n",
    "    if len(candidate_pool_titles) == 0:\n",
    "        candidate_pool_vectors = [np.zeros(100), np.zeros(100), np.zeros(100)]\n",
    "    \n",
    "    if verbose: print(f\"Failed Wikipedia2Vec Entity Vector Queries: {no_vector_count}\")\n",
    "    return candidate_pool_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed Wikipedia2Vec Entity Vector Queries: 2\n",
      "Failed Wikipedia2Vec Entity Vector Queries: 0\n",
      "Failed Wikipedia2Vec Entity Vector Queries: 1\n",
      "Failed Wikipedia2Vec Entity Vector Queries: 0\n",
      "Failed Wikipedia2Vec Entity Vector Queries: 0\n"
     ]
    }
   ],
   "source": [
    "# Save vectors in dictionary\n",
    "vector_dict = {}\n",
    "\n",
    "# For each full mention we are analyzing in the contextual domain (i.e. sentence)\n",
    "for m in sentence_mention_nums:\n",
    "    \n",
    "    # Retrieve candidate pool titles\n",
    "    candidate_pool_titles = single_sentence_df['candidate_pool_titles'][m]\n",
    "    \n",
    "    # Convert candidate pool titles to candidate pool vectors\n",
    "    candidate_pool_vectors = get_candidate_pool_vectors(candidate_pool_titles, verbose=True)\n",
    "    \n",
    "    # Save candidate pool vectors to dictionary\n",
    "    vector_dict[m] = candidate_pool_vectors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "memmap([ 5.6705320e-01, -3.3967879e-01,  6.7967427e-01, -8.8146311e-01,\n",
       "        -9.9295086e-01, -3.8026679e-01,  3.1121460e-01, -1.2859932e-01,\n",
       "         6.6351652e-01, -1.9566450e+00,  3.7053553e-04, -2.7253684e-01,\n",
       "         8.7685895e-01, -9.0732628e-01,  3.2349053e-01,  5.2059549e-01,\n",
       "         5.6463188e-01, -6.1859089e-01,  4.5522106e-01, -7.2353148e-01,\n",
       "        -9.7908747e-01,  1.5604380e+00, -8.5058933e-01, -3.0102137e-01,\n",
       "        -7.3634320e-01,  6.0062087e-01, -5.4628011e-02,  6.4058477e-01,\n",
       "         6.5022165e-01,  2.9072487e-01,  1.2940426e+00, -9.4071068e-02,\n",
       "         4.9198017e-01,  3.0347526e-01, -5.4809892e-01, -2.0429029e-01,\n",
       "         9.0489048e-01,  2.7048671e-01,  3.9246964e-01, -1.1840639e+00,\n",
       "        -4.3033957e-01, -7.5106245e-01, -5.7284772e-01,  1.4852484e+00,\n",
       "        -8.7626231e-01, -7.4376535e-01, -1.5343527e-01, -7.3458463e-02,\n",
       "        -3.2605672e-01, -1.0146785e+00,  1.0237430e+00, -9.4328153e-01,\n",
       "         3.4996659e-02, -2.0044473e-01, -1.9703417e-01,  9.8306006e-01,\n",
       "         1.2443291e+00,  4.4966465e-01, -1.7725631e+00,  1.4776839e+00,\n",
       "         3.4709200e-01, -6.4714819e-01, -1.2517909e+00,  1.3799247e-01,\n",
       "         8.6123645e-01, -7.0240957e-01,  2.6356363e-01,  1.7173262e+00,\n",
       "        -1.1625690e+00, -7.3700833e-01,  8.7417591e-01, -7.2752094e-01,\n",
       "         5.1354527e-01, -1.4106265e-01,  4.3454650e-01, -2.7464458e-01,\n",
       "        -2.5152385e-01, -1.6812341e-01, -9.3517298e-01,  1.0230876e-01,\n",
       "         4.6504697e-01, -1.7253537e+00,  8.3058596e-01, -4.7467527e-01,\n",
       "        -5.2035451e-01,  3.3971253e-01,  1.5667379e+00,  1.4175670e+00,\n",
       "         4.1496566e-01, -8.0814487e-01, -9.0114975e-01,  8.7815797e-01,\n",
       "        -1.3504833e+00, -1.2146077e+00,  1.3884471e-01, -1.1015518e+00,\n",
       "        -1.5871716e-01, -5.3572315e-03, -1.1229993e+00,  3.8020507e-01],\n",
       "       dtype=float32)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display vector_dict output\n",
    "print(vector_dict.keys())\n",
    "# Preview one candidate vector from a candidate pool vectors\n",
    "vector_dict[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[range(0, 3), range(0, 5), range(0, 5), range(0, 5), range(0, 5)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Structure logic to create all combinations of candidates\n",
    "candidate_counts = [range(len(v)) for v in vector_dict.values()]\n",
    "candidate_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, 0, 0, 0),\n",
       " (0, 0, 0, 0, 1),\n",
       " (0, 0, 0, 0, 2),\n",
       " (0, 0, 0, 0, 3),\n",
       " (0, 0, 0, 0, 4),\n",
       " (0, 0, 0, 1, 0),\n",
       " (0, 0, 0, 1, 1),\n",
       " (0, 0, 0, 1, 2),\n",
       " (0, 0, 0, 1, 3),\n",
       " (0, 0, 0, 1, 4)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_combinations_idx = list(product(*candidate_counts))\n",
    "unique_combinations_idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Translate unique combination indexes into list of vector combinations\n",
    "unique_combinations = []\n",
    "for combo in unique_combinations_idx:\n",
    "#     print(combo)\n",
    "    combo_vector = []\n",
    "    for i in range(len(combo)):\n",
    "        combo_vector.append(vector_dict[i][combo[i]])\n",
    "    unique_combinations.append(combo_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate centroids for each unique combination\n",
    "centroids = []\n",
    "for combo in unique_combinations:\n",
    "    centroids.append(sum(combo)) #/len(combo)) if you want mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.131043  , -0.03438118,  2.4980736 , -0.7308637 , -1.1257738 ,\n",
       "       -0.49353868,  1.0083045 , -1.0838606 ,  0.75853443, -5.91596   ,\n",
       "        0.47778386, -1.3803507 ,  2.8838859 , -5.77764   , -1.5809379 ,\n",
       "       -0.7298596 ,  2.0230465 , -0.5698778 ,  1.3996718 , -0.73016936,\n",
       "       -1.5379165 ,  2.231394  , -1.0941744 , -1.3733233 , -2.2880337 ,\n",
       "        1.8583322 ,  2.8878713 , -1.3950173 ,  0.5865395 ,  0.8182961 ,\n",
       "       -0.37736836, -0.1751889 ,  3.4341693 ,  2.48418   ,  1.6804861 ,\n",
       "        0.1854988 ,  1.6437321 ,  1.0341145 ,  0.44050485, -1.1708148 ,\n",
       "        0.7957667 , -1.3546429 ,  0.38562632,  3.6486506 , -0.76347744,\n",
       "       -1.1840131 , -0.9945575 ,  3.122835  , -2.0672047 , -2.3407288 ,\n",
       "        2.0564058 ,  1.6348517 ,  1.4340049 , -2.695025  ,  0.19447258,\n",
       "        0.7308686 ,  2.818136  ,  1.1672243 , -2.6244626 ,  1.1208712 ,\n",
       "        2.4334676 ,  0.36272705, -1.8655688 ,  1.482802  ,  5.2873936 ,\n",
       "       -1.9874624 , -2.7909927 ,  1.2789898 , -2.3831098 , -3.9685295 ,\n",
       "       -1.3055067 ,  0.16041306, -1.5204049 ,  2.215236  , -2.1311655 ,\n",
       "        0.15059692,  1.4126135 , -0.85459715,  0.441755  , -0.65415514,\n",
       "        0.3865388 , -2.1975203 ,  1.040261  , -1.7043724 ,  1.3146981 ,\n",
       "        0.51544535,  1.6908295 , -0.04856205,  1.2496967 , -2.8507175 ,\n",
       "       -3.2187786 , -1.3497958 ,  0.36218208, -1.3739964 ,  1.1698556 ,\n",
       "       -2.0754268 ,  0.50031245,  1.8875923 , -0.58603346, -1.5836864 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each position should now have one\n",
    "centroids[0]              # Leave as is for sum of vectors\n",
    "# np.array(centroids[0])/5  # Divide by mention count for mean of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm we have a centroid for every set\n",
    "assert len(unique_combinations) == len(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity as distance between each candidate and that set's centroid\n",
    "set_distances = []\n",
    "for i in range(len(unique_combinations)):\n",
    "    candidate_distances = []\n",
    "    combination = unique_combinations[i]\n",
    "    centroid = centroids[i]\n",
    "    for candidate in combination:\n",
    "        \n",
    "        # todo which should I be using?\n",
    "        candidate_distance = cosine_similarity(candidate.reshape(-1, 1), centroid.reshape(-1, 1))\n",
    "#         candidate_distance = pairwise_distances(candidate.reshape(-1, 1), centroid.reshape(-1, 1), metric='cosine')\n",
    "\n",
    "        candidate_distances.append(candidate_distance)\n",
    "    set_distances.append(candidate_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-1.,  1., -1., ..., -1.,  1.,  1.],\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        ...,\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        [-1.,  1., -1., ..., -1.,  1.,  1.],\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.]], dtype=float32),\n",
       " array([[ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        [-1.,  1., -1., ..., -1.,  1.,  1.],\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        ...,\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        [-1.,  1., -1., ..., -1.,  1.,  1.],\n",
       "        [-1.,  1., -1., ..., -1.,  1.,  1.]], dtype=float32),\n",
       " array([[ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        [-1.,  1., -1., ..., -1.,  1.,  1.],\n",
       "        ...,\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        [-1.,  1., -1., ..., -1.,  1.,  1.]], dtype=float32),\n",
       " array([[ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        [-1.,  1., -1., ..., -1.,  1.,  1.],\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        ...,\n",
       "        [-1.,  1., -1., ..., -1.,  1.,  1.],\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.]], dtype=float32),\n",
       " array([[ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        [-1.,  1., -1., ..., -1.,  1.,  1.],\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        ...,\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        [-1.,  1., -1., ..., -1.,  1.,  1.],\n",
       "        [-1.,  1., -1., ..., -1.,  1.,  1.]], dtype=float32)]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_distances[0] # Example combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.,  1., -1., ..., -1.,  1.,  1.],\n",
       "       [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "       [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "       ...,\n",
       "       [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "       [-1.,  1., -1., ..., -1.,  1.,  1.],\n",
       "       [ 1., -1.,  1., ...,  1., -1., -1.]], dtype=float32)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_distances[0][0] # Example candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_set_distance = [np.mean(combo) for combo in set_distances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0176, -0.00528)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(average_set_distance), min(average_set_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_idx = np.argmin(average_set_distance)\n",
    "select_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3, 3, 0, 0)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_congruent_predictions = unique_combinations_idx[select_idx]\n",
    "most_congruent_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 3, 2: 3, 3: 0, 4: 0}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See what we got done\n",
    "mention_predictions = {}\n",
    "for i in range(len(most_congruent_predictions)):\n",
    "    mention_predictions[i] = most_congruent_predictions[i]\n",
    "mention_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mention', 'full_mention', 'wikipedia_URL', 'wikipedia_page_ID',\n",
       "       'wikipedia_title', 'sentence_id', 'doc_id', 'congruent_mentions',\n",
       "       'norm_full_mention', 'candidate_pool_page_ids',\n",
       "       'candidate_pool_item_ids', 'candidate_pool_titles',\n",
       "       'candidate_pool_likelihoods'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_sentence_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Peter Blackburn - True: nan, nan ==? Pred: Peter_Blackburn_(badminton),56783206\n",
      "Text: BRUSSELS - True: Brussels, 3708.0 ==? Pred: Brussels_Airport,269753\n",
      "Text: European Commission - True: European Commission, 9974.0 ==? Pred: European_Commissioner_for_Competition,1549462\n",
      "Text: German - True: Germany, 11867.0 ==? Pred: Germany,11867\n",
      "Text: British - True: United Kingdom, 31717.0 ==? Pred: United_Kingdom,31717\n",
      "*********************************************\n",
      "We predicted 40.0% mentions correctly.\n",
      "The correct answer was present in 80.0% candidate pools.\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = 0\n",
    "answer_present = 0\n",
    "\n",
    "for i in range(len(single_sentence_df)):\n",
    "    row = single_sentence_df.iloc[i]\n",
    "    full_mention = row['full_mention']\n",
    "    wiki_title = row['wikipedia_title']\n",
    "    wiki_page_id = row['wikipedia_page_ID']\n",
    "    candidate_pool_titles = row['candidate_pool_titles']\n",
    "    candidate_pool_page_ids = row['candidate_pool_page_ids']\n",
    "    pred_idx = mention_predictions[i]\n",
    "    pred_title = candidate_pool_titles[pred_idx]\n",
    "    pred_page_id = candidate_pool_page_ids[pred_idx]\n",
    "    print(f\"Text: {full_mention} - True: {wiki_title}, {wiki_page_id} ==? Pred: {pred_title},{pred_page_id}\")\n",
    "    if wiki_page_id == pred_page_id:\n",
    "        correct_predictions += 1\n",
    "    if wiki_page_id in candidate_pool_page_ids:\n",
    "        answer_present += 1\n",
    "\n",
    "print(\"*********************************************\")\n",
    "print(f\"We predicted {round(correct_predictions/len(single_sentence_df)*100,2)}% mentions correctly.\")\n",
    "print(f\"The correct answer was present in {round(answer_present/len(single_sentence_df)*100,2)}% candidate pools.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You've predicted everything!\n"
     ]
    }
   ],
   "source": [
    "print(\"You've predicted everything!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
