{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase Two: Generate Candidate Pool via Anchor Link Statistics\n",
    "\n",
    "In Phase Two, we try to generate candidate pools for each full mention. This notebook uses anchor links on Wikipedia, or hyperlinks from a text string to a Wikipedia page, to propose a candidate pool of possible entities/pages for each full mention. Kensho has provided a version of this dataset structured for NLP tasks that provides a list of all anchor link strings, the associated Wikipedia page that anchor string linked to and the count of links and page popularity. We propose two methods of using anchor links: one sorts by most popular or viewed pages and the other by the most linked or central pages. We output both dataframes for evaluation by congruence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Progress bar\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Processed ACY Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>full_mention</th>\n",
       "      <th>wikipedia_URL</th>\n",
       "      <th>wikipedia_page_ID</th>\n",
       "      <th>wikipedia_title</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>congruent_mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>EU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>German</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Germany</td>\n",
       "      <td>11867.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>British</td>\n",
       "      <td>http://en.wikipedia.org/wiki/United_Kingdom</td>\n",
       "      <td>31717.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mention full_mention                                wikipedia_URL  \\\n",
       "0       B           EU                                          NaN   \n",
       "1       B       German         http://en.wikipedia.org/wiki/Germany   \n",
       "2       B      British  http://en.wikipedia.org/wiki/United_Kingdom   \n",
       "\n",
       "   wikipedia_page_ID wikipedia_title  sentence_id  doc_id  \\\n",
       "0                NaN             NaN            0       0   \n",
       "1            11867.0         Germany            0       0   \n",
       "2            31717.0  United Kingdom            0       0   \n",
       "\n",
       "            congruent_mentions  \n",
       "0  ['EU', 'German', 'British']  \n",
       "1  ['EU', 'German', 'British']  \n",
       "2  ['EU', 'German', 'British']  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base path to input\n",
    "acy_path = '../../data/aida-conll-yago-dataset/'\n",
    "\n",
    "# Load data\n",
    "acy_input = pd.read_csv(os.path.join(acy_path, \"Aida-Conll-Yago-Input.csv\"), delimiter=\",\")\n",
    "acy_input.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21810"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of full mentions\n",
    "len(acy_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Kensho Target Dataset\n",
    "\n",
    "This dataset provides anchor link statistics for Wikipedia pages and is provided by Kensho Technologies. We perform some processing to make it into an improved structure for our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base path to KWNLP\n",
    "kwnlp_path = '../../data/kwnlp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>page_title</th>\n",
       "      <th>views</th>\n",
       "      <th>len_article_chars</th>\n",
       "      <th>len_intro_chars</th>\n",
       "      <th>in_link_count</th>\n",
       "      <th>out_link_count</th>\n",
       "      <th>tmpl_good_article</th>\n",
       "      <th>tmpl_featured_article</th>\n",
       "      <th>tmpl_pseudoscience</th>\n",
       "      <th>tmpl_conspiracy_theories</th>\n",
       "      <th>isa_Q17442446</th>\n",
       "      <th>isa_Q14795564</th>\n",
       "      <th>isa_Q18340514</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>6199</td>\n",
       "      <td>Anarchism</td>\n",
       "      <td>35558</td>\n",
       "      <td>40449</td>\n",
       "      <td>409</td>\n",
       "      <td>3826</td>\n",
       "      <td>371</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>38404</td>\n",
       "      <td>Autism</td>\n",
       "      <td>40081</td>\n",
       "      <td>47659</td>\n",
       "      <td>419</td>\n",
       "      <td>2313</td>\n",
       "      <td>309</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>101038</td>\n",
       "      <td>Albedo</td>\n",
       "      <td>10770</td>\n",
       "      <td>18766</td>\n",
       "      <td>293</td>\n",
       "      <td>3090</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_id  item_id page_title  views  len_article_chars  len_intro_chars  \\\n",
       "0       12     6199  Anarchism  35558              40449              409   \n",
       "1       25    38404     Autism  40081              47659              419   \n",
       "2       39   101038     Albedo  10770              18766              293   \n",
       "\n",
       "   in_link_count  out_link_count  tmpl_good_article  tmpl_featured_article  \\\n",
       "0           3826             371                  1                      0   \n",
       "1           2313             309                  0                      1   \n",
       "2           3090             115                  0                      0   \n",
       "\n",
       "   tmpl_pseudoscience  tmpl_conspiracy_theories  isa_Q17442446  isa_Q14795564  \\\n",
       "0                   0                         0              0              0   \n",
       "1                   0                         0              0              0   \n",
       "2                   0                         0              0              0   \n",
       "\n",
       "   isa_Q18340514  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load article data\n",
    "article_df = pd.read_csv(os.path.join(kwnlp_path, 'kwnlp-enwiki-20200920-article.csv'))\n",
    "article_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anchor_text</th>\n",
       "      <th>target_page_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>3434750</td>\n",
       "      <td>152451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>World War II</td>\n",
       "      <td>32927</td>\n",
       "      <td>133668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>14533</td>\n",
       "      <td>112069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     anchor_text  target_page_id   count\n",
       "0  United States         3434750  152451\n",
       "1   World War II           32927  133668\n",
       "2          India           14533  112069"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load anchor target counts data\n",
    "anchor_df = pd.read_csv(os.path.join(kwnlp_path, 'kwnlp-enwiki-20200920-anchor-target-counts.csv'))\n",
    "anchor_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Target Data\n",
    "\n",
    "We apply normalization to the anchor text to make for simpler matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy to new dataframe for processing\n",
    "anchor_text = anchor_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define text normalization function\n",
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    We define normalized in this notebook as:\n",
    "    - lowercase\n",
    "    - strip whitespace\n",
    "    - Spaces, not underlines\n",
    "    \"\"\"\n",
    "    return str(text).strip().lower().replace(\"_\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply normalization to anchor text\n",
    "anchor_text['norm_anchor_text'] = anchor_text['anchor_text'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3,581 'None' values in anchor_text.\n"
     ]
    }
   ],
   "source": [
    "# Assess presence of Null values in anchor_text\n",
    "print(f\"There are {anchor_text['anchor_text'].isnull().sum():,} 'None' values in anchor_text.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 15,269,229\n",
      "After: 15,265,648\n"
     ]
    }
   ],
   "source": [
    "# Filter out None values\n",
    "print(\"Before: {:,}\".format(len(anchor_text)))\n",
    "anchor_text = anchor_text[anchor_text['anchor_text'].notnull()]\n",
    "print(\"After: {:,}\".format(len(anchor_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anchor_text</th>\n",
       "      <th>target_page_id</th>\n",
       "      <th>count</th>\n",
       "      <th>norm_anchor_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>3434750</td>\n",
       "      <td>152451</td>\n",
       "      <td>united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>World War II</td>\n",
       "      <td>32927</td>\n",
       "      <td>133668</td>\n",
       "      <td>world war ii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>14533</td>\n",
       "      <td>112069</td>\n",
       "      <td>india</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>France</td>\n",
       "      <td>5843419</td>\n",
       "      <td>109669</td>\n",
       "      <td>france</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>footballer</td>\n",
       "      <td>10568</td>\n",
       "      <td>101027</td>\n",
       "      <td>footballer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     anchor_text  target_page_id   count norm_anchor_text\n",
       "0  United States         3434750  152451    united states\n",
       "1   World War II           32927  133668     world war ii\n",
       "2          India           14533  112069            india\n",
       "3         France         5843419  109669           france\n",
       "4     footballer           10568  101027       footballer"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview dataframe\n",
    "anchor_text.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 15,265,648\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>norm_anchor_text</th>\n",
       "      <th>target_page_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>477081</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>51968092</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(album)</td>\n",
       "      <td>51968092</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(underscore)</td>\n",
       "      <td>477081</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>builtin popcount</td>\n",
       "      <td>1127884</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     norm_anchor_text  target_page_id  count\n",
       "0                              477081      2\n",
       "1                            51968092      6\n",
       "2             (album)        51968092      1\n",
       "3        (underscore)          477081      1\n",
       "4    builtin popcount         1127884      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After: 14,431,024\n",
      "-------------------\n",
      "CPU times: user 1min 9s, sys: 11.4 s, total: 1min 20s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Aggregate duplicates now exist as a result of normalization\n",
    "# Example: 'united states' and 'united states' both link to page 3434750 in separate rows\n",
    "# because they were different pre-normalization, but now we want to treat them the same\n",
    "# One row for every every anchor text -> page pair\n",
    "print(\"Before: {:,}\".format(len(anchor_text)))\n",
    "anchor_text = anchor_text.groupby(['norm_anchor_text', 'target_page_id'], as_index=False).agg({'count': sum})\n",
    "display(anchor_text.head(5))\n",
    "print(\"After: {:,}\".format(len(anchor_text)))\n",
    "print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join Page Statistics to Anchor Text Data\n",
    "\n",
    "This provides us with information on page views and link counts for every anchor text string in our desired format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.6 s, sys: 22.7 s, total: 44.2 s\n",
      "Wall time: 53.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>norm_anchor_text</th>\n",
       "      <th>target_page_id</th>\n",
       "      <th>target_item_id</th>\n",
       "      <th>target_page_title</th>\n",
       "      <th>target_page_views</th>\n",
       "      <th>anchor_target_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>477081</td>\n",
       "      <td>11199</td>\n",
       "      <td>Underscore</td>\n",
       "      <td>8857</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(underscore)</td>\n",
       "      <td>477081</td>\n",
       "      <td>11199</td>\n",
       "      <td>Underscore</td>\n",
       "      <td>8857</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>underline mark</td>\n",
       "      <td>477081</td>\n",
       "      <td>11199</td>\n",
       "      <td>Underscore</td>\n",
       "      <td>8857</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  norm_anchor_text  target_page_id  target_item_id target_page_title  \\\n",
       "0                           477081           11199        Underscore   \n",
       "1     (underscore)          477081           11199        Underscore   \n",
       "2   underline mark          477081           11199        Underscore   \n",
       "\n",
       "   target_page_views  anchor_target_count  \n",
       "0               8857                    2  \n",
       "1               8857                    1  \n",
       "2               8857                    1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Merge anchor_text and article stats dataframes\n",
    "anchor_text = pd.merge(\n",
    "    anchor_text,\n",
    "    article_df,\n",
    "    how=\"inner\",\n",
    "    left_on=\"target_page_id\",\n",
    "    right_on=\"page_id\")\n",
    "\n",
    "# Rename columns for clarity\n",
    "anchor_text = anchor_text.rename(columns={\n",
    "    'title': 'target_page_title',\n",
    "    'item_id': 'target_item_id',\n",
    "    'views': 'target_page_views',\n",
    "    'count': 'anchor_target_count',\n",
    "    'page_title': 'target_page_title'})\n",
    "\n",
    "# Specify column ordering\n",
    "anchor_text = anchor_text[[\n",
    "    \"norm_anchor_text\",\n",
    "    \"target_page_id\",\n",
    "    \"target_item_id\",\n",
    "    \"target_page_title\",\n",
    "    \"target_page_views\",\n",
    "    \"anchor_target_count\"]]\n",
    "\n",
    "# Display preview\n",
    "anchor_text.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>norm_anchor_text</th>\n",
       "      <th>target_page_id</th>\n",
       "      <th>target_item_id</th>\n",
       "      <th>target_page_title</th>\n",
       "      <th>target_page_views</th>\n",
       "      <th>anchor_target_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>united states</td>\n",
       "      <td>496626</td>\n",
       "      <td>2416331</td>\n",
       "      <td>Forbes_400</td>\n",
       "      <td>3790</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15041</th>\n",
       "      <td>united states</td>\n",
       "      <td>320247</td>\n",
       "      <td>482421</td>\n",
       "      <td>United_States_Army_Special_Forces</td>\n",
       "      <td>26292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28490</th>\n",
       "      <td>united states</td>\n",
       "      <td>2175</td>\n",
       "      <td>40578</td>\n",
       "      <td>American_cuisine</td>\n",
       "      <td>7398</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29141</th>\n",
       "      <td>united states</td>\n",
       "      <td>3434750</td>\n",
       "      <td>30</td>\n",
       "      <td>United_States</td>\n",
       "      <td>460156</td>\n",
       "      <td>152456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29254</th>\n",
       "      <td>united states</td>\n",
       "      <td>19792942</td>\n",
       "      <td>846570</td>\n",
       "      <td>Americans</td>\n",
       "      <td>14146</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14020894</th>\n",
       "      <td>united states</td>\n",
       "      <td>61098676</td>\n",
       "      <td>65049959</td>\n",
       "      <td>United_States_at_the_2020_Summer_Paralympics</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14020896</th>\n",
       "      <td>united states</td>\n",
       "      <td>61115649</td>\n",
       "      <td>65050638</td>\n",
       "      <td>United_States_men's_national_3x3_team</td>\n",
       "      <td>145</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14020899</th>\n",
       "      <td>united states</td>\n",
       "      <td>62050037</td>\n",
       "      <td>85814603</td>\n",
       "      <td>Water_polo_in_the_United_States</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14020901</th>\n",
       "      <td>united states</td>\n",
       "      <td>62548724</td>\n",
       "      <td>85812126</td>\n",
       "      <td>United_States_at_the_2019_Winter_Deaflympics</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14020902</th>\n",
       "      <td>united states</td>\n",
       "      <td>62602499</td>\n",
       "      <td>85812214</td>\n",
       "      <td>United_States_women's_national_wheelchair_bask...</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1067 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         norm_anchor_text  target_page_id  target_item_id  \\\n",
       "6995        united states          496626         2416331   \n",
       "15041       united states          320247          482421   \n",
       "28490       united states            2175           40578   \n",
       "29141       united states         3434750              30   \n",
       "29254       united states        19792942          846570   \n",
       "...                   ...             ...             ...   \n",
       "14020894    united states        61098676        65049959   \n",
       "14020896    united states        61115649        65050638   \n",
       "14020899    united states        62050037        85814603   \n",
       "14020901    united states        62548724        85812126   \n",
       "14020902    united states        62602499        85812214   \n",
       "\n",
       "                                          target_page_title  \\\n",
       "6995                                             Forbes_400   \n",
       "15041                     United_States_Army_Special_Forces   \n",
       "28490                                      American_cuisine   \n",
       "29141                                         United_States   \n",
       "29254                                             Americans   \n",
       "...                                                     ...   \n",
       "14020894       United_States_at_the_2020_Summer_Paralympics   \n",
       "14020896              United_States_men's_national_3x3_team   \n",
       "14020899                    Water_polo_in_the_United_States   \n",
       "14020901       United_States_at_the_2019_Winter_Deaflympics   \n",
       "14020902  United_States_women's_national_wheelchair_bask...   \n",
       "\n",
       "          target_page_views  anchor_target_count  \n",
       "6995                   3790                    1  \n",
       "15041                 26292                    1  \n",
       "28490                  7398                   13  \n",
       "29141                460156               152456  \n",
       "29254                 14146                   15  \n",
       "...                     ...                  ...  \n",
       "14020894                 33                    1  \n",
       "14020896                145                    2  \n",
       "14020899                101                    2  \n",
       "14020901                  5                    1  \n",
       "14020902                 30                    2  \n",
       "\n",
       "[1067 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display filtered example\n",
    "anchor_text[anchor_text['norm_anchor_text'] == 'united states']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Prior Confidence\n",
    "\n",
    "To create a confidence score that can serve as a prior, we calculate, for every anchor text, the percentage of values that each frequency or popularity link constituted of all links for that anchor text. If an anchor text to page link scores high in this, it means the page is a very frequent link or very popular, both good indicators that the link is likely strong and thus true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Load with priors so you don't need to re-run the hour each time\n",
    "\n",
    "# # Base path to input\n",
    "# preds_path = '../../predictions/'\n",
    "\n",
    "# # Save candidate pools dataframe\n",
    "# anchor_text = pd.read_csv(os.path.join(preds_path, \"anchortext_with_priors.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.4 s, sys: 3.26 s, total: 1min\n",
      "Wall time: 1min 2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>norm_anchor_text</th>\n",
       "      <th>anchor_target_count</th>\n",
       "      <th>target_page_views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10552160</th>\n",
       "      <td>united states</td>\n",
       "      <td>160780</td>\n",
       "      <td>8572980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         norm_anchor_text  anchor_target_count  target_page_views\n",
       "10552160    united states               160780            8572980"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Calculate frequency and popularity as percentage of total\n",
    "anchor_text_totals = anchor_text.groupby('norm_anchor_text', as_index=False).agg({\n",
    "    'anchor_target_count': sum,\n",
    "    'target_page_views': sum\n",
    "})\n",
    "anchor_text_totals[anchor_text_totals['norm_anchor_text'] == 'united states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11327029/11327029 [29:15<00:00, 6451.74it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26min 32s, sys: 1min 23s, total: 27min 55s\n",
      "Wall time: 29min 15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Save values as dictionary to speed up downstream processing\n",
    "totals_dict = {}\n",
    "for i in tqdm(range(len(anchor_text_totals))):\n",
    "    row = anchor_text_totals.loc[i]\n",
    "    totals_dict[row['norm_anchor_text']] = (row['anchor_target_count'], row['target_page_views'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3859/14431024 [00:02<3:01:58, 1321.33it/s]/Users/wseaton/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \n",
      "100%|██████████| 14431024/14431024 [1:56:09<00:00, 2070.47it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56min 49s, sys: 17min 19s, total: 1h 14min 9s\n",
      "Wall time: 1h 56min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Calculate individual link prior as \"confidence\"\n",
    "list_prior_freq = []\n",
    "list_prior_pop = []\n",
    "\n",
    "for i in tqdm(range(len(anchor_text))):\n",
    "    row = anchor_text.loc[i]\n",
    "    prior_freq = round(row['anchor_target_count'] / totals_dict[row['norm_anchor_text']][0], 7)\n",
    "    prior_pop = round(row['target_page_views'] / totals_dict[row['norm_anchor_text']][1], 7)\n",
    "    \n",
    "    list_prior_freq.append(prior_freq)\n",
    "    list_prior_pop.append(prior_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save prior to dataframe\n",
    "anchor_text['prior_target_count'] = list_prior_freq\n",
    "anchor_text['prior_page_views'] = list_prior_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>norm_anchor_text</th>\n",
       "      <th>target_page_id</th>\n",
       "      <th>target_item_id</th>\n",
       "      <th>target_page_title</th>\n",
       "      <th>target_page_views</th>\n",
       "      <th>anchor_target_count</th>\n",
       "      <th>prior_target_count</th>\n",
       "      <th>prior_page_views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>477081</td>\n",
       "      <td>11199</td>\n",
       "      <td>Underscore</td>\n",
       "      <td>8857</td>\n",
       "      <td>2</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.946665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(underscore)</td>\n",
       "      <td>477081</td>\n",
       "      <td>11199</td>\n",
       "      <td>Underscore</td>\n",
       "      <td>8857</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>underline mark</td>\n",
       "      <td>477081</td>\n",
       "      <td>11199</td>\n",
       "      <td>Underscore</td>\n",
       "      <td>8857</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>underscore</td>\n",
       "      <td>477081</td>\n",
       "      <td>11199</td>\n",
       "      <td>Underscore</td>\n",
       "      <td>8857</td>\n",
       "      <td>68</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.466674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>underscore ( )</td>\n",
       "      <td>477081</td>\n",
       "      <td>11199</td>\n",
       "      <td>Underscore</td>\n",
       "      <td>8857</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>underscores</td>\n",
       "      <td>477081</td>\n",
       "      <td>11199</td>\n",
       "      <td>Underscore</td>\n",
       "      <td>8857</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.968507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>51968092</td>\n",
       "      <td>27536732</td>\n",
       "      <td>(album)</td>\n",
       "      <td>499</td>\n",
       "      <td>6</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.053335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(album)</td>\n",
       "      <td>51968092</td>\n",
       "      <td>27536732</td>\n",
       "      <td>(album)</td>\n",
       "      <td>499</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>builtin popcount</td>\n",
       "      <td>1127884</td>\n",
       "      <td>5645805</td>\n",
       "      <td>Hamming_weight</td>\n",
       "      <td>3363</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>available in only some high-level languages</td>\n",
       "      <td>1127884</td>\n",
       "      <td>5645805</td>\n",
       "      <td>Hamming_weight</td>\n",
       "      <td>3363</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              norm_anchor_text  target_page_id  \\\n",
       "0                                                       477081   \n",
       "1                                 (underscore)          477081   \n",
       "2                               underline mark          477081   \n",
       "3                                   underscore          477081   \n",
       "4                               underscore ( )          477081   \n",
       "5                                  underscores          477081   \n",
       "6                                                     51968092   \n",
       "7                                      (album)        51968092   \n",
       "8                             builtin popcount         1127884   \n",
       "9  available in only some high-level languages         1127884   \n",
       "\n",
       "   target_item_id target_page_title  target_page_views  anchor_target_count  \\\n",
       "0           11199        Underscore               8857                    2   \n",
       "1           11199        Underscore               8857                    1   \n",
       "2           11199        Underscore               8857                    1   \n",
       "3           11199        Underscore               8857                   68   \n",
       "4           11199        Underscore               8857                    1   \n",
       "5           11199        Underscore               8857                    3   \n",
       "6        27536732           (album)                499                    6   \n",
       "7        27536732           (album)                499                    1   \n",
       "8         5645805    Hamming_weight               3363                    1   \n",
       "9         5645805    Hamming_weight               3363                    1   \n",
       "\n",
       "   prior_target_count  prior_page_views  \n",
       "0            0.250000          0.946665  \n",
       "1            1.000000          1.000000  \n",
       "2            1.000000          1.000000  \n",
       "3            0.819277          0.466674  \n",
       "4            1.000000          1.000000  \n",
       "5            0.750000          0.968507  \n",
       "6            0.750000          0.053335  \n",
       "7            1.000000          1.000000  \n",
       "8            1.000000          1.000000  \n",
       "9            1.000000          1.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview dataframe\n",
    "anchor_text.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>norm_anchor_text</th>\n",
       "      <th>target_page_id</th>\n",
       "      <th>target_item_id</th>\n",
       "      <th>target_page_title</th>\n",
       "      <th>target_page_views</th>\n",
       "      <th>anchor_target_count</th>\n",
       "      <th>prior_target_count</th>\n",
       "      <th>prior_page_views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>united states</td>\n",
       "      <td>496626</td>\n",
       "      <td>2416331</td>\n",
       "      <td>Forbes_400</td>\n",
       "      <td>3790</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15041</th>\n",
       "      <td>united states</td>\n",
       "      <td>320247</td>\n",
       "      <td>482421</td>\n",
       "      <td>United_States_Army_Special_Forces</td>\n",
       "      <td>26292</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.003067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28490</th>\n",
       "      <td>united states</td>\n",
       "      <td>2175</td>\n",
       "      <td>40578</td>\n",
       "      <td>American_cuisine</td>\n",
       "      <td>7398</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29141</th>\n",
       "      <td>united states</td>\n",
       "      <td>3434750</td>\n",
       "      <td>30</td>\n",
       "      <td>United_States</td>\n",
       "      <td>460156</td>\n",
       "      <td>152456</td>\n",
       "      <td>0.948227</td>\n",
       "      <td>0.053675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29254</th>\n",
       "      <td>united states</td>\n",
       "      <td>19792942</td>\n",
       "      <td>846570</td>\n",
       "      <td>Americans</td>\n",
       "      <td>14146</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.001650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30113</th>\n",
       "      <td>united states</td>\n",
       "      <td>3058522</td>\n",
       "      <td>3021105</td>\n",
       "      <td>Race_and_ethnicity_in_the_United_States</td>\n",
       "      <td>91352</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.010656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38855</th>\n",
       "      <td>united states</td>\n",
       "      <td>4567589</td>\n",
       "      <td>7892316</td>\n",
       "      <td>United_States_and_the_International_Criminal_C...</td>\n",
       "      <td>2184</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57494</th>\n",
       "      <td>united states</td>\n",
       "      <td>1974940</td>\n",
       "      <td>2630384</td>\n",
       "      <td>Beauty_and_the_Geek</td>\n",
       "      <td>2355</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62363</th>\n",
       "      <td>united states</td>\n",
       "      <td>27007275</td>\n",
       "      <td>1102213</td>\n",
       "      <td>Eugenics_in_the_United_States</td>\n",
       "      <td>7599</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68476</th>\n",
       "      <td>united states</td>\n",
       "      <td>423161</td>\n",
       "      <td>180072</td>\n",
       "      <td>Billboard_Hot_100</td>\n",
       "      <td>49494</td>\n",
       "      <td>31</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.005773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      norm_anchor_text  target_page_id  target_item_id  \\\n",
       "6995     united states          496626         2416331   \n",
       "15041    united states          320247          482421   \n",
       "28490    united states            2175           40578   \n",
       "29141    united states         3434750              30   \n",
       "29254    united states        19792942          846570   \n",
       "30113    united states         3058522         3021105   \n",
       "38855    united states         4567589         7892316   \n",
       "57494    united states         1974940         2630384   \n",
       "62363    united states        27007275         1102213   \n",
       "68476    united states          423161          180072   \n",
       "\n",
       "                                       target_page_title  target_page_views  \\\n",
       "6995                                          Forbes_400               3790   \n",
       "15041                  United_States_Army_Special_Forces              26292   \n",
       "28490                                   American_cuisine               7398   \n",
       "29141                                      United_States             460156   \n",
       "29254                                          Americans              14146   \n",
       "30113            Race_and_ethnicity_in_the_United_States              91352   \n",
       "38855  United_States_and_the_International_Criminal_C...               2184   \n",
       "57494                                Beauty_and_the_Geek               2355   \n",
       "62363                      Eugenics_in_the_United_States               7599   \n",
       "68476                                  Billboard_Hot_100              49494   \n",
       "\n",
       "       anchor_target_count  prior_target_count  prior_page_views  \n",
       "6995                     1            0.000006          0.000442  \n",
       "15041                    1            0.000006          0.003067  \n",
       "28490                   13            0.000081          0.000863  \n",
       "29141               152456            0.948227          0.053675  \n",
       "29254                   15            0.000093          0.001650  \n",
       "30113                    2            0.000012          0.010656  \n",
       "38855                    1            0.000006          0.000255  \n",
       "57494                    1            0.000006          0.000275  \n",
       "62363                    4            0.000025          0.000886  \n",
       "68476                   31            0.000193          0.005773  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview single anchor text in dataframe\n",
    "anchor_text[anchor_text['norm_anchor_text'] == 'united states'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save with priors so you don't need to re-run the hour each time\n",
    "\n",
    "# Base path to input\n",
    "preds_path = '../../predictions/'\n",
    "\n",
    "# Save candidate pools dataframe\n",
    "anchor_text.to_csv(os.path.join(preds_path, \"anchortext_with_priors.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Candidate Pools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchor Link Frequency\n",
    "\n",
    "This model generates a candidate pool of Wikipedia pages for each full mention by looking at the pages that anchor string links to the most number of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 15s, sys: 22.9 s, total: 1min 38s\n",
      "Wall time: 1min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Sort dataframe by anchor text and then most frequently linked page\n",
    "anchor_text = anchor_text.sort_values(['norm_anchor_text', 'anchor_target_count'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 3s, sys: 30.2 s, total: 1min 33s\n",
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Return just the top N most linked entities to create our candidate pool for each anchor link\n",
    "# Testing shows that 5-10 candidates is the most effective range for downstream congruence impact\n",
    "top_N = 5\n",
    "anchor_text_link_frequency = anchor_text.groupby('norm_anchor_text').head(top_N).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>norm_anchor_text</th>\n",
       "      <th>target_page_id</th>\n",
       "      <th>target_item_id</th>\n",
       "      <th>target_page_title</th>\n",
       "      <th>target_page_views</th>\n",
       "      <th>anchor_target_count</th>\n",
       "      <th>prior_target_count</th>\n",
       "      <th>prior_page_views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>882966</th>\n",
       "      <td>united states</td>\n",
       "      <td>3434750</td>\n",
       "      <td>30</td>\n",
       "      <td>United_States</td>\n",
       "      <td>460156</td>\n",
       "      <td>152456</td>\n",
       "      <td>0.948227</td>\n",
       "      <td>0.053675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882967</th>\n",
       "      <td>united states</td>\n",
       "      <td>582488</td>\n",
       "      <td>164134</td>\n",
       "      <td>United_States_men's_national_soccer_team</td>\n",
       "      <td>25804</td>\n",
       "      <td>1466</td>\n",
       "      <td>0.009118</td>\n",
       "      <td>0.003010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882968</th>\n",
       "      <td>united states</td>\n",
       "      <td>647757</td>\n",
       "      <td>334526</td>\n",
       "      <td>United_States_women's_national_soccer_team</td>\n",
       "      <td>12292</td>\n",
       "      <td>594</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.001434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882969</th>\n",
       "      <td>united states</td>\n",
       "      <td>1145226</td>\n",
       "      <td>1143805</td>\n",
       "      <td>United_States_national_rugby_union_team</td>\n",
       "      <td>1165</td>\n",
       "      <td>352</td>\n",
       "      <td>0.002189</td>\n",
       "      <td>0.000136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882970</th>\n",
       "      <td>united states</td>\n",
       "      <td>945923</td>\n",
       "      <td>913651</td>\n",
       "      <td>United_States_men's_national_ice_hockey_team</td>\n",
       "      <td>2537</td>\n",
       "      <td>257</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.000296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       norm_anchor_text  target_page_id  target_item_id  \\\n",
       "882966    united states         3434750              30   \n",
       "882967    united states          582488          164134   \n",
       "882968    united states          647757          334526   \n",
       "882969    united states         1145226         1143805   \n",
       "882970    united states          945923          913651   \n",
       "\n",
       "                                   target_page_title  target_page_views  \\\n",
       "882966                                 United_States             460156   \n",
       "882967      United_States_men's_national_soccer_team              25804   \n",
       "882968    United_States_women's_national_soccer_team              12292   \n",
       "882969       United_States_national_rugby_union_team               1165   \n",
       "882970  United_States_men's_national_ice_hockey_team               2537   \n",
       "\n",
       "        anchor_target_count  prior_target_count  prior_page_views  \n",
       "882966               152456            0.948227          0.053675  \n",
       "882967                 1466            0.009118          0.003010  \n",
       "882968                  594            0.003694          0.001434  \n",
       "882969                  352            0.002189          0.000136  \n",
       "882970                  257            0.001599          0.000296  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually preview 'united states'\n",
    "anchor_text_link_frequency[anchor_text_link_frequency['norm_anchor_text'] == 'united states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique anchor links numbered 14,431,024\n",
      "Remaining dataframe contains 12,906,013 rows\n"
     ]
    }
   ],
   "source": [
    "# Assess remaining rows\n",
    "print(\"Unique anchor links numbered {:,}\".format(len(anchor_text)))\n",
    "print(\"Remaining dataframe contains {:,} rows\".format(len(anchor_text_link_frequency)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did not reduce the dataframe by much, suggesting only a few anchor texts have more than our selected N number of distinct links. To append to our ACY Input data, we produce a dictionary of anchor text to its candidate pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In case of prior road, load saved json file before re-running the whole thing\n",
    "# # Load dictionary\n",
    "# with open('../../predictions/dict_anchor_pool_frequency.json', 'r') as filepath:\n",
    "#     dict_anchor_pool_frequency = json.load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 6s, sys: 4min 46s, total: 21min 53s\n",
      "Wall time: 27min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Group by anchor text to produce list of item IDs, page IDs and page titles (our candidate pools)\n",
    "anchor_text_candidate_pools = anchor_text_link_frequency.groupby('norm_anchor_text')\\\n",
    "                                    [['target_page_id',\n",
    "                                      'target_page_title',\n",
    "                                      'target_item_id',\n",
    "                                      'prior_target_count']]\\\n",
    "                                    .agg(lambda x: list(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11327029/11327029 [51:14<00:00, 3684.50it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25min 47s, sys: 7min 50s, total: 33min 37s\n",
      "Wall time: 51min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Add to dictionary for faster searching later in the pipeline\n",
    "\n",
    "# Create dictionary\n",
    "dict_anchor_pool_frequency = {}\n",
    "\n",
    "# Add lists to dictionary with anchor text as search term\n",
    "# This should match the full mention search when measuring accuracy later\n",
    "for i in tqdm(range(len(anchor_text_candidate_pools))):\n",
    "    row = anchor_text_candidate_pools.loc[i]\n",
    "    dict_anchor_pool_frequency[row['norm_anchor_text']] = [row['target_page_id'],\n",
    "                                                           row['target_page_title'],\n",
    "                                                           row['target_item_id'],\n",
    "                                                           row['prior_target_count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demonstrate search performance boost of dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 µs, sys: 145 µs, total: 155 µs\n",
      "Wall time: 479 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Demonstrate search benefit of storing as dictionary\n",
    "o = dict_anchor_pool_frequency['united states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.5 s, sys: 1min 21s, total: 1min 32s\n",
      "Wall time: 3min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Compare Pandas dataframe search to dictionary search\n",
    "o = anchor_text_candidate_pools[anchor_text_candidate_pools['norm_anchor_text'] == 'united states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dictionary\n",
    "with open('../../predictions/dict_anchor_pool_frequency.json', 'w') as filepath:\n",
    "    json.dump(dict_anchor_pool_frequency, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchor Link Popularity\n",
    "\n",
    "This model generates a candidate pool of Wikipedia pages for each full mention by looking at the popularity of pages that string has linked to and sorting by the pages with the most views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 24s, sys: 1min 22s, total: 2min 47s\n",
      "Wall time: 4min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Sort dataframe by anchor text and then most frequently linked page\n",
    "anchor_text = anchor_text.sort_values(['norm_anchor_text', 'target_page_views'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 6s, sys: 27.6 s, total: 1min 33s\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Return just the top N most viewed entities to create our candidate pool for each anchor link\n",
    "top_N = 5\n",
    "anchor_text_link_popularity = anchor_text.groupby('norm_anchor_text').head(top_N).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>norm_anchor_text</th>\n",
       "      <th>target_page_id</th>\n",
       "      <th>target_item_id</th>\n",
       "      <th>target_page_title</th>\n",
       "      <th>target_page_views</th>\n",
       "      <th>anchor_target_count</th>\n",
       "      <th>prior_target_count</th>\n",
       "      <th>prior_page_views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>882966</th>\n",
       "      <td>united states</td>\n",
       "      <td>3434750</td>\n",
       "      <td>30</td>\n",
       "      <td>United_States</td>\n",
       "      <td>460156</td>\n",
       "      <td>152456</td>\n",
       "      <td>0.948227</td>\n",
       "      <td>0.053675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882967</th>\n",
       "      <td>united states</td>\n",
       "      <td>63136490</td>\n",
       "      <td>83873577</td>\n",
       "      <td>COVID-19_pandemic_in_the_United_States</td>\n",
       "      <td>428030</td>\n",
       "      <td>31</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.049928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882968</th>\n",
       "      <td>united states</td>\n",
       "      <td>58993617</td>\n",
       "      <td>41174436</td>\n",
       "      <td>2020_Formula_One_World_Championship</td>\n",
       "      <td>343066</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.040017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882969</th>\n",
       "      <td>united states</td>\n",
       "      <td>44751865</td>\n",
       "      <td>19600530</td>\n",
       "      <td>Black_Lives_Matter</td>\n",
       "      <td>250974</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.029275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882970</th>\n",
       "      <td>united states</td>\n",
       "      <td>12610470</td>\n",
       "      <td>1682357</td>\n",
       "      <td>List_of_states_and_territories_of_the_United_S...</td>\n",
       "      <td>185044</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.021585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       norm_anchor_text  target_page_id  target_item_id  \\\n",
       "882966    united states         3434750              30   \n",
       "882967    united states        63136490        83873577   \n",
       "882968    united states        58993617        41174436   \n",
       "882969    united states        44751865        19600530   \n",
       "882970    united states        12610470         1682357   \n",
       "\n",
       "                                        target_page_title  target_page_views  \\\n",
       "882966                                      United_States             460156   \n",
       "882967             COVID-19_pandemic_in_the_United_States             428030   \n",
       "882968                2020_Formula_One_World_Championship             343066   \n",
       "882969                                 Black_Lives_Matter             250974   \n",
       "882970  List_of_states_and_territories_of_the_United_S...             185044   \n",
       "\n",
       "        anchor_target_count  prior_target_count  prior_page_views  \n",
       "882966               152456            0.948227          0.053675  \n",
       "882967                   31            0.000193          0.049928  \n",
       "882968                    1            0.000006          0.040017  \n",
       "882969                    1            0.000006          0.029275  \n",
       "882970                    1            0.000006          0.021585  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually test United States to assess resulting dataframe\n",
    "anchor_text_link_popularity[anchor_text_link_popularity['norm_anchor_text'] == 'united states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique anchor links numbered 14,431,024\n",
      "Remaining dataframe contains 12,906,013 rows\n"
     ]
    }
   ],
   "source": [
    "# Assess remaining rows\n",
    "print(\"Unique anchor links numbered {:,}\".format(len(anchor_text)))\n",
    "print(\"Remaining dataframe contains {:,} rows\".format(len(anchor_text_link_popularity)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In case of prior road, load saved json file before re-running the whole thing\n",
    "# # Load dictionary\n",
    "# with open('../../predictions/dict_anchor_pool_popularity.json', 'r') as filepath:\n",
    "#     dict_anchor_pool_popularity = json.load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 9s, sys: 11min 24s, total: 27min 33s\n",
      "Wall time: 51min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Group by anchor text to produce list of item IDs, page IDs and page titles (our candidate pools)\n",
    "anchor_text_candidate_pools = anchor_text_link_popularity.groupby('norm_anchor_text')\\\n",
    "                                    [['target_page_id',\n",
    "                                      'target_page_title',\n",
    "                                      'target_item_id',\n",
    "                                      'prior_page_views']]\\\n",
    "                                    .agg(lambda x: list(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11327029/11327029 [59:40<00:00, 3163.31it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24min 40s, sys: 10min 24s, total: 35min 4s\n",
      "Wall time: 59min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Add to dictionary for faster searching later in the pipeline\n",
    "\n",
    "# Create dictionary\n",
    "dict_anchor_pool_popularity = {}\n",
    "\n",
    "# Add lists to dictionary with anchor text as search term\n",
    "# This should match the full mention search when measuring accuracy later\n",
    "for i in tqdm(range(len(anchor_text_candidate_pools))):\n",
    "    row = anchor_text_candidate_pools.loc[i]\n",
    "    dict_anchor_pool_popularity[row['norm_anchor_text']] = [row['target_page_id'],\n",
    "                                                           row['target_page_title'],\n",
    "                                                           row['target_item_id'],\n",
    "                                                           row['prior_page_views']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dictionary\n",
    "with open('../../predictions/dict_anchor_pool_popularity.json', 'w') as filepath:\n",
    "    json.dump(dict_anchor_pool_popularity, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess Accuracy of Anchor Link Models without Congruence\n",
    "\n",
    "For each full mention in our ACY input dataset, we now append the generated candidate pool as a column and save our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize full mentions for direct comparison with normalized anchor texts\n",
    "acy_input['norm_full_mention'] = acy_input['full_mention'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchor Link Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy input dataframe\n",
    "preds_anchor_frequency = acy_input.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21810/21810 [00:14<00:00, 1512.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# For each full mention, retrieve the candidate pool generated by the model\n",
    "candidate_pools_page_ids = []\n",
    "candidate_pools_item_ids = []\n",
    "candidate_pools_titles = []\n",
    "candidate_pools_priors = []\n",
    "\n",
    "# Track metrics\n",
    "oov_error = 0\n",
    "\n",
    "for i in tqdm(range(len(acy_input))):\n",
    "    \n",
    "    # Retrieve normalized full mention\n",
    "    full_mention = acy_input['norm_full_mention'][i]\n",
    "    \n",
    "    # Retrieve candidate pools for full mention\n",
    "    try:\n",
    "        dicts = dict_anchor_pool_frequency[full_mention]\n",
    "    except KeyError:\n",
    "        oov_error += 1\n",
    "        dicts = (None, None, None, None)\n",
    "        \n",
    "    candidate_pool_page_ids = dicts[0]\n",
    "    candidate_pool_titles = dicts[1]\n",
    "    candidate_pool_item_ids = dicts[2]\n",
    "    candidate_pool_priors = dicts[3]\n",
    "    \n",
    "    # Save candidate pools\n",
    "    candidate_pools_page_ids.append(candidate_pool_page_ids)\n",
    "    candidate_pools_item_ids.append(candidate_pool_item_ids)\n",
    "    candidate_pools_titles.append(candidate_pool_titles)\n",
    "    candidate_pools_priors.append(candidate_pool_priors)\n",
    "    \n",
    "preds_anchor_frequency['candidate_pool_page_ids'] = candidate_pools_page_ids\n",
    "preds_anchor_frequency['candidate_pool_item_ids'] = candidate_pools_item_ids\n",
    "preds_anchor_frequency['candidate_pool_titles'] = candidate_pools_titles\n",
    "preds_anchor_frequency['candidate_pool_priors'] = candidate_pools_priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We received 3,782 Out-of-Vocabulary Errors.\n"
     ]
    }
   ],
   "source": [
    "print(f\"We received {oov_error:,} Out-of-Vocabulary Errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Out-of-Vocabulary Error means that we have a full mention that does not exist as an anchor link string in our anchor link statistics dataframe. This can result from differing dates of dataset creation between ACY and Anchor Link Statistics or as a result of the natural progression of language to develop new terms and phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>full_mention</th>\n",
       "      <th>wikipedia_URL</th>\n",
       "      <th>wikipedia_page_ID</th>\n",
       "      <th>wikipedia_title</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>congruent_mentions</th>\n",
       "      <th>norm_full_mention</th>\n",
       "      <th>candidate_pool_page_ids</th>\n",
       "      <th>candidate_pool_item_ids</th>\n",
       "      <th>candidate_pool_titles</th>\n",
       "      <th>candidate_pool_priors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>EU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>eu</td>\n",
       "      <td>[9317, 9239, 21347120, 9477, 1882861]</td>\n",
       "      <td>[458, 46, 211593, 1396, 363404]</td>\n",
       "      <td>[European_Union, Europe, Eu,_Seine-Maritime, E...</td>\n",
       "      <td>[0.9227799, 0.024651, 0.020196, 0.005346, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>German</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Germany</td>\n",
       "      <td>11867.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>german</td>\n",
       "      <td>[11867, 11884, 152735, 21212, 12674]</td>\n",
       "      <td>[183, 188, 42884, 7318, 43287]</td>\n",
       "      <td>[Germany, German_language, Germans, Nazi_Germa...</td>\n",
       "      <td>[0.4192066, 0.2893363, 0.1470461, 0.03832, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>British</td>\n",
       "      <td>http://en.wikipedia.org/wiki/United_Kingdom</td>\n",
       "      <td>31717.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>british</td>\n",
       "      <td>[31717, 19097669, 13530298, 4721, 158019]</td>\n",
       "      <td>[145, 842438, 23666, 8680, 161885]</td>\n",
       "      <td>[United_Kingdom, British_people, Great_Britain...</td>\n",
       "      <td>[0.6101256, 0.1146913, 0.0681775, 0.0366451, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mention full_mention                                wikipedia_URL  \\\n",
       "0       B           EU                                          NaN   \n",
       "1       B       German         http://en.wikipedia.org/wiki/Germany   \n",
       "2       B      British  http://en.wikipedia.org/wiki/United_Kingdom   \n",
       "\n",
       "   wikipedia_page_ID wikipedia_title  sentence_id  doc_id  \\\n",
       "0                NaN             NaN            0       0   \n",
       "1            11867.0         Germany            0       0   \n",
       "2            31717.0  United Kingdom            0       0   \n",
       "\n",
       "            congruent_mentions norm_full_mention  \\\n",
       "0  ['EU', 'German', 'British']                eu   \n",
       "1  ['EU', 'German', 'British']            german   \n",
       "2  ['EU', 'German', 'British']           british   \n",
       "\n",
       "                     candidate_pool_page_ids  \\\n",
       "0      [9317, 9239, 21347120, 9477, 1882861]   \n",
       "1       [11867, 11884, 152735, 21212, 12674]   \n",
       "2  [31717, 19097669, 13530298, 4721, 158019]   \n",
       "\n",
       "              candidate_pool_item_ids  \\\n",
       "0     [458, 46, 211593, 1396, 363404]   \n",
       "1      [183, 188, 42884, 7318, 43287]   \n",
       "2  [145, 842438, 23666, 8680, 161885]   \n",
       "\n",
       "                               candidate_pool_titles  \\\n",
       "0  [European_Union, Europe, Eu,_Seine-Maritime, E...   \n",
       "1  [Germany, German_language, Germans, Nazi_Germa...   \n",
       "2  [United_Kingdom, British_people, Great_Britain...   \n",
       "\n",
       "                               candidate_pool_priors  \n",
       "0  [0.9227799, 0.024651, 0.020196, 0.005346, 0.00...  \n",
       "1  [0.4192066, 0.2893363, 0.1470461, 0.03832, 0.0...  \n",
       "2  [0.6101256, 0.1146913, 0.0681775, 0.0366451, 0...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview dataframe\n",
    "preds_anchor_frequency.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************\n",
      "Overall Predictive Accuracy: 52.572%\n",
      "****************************\n"
     ]
    }
   ],
   "source": [
    "# Calculate overall accuracy with no intelligent filtering applied yet\n",
    "accurate_predictions = 0\n",
    "for i in range(len(preds_anchor_frequency)):\n",
    "    try:\n",
    "        if preds_anchor_frequency['wikipedia_page_ID'][i] == preds_anchor_frequency['candidate_pool_page_ids'][i][0]:\n",
    "            accurate_predictions += 1\n",
    "    except TypeError:\n",
    "        pass\n",
    "print(\"****************************\")\n",
    "print(f\"Overall Predictive Accuracy: {round(accurate_predictions / len(preds_anchor_frequency) * 100, 3)}%\")\n",
    "print(\"****************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answer is present in 65.878% of generated candidate pools via Anchor Links Frequency method.\n"
     ]
    }
   ],
   "source": [
    "# Calculate percentage of candidate pools with the correct answer present\n",
    "# Necessary to determine if shuffling pool with congruence could even get the right answer\n",
    "response_present = 0\n",
    "for i in range(len(preds_anchor_frequency)):\n",
    "    try:\n",
    "        if preds_anchor_frequency['wikipedia_page_ID'][i] in preds_anchor_frequency['candidate_pool_page_ids'][i]:\n",
    "            response_present += 1\n",
    "    except TypeError:\n",
    "        pass\n",
    "print(f\"Correct answer is present in {round(response_present / len(preds_anchor_frequency) * 100, 3)}% of generated candidate pools via Anchor Links Frequency method.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confirm Accuracy Only for Full Mentions with True Positives\n",
    "\n",
    "We have standardized on comparing accuracy across model types for only true mentions with a known positive response value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************\n",
      "Predictive Accuracy: 72.032%\n",
      "****************************\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy only for known true values\n",
    "accurate_predictions = 0\n",
    "preds_frequency_nonulls = preds_anchor_frequency[preds_anchor_frequency['wikipedia_page_ID'].notnull()].reset_index()\n",
    "for i in range(len(preds_frequency_nonulls)):\n",
    "    try:\n",
    "        if preds_frequency_nonulls['wikipedia_page_ID'][i] == preds_frequency_nonulls['candidate_pool_page_ids'][i][0]:\n",
    "            accurate_predictions += 1\n",
    "    except TypeError:\n",
    "        pass\n",
    "print(\"****************************\")\n",
    "print(f\"Predictive Accuracy: {round(accurate_predictions / len(preds_frequency_nonulls) * 100, 3)}%\")\n",
    "print(\"****************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answer is present in 90.263% of generated candidate pools via Anchor Links Frequency method.\n"
     ]
    }
   ],
   "source": [
    "# Calculate percentage of candidate pools with the correct answer present for known true values\n",
    "# Necessary to determine if shuffling pool could even get the right answer\n",
    "response_present = 0\n",
    "for i in range(len(preds_frequency_nonulls)):\n",
    "    try:\n",
    "        if preds_frequency_nonulls['wikipedia_page_ID'][i] in preds_frequency_nonulls['candidate_pool_page_ids'][i]:\n",
    "            response_present += 1\n",
    "    except TypeError:\n",
    "        pass\n",
    "print(f\"Correct answer is present in {round(response_present / len(preds_frequency_nonulls) * 100, 3)}% of generated candidate pools via Anchor Links Frequency method.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base path to input\n",
    "preds_path = '../../predictions/'\n",
    "\n",
    "# Save candidate pools dataframe\n",
    "preds_anchor_frequency.to_csv(os.path.join(preds_path, \"anchortext_frequency.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchor Link Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy input dataframe\n",
    "preds_anchor_popularity = acy_input.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21810/21810 [00:08<00:00, 2680.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# For each full mention, retrieve the candidate pool generated by the model\n",
    "candidate_pools_page_ids = []\n",
    "candidate_pools_item_ids = []\n",
    "candidate_pools_titles = []\n",
    "candidate_pools_priors = []\n",
    "\n",
    "# Track metrics\n",
    "oov_error = 0\n",
    "\n",
    "for i in tqdm(range(len(acy_input))):\n",
    "    \n",
    "    # Retrieve normalized full mention\n",
    "    full_mention = acy_input['norm_full_mention'][i]\n",
    "    \n",
    "    # Retrieve candidate pools for full mention\n",
    "    try:\n",
    "        dicts = dict_anchor_pool_popularity[full_mention]\n",
    "    except KeyError:\n",
    "        oov_error += 1\n",
    "        dicts = (None, None, None, None)\n",
    "        \n",
    "    candidate_pool_page_ids = dicts[0]\n",
    "    candidate_pool_titles = dicts[1]\n",
    "    candidate_pool_item_ids = dicts[2]\n",
    "    candidate_pool_priors = dicts[3]\n",
    "    \n",
    "    # Save candidate pools\n",
    "    candidate_pools_page_ids.append(candidate_pool_page_ids)\n",
    "    candidate_pools_item_ids.append(candidate_pool_item_ids)\n",
    "    candidate_pools_titles.append(candidate_pool_titles)\n",
    "    candidate_pools_priors.append(candidate_pool_priors)\n",
    "    \n",
    "preds_anchor_popularity['candidate_pool_page_ids'] = candidate_pools_page_ids\n",
    "preds_anchor_popularity['candidate_pool_item_ids'] = candidate_pools_item_ids\n",
    "preds_anchor_popularity['candidate_pool_titles'] = candidate_pools_titles\n",
    "preds_anchor_popularity['candidate_pool_priors'] = candidate_pools_priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We received 3,782 Out-of-Vocabulary Errors.\n"
     ]
    }
   ],
   "source": [
    "print(f\"We received {oov_error:,} Out-of-Vocabulary Errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>full_mention</th>\n",
       "      <th>wikipedia_URL</th>\n",
       "      <th>wikipedia_page_ID</th>\n",
       "      <th>wikipedia_title</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>congruent_mentions</th>\n",
       "      <th>norm_full_mention</th>\n",
       "      <th>candidate_pool_page_ids</th>\n",
       "      <th>candidate_pool_item_ids</th>\n",
       "      <th>candidate_pool_titles</th>\n",
       "      <th>candidate_pool_priors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>EU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>eu</td>\n",
       "      <td>[9317, 9239, 9891, 9472, 10890716]</td>\n",
       "      <td>[458, 46, 45003, 4916, 185441]</td>\n",
       "      <td>[European_Union, Europe, Entropy, Euro, Member...</td>\n",
       "      <td>[0.2245141, 0.2015168, 0.0965482, 0.0768826, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>German</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Germany</td>\n",
       "      <td>11867.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>german</td>\n",
       "      <td>[11867, 27318, 21148, 21212, 26964606]</td>\n",
       "      <td>[183, 334, 55, 7318, 40]</td>\n",
       "      <td>[Germany, Singapore, Netherlands, Nazi_Germany...</td>\n",
       "      <td>[0.0558084, 0.0548498, 0.044104, 0.0268639, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>British</td>\n",
       "      <td>http://en.wikipedia.org/wiki/United_Kingdom</td>\n",
       "      <td>31717.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>british</td>\n",
       "      <td>[3434750, 31717, 19344654, 26061, 8569916]</td>\n",
       "      <td>[30, 145, 9531, 172771, 1860]</td>\n",
       "      <td>[United_States, United_Kingdom, BBC, Royal_Nav...</td>\n",
       "      <td>[0.1243038, 0.0660245, 0.0317426, 0.0291264, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mention full_mention                                wikipedia_URL  \\\n",
       "0       B           EU                                          NaN   \n",
       "1       B       German         http://en.wikipedia.org/wiki/Germany   \n",
       "2       B      British  http://en.wikipedia.org/wiki/United_Kingdom   \n",
       "\n",
       "   wikipedia_page_ID wikipedia_title  sentence_id  doc_id  \\\n",
       "0                NaN             NaN            0       0   \n",
       "1            11867.0         Germany            0       0   \n",
       "2            31717.0  United Kingdom            0       0   \n",
       "\n",
       "            congruent_mentions norm_full_mention  \\\n",
       "0  ['EU', 'German', 'British']                eu   \n",
       "1  ['EU', 'German', 'British']            german   \n",
       "2  ['EU', 'German', 'British']           british   \n",
       "\n",
       "                      candidate_pool_page_ids         candidate_pool_item_ids  \\\n",
       "0          [9317, 9239, 9891, 9472, 10890716]  [458, 46, 45003, 4916, 185441]   \n",
       "1      [11867, 27318, 21148, 21212, 26964606]        [183, 334, 55, 7318, 40]   \n",
       "2  [3434750, 31717, 19344654, 26061, 8569916]   [30, 145, 9531, 172771, 1860]   \n",
       "\n",
       "                               candidate_pool_titles  \\\n",
       "0  [European_Union, Europe, Entropy, Euro, Member...   \n",
       "1  [Germany, Singapore, Netherlands, Nazi_Germany...   \n",
       "2  [United_States, United_Kingdom, BBC, Royal_Nav...   \n",
       "\n",
       "                               candidate_pool_priors  \n",
       "0  [0.2245141, 0.2015168, 0.0965482, 0.0768826, 0...  \n",
       "1  [0.0558084, 0.0548498, 0.044104, 0.0268639, 0....  \n",
       "2  [0.1243038, 0.0660245, 0.0317426, 0.0291264, 0...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview dataframe\n",
    "preds_anchor_popularity.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************\n",
      "Predictive Accuracy: 45.158%\n",
      "****************************\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accurate_predictions = 0\n",
    "for i in range(len(preds_anchor_popularity)):\n",
    "    try:\n",
    "        if preds_anchor_popularity['wikipedia_page_ID'][i] == preds_anchor_popularity['candidate_pool_page_ids'][i][0]:\n",
    "            accurate_predictions += 1\n",
    "    except TypeError:\n",
    "        pass\n",
    "print(\"****************************\")\n",
    "print(f\"Predictive Accuracy: {round(accurate_predictions / len(preds_anchor_popularity) * 100, 3)}%\")\n",
    "print(\"****************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answer is present in 62.765% of generated candidate pools via Anchor Links popularity method.\n"
     ]
    }
   ],
   "source": [
    "# Calculate percentage of candidate pools with the correct answer present\n",
    "# Necessary to determine if shuffling pool could even get the right answer\n",
    "response_present = 0\n",
    "for i in range(len(preds_anchor_popularity)):\n",
    "    try:\n",
    "        if preds_anchor_popularity['wikipedia_page_ID'][i] in preds_anchor_popularity['candidate_pool_page_ids'][i]:\n",
    "            response_present += 1\n",
    "    except TypeError:\n",
    "        pass\n",
    "print(f\"Correct answer is present in {round(response_present / len(preds_anchor_popularity) * 100, 3)}% of generated candidate pools via Anchor Links popularity method.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confirm Accuracy Only for Full Mentions with True Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************\n",
      "Predictive Accuracy: 61.873%\n",
      "****************************\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy only for known true values\n",
    "accurate_predictions = 0\n",
    "preds_popularity_nonulls = preds_anchor_popularity[preds_anchor_popularity['wikipedia_page_ID'].notnull()].reset_index()\n",
    "for i in range(len(preds_popularity_nonulls)):\n",
    "    try:\n",
    "        if preds_popularity_nonulls['wikipedia_page_ID'][i] == preds_popularity_nonulls['candidate_pool_page_ids'][i][0]:\n",
    "            accurate_predictions += 1\n",
    "    except TypeError:\n",
    "        pass\n",
    "print(\"****************************\")\n",
    "print(f\"Predictive Accuracy: {round(accurate_predictions / len(preds_popularity_nonulls) * 100, 3)}%\")\n",
    "print(\"****************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answer is present in 85.997% of generated candidate pools via Anchor Links popularity method.\n"
     ]
    }
   ],
   "source": [
    "# Calculate percentage of candidate pools with the correct answer present for known true values\n",
    "# Necessary to determine if shuffling pool could even get the right answer\n",
    "response_present = 0\n",
    "for i in range(len(preds_popularity_nonulls)):\n",
    "    try:\n",
    "        if preds_popularity_nonulls['wikipedia_page_ID'][i] in preds_popularity_nonulls['candidate_pool_page_ids'][i]:\n",
    "            response_present += 1\n",
    "    except TypeError:\n",
    "        pass\n",
    "print(f\"Correct answer is present in {round(response_present / len(preds_popularity_nonulls) * 100, 3)}% of generated candidate pools via Anchor Links popularity method.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save candidate pools dataframe\n",
    "preds_anchor_popularity.to_csv(os.path.join(preds_path, \"anchortext_popularity.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
