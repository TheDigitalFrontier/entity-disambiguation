{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Candidate Pool via Anchor Links\n",
    "\n",
    "This notebook uses anchor links on Wikipedia, or hyperlinks from a string to a Wikipedia page, to propose a candidate pool of possible entities/pages for each full mention. We propose two methods of using anchor links: one sorts by most popular or viewed pages and the other by the most linked or central pages. We output both dataframes for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Progress bar\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Processed ACY Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>full_mention</th>\n",
       "      <th>wikipedia_URL</th>\n",
       "      <th>wikipedia_page_ID</th>\n",
       "      <th>wikipedia_title</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>congruent_mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>EU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>German</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Germany</td>\n",
       "      <td>11867.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>British</td>\n",
       "      <td>http://en.wikipedia.org/wiki/United_Kingdom</td>\n",
       "      <td>31717.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mention full_mention                                wikipedia_URL  \\\n",
       "0       B           EU                                          NaN   \n",
       "1       B       German         http://en.wikipedia.org/wiki/Germany   \n",
       "2       B      British  http://en.wikipedia.org/wiki/United_Kingdom   \n",
       "\n",
       "   wikipedia_page_ID wikipedia_title  sentence_id  doc_id  \\\n",
       "0                NaN             NaN            0       0   \n",
       "1            11867.0         Germany            0       0   \n",
       "2            31717.0  United Kingdom            0       0   \n",
       "\n",
       "            congruent_mentions  \n",
       "0  ['EU', 'German', 'British']  \n",
       "1  ['EU', 'German', 'British']  \n",
       "2  ['EU', 'German', 'British']  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base path to input\n",
    "acy_path = '../../data/aida-conll-yago-dataset/'\n",
    "\n",
    "# Load data\n",
    "acy_input = pd.read_csv(os.path.join(acy_path, \"Aida-Conll-Yago-Input.csv\"), delimiter=\",\")\n",
    "acy_input.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Kensho Target Dataset\n",
    "\n",
    "This dataset provides anchor linkage statistics for Wikipedia pages and is provided by Kensho Technologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base path to KWNLP\n",
    "kwnlp_path = '../../data/kwnlp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>page_title</th>\n",
       "      <th>views</th>\n",
       "      <th>len_article_chars</th>\n",
       "      <th>len_intro_chars</th>\n",
       "      <th>in_link_count</th>\n",
       "      <th>out_link_count</th>\n",
       "      <th>tmpl_good_article</th>\n",
       "      <th>tmpl_featured_article</th>\n",
       "      <th>tmpl_pseudoscience</th>\n",
       "      <th>tmpl_conspiracy_theories</th>\n",
       "      <th>isa_Q17442446</th>\n",
       "      <th>isa_Q14795564</th>\n",
       "      <th>isa_Q18340514</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>6199</td>\n",
       "      <td>Anarchism</td>\n",
       "      <td>35558</td>\n",
       "      <td>40449</td>\n",
       "      <td>409</td>\n",
       "      <td>3826</td>\n",
       "      <td>371</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>38404</td>\n",
       "      <td>Autism</td>\n",
       "      <td>40081</td>\n",
       "      <td>47659</td>\n",
       "      <td>419</td>\n",
       "      <td>2313</td>\n",
       "      <td>309</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>101038</td>\n",
       "      <td>Albedo</td>\n",
       "      <td>10770</td>\n",
       "      <td>18766</td>\n",
       "      <td>293</td>\n",
       "      <td>3090</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_id  item_id page_title  views  len_article_chars  len_intro_chars  \\\n",
       "0       12     6199  Anarchism  35558              40449              409   \n",
       "1       25    38404     Autism  40081              47659              419   \n",
       "2       39   101038     Albedo  10770              18766              293   \n",
       "\n",
       "   in_link_count  out_link_count  tmpl_good_article  tmpl_featured_article  \\\n",
       "0           3826             371                  1                      0   \n",
       "1           2313             309                  0                      1   \n",
       "2           3090             115                  0                      0   \n",
       "\n",
       "   tmpl_pseudoscience  tmpl_conspiracy_theories  isa_Q17442446  isa_Q14795564  \\\n",
       "0                   0                         0              0              0   \n",
       "1                   0                         0              0              0   \n",
       "2                   0                         0              0              0   \n",
       "\n",
       "   isa_Q18340514  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load article data\n",
    "article_df = pd.read_csv(os.path.join(kwnlp_path, 'kwnlp-enwiki-20200920-article.csv'))\n",
    "article_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anchor_text</th>\n",
       "      <th>target_page_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>3434750</td>\n",
       "      <td>152451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>World War II</td>\n",
       "      <td>32927</td>\n",
       "      <td>133668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>14533</td>\n",
       "      <td>112069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     anchor_text  target_page_id   count\n",
       "0  United States         3434750  152451\n",
       "1   World War II           32927  133668\n",
       "2          India           14533  112069"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load anchor target counts data\n",
    "anchor_df = pd.read_csv(os.path.join(kwnlp_path, 'kwnlp-enwiki-20200920-anchor-target-counts.csv'))\n",
    "anchor_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Target Data\n",
    "\n",
    "We apply normalization to the anchor text to make for simpler matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy to new dataframe for processing\n",
    "anchor_texts = anchor_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define text normalization function\n",
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    We define normalized as:\n",
    "    - lowercase\n",
    "    - strip whitespace\n",
    "    - Spaces, not underlines\n",
    "    - Remove punctuation (todo decide&implement)\n",
    "    \"\"\"\n",
    "    return str(text).strip().lower().replace(\"_\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply normalization to anchor text\n",
    "anchor_texts['norm_anchor_text'] = anchor_texts['anchor_text'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3,581 'None' values in anchor_text.\n"
     ]
    }
   ],
   "source": [
    "# Assess presence of Null values in anchor_text\n",
    "print(f\"There are {anchor_texts['anchor_text'].isnull().sum():,} 'None' values in anchor_text.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 15269229\n",
      "After: 15265648\n"
     ]
    }
   ],
   "source": [
    "# Filter out None values\n",
    "print(\"Before: {}\".format(len(anchor_texts)))\n",
    "anchor_texts = anchor_texts[anchor_texts['anchor_text'].notnull()]\n",
    "print(\"After: {}\".format(len(anchor_texts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join Page Data to Anchor Text Data\n",
    "\n",
    "This provides us with information on page views and links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.6 s, sys: 30.1 s, total: 1min 6s\n",
      "Wall time: 1min 20s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>norm_anchor_text</th>\n",
       "      <th>target_page_id</th>\n",
       "      <th>target_item_id</th>\n",
       "      <th>target_page_title</th>\n",
       "      <th>target_page_views</th>\n",
       "      <th>anchor_target_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>united states</td>\n",
       "      <td>3434750</td>\n",
       "      <td>30</td>\n",
       "      <td>United_States</td>\n",
       "      <td>460156</td>\n",
       "      <td>152451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>american</td>\n",
       "      <td>3434750</td>\n",
       "      <td>30</td>\n",
       "      <td>United_States</td>\n",
       "      <td>460156</td>\n",
       "      <td>65722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>usa</td>\n",
       "      <td>3434750</td>\n",
       "      <td>30</td>\n",
       "      <td>United_States</td>\n",
       "      <td>460156</td>\n",
       "      <td>8559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  norm_anchor_text  target_page_id  target_item_id target_page_title  \\\n",
       "0    united states         3434750              30     United_States   \n",
       "1         american         3434750              30     United_States   \n",
       "2              usa         3434750              30     United_States   \n",
       "\n",
       "   target_page_views  anchor_target_count  \n",
       "0             460156               152451  \n",
       "1             460156                65722  \n",
       "2             460156                 8559  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Merge at_count and article stats dataframes\n",
    "anchor_texts = pd.merge(\n",
    "    anchor_texts,\n",
    "    article_df,\n",
    "    how=\"inner\",\n",
    "    left_on=\"target_page_id\",\n",
    "    right_on=\"page_id\")\n",
    "\n",
    "# Rename columns for clarity\n",
    "anchor_texts = anchor_texts.rename(columns={\n",
    "    'title': 'target_page_title',\n",
    "    'item_id': 'target_item_id',\n",
    "    'views': 'target_page_views',\n",
    "    'count': 'anchor_target_count',\n",
    "    'page_title': 'target_page_title'})\n",
    "\n",
    "# Specify column ordering\n",
    "anchor_texts = anchor_texts[[\n",
    "    \"norm_anchor_text\",\n",
    "    \"target_page_id\",\n",
    "    \"target_item_id\",\n",
    "    \"target_page_title\",\n",
    "    \"target_page_views\",\n",
    "    \"anchor_target_count\"]]\n",
    "\n",
    "# Display preview\n",
    "anchor_texts.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop Anchor Link Candidate Generation Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchor Link Frequency\n",
    "\n",
    "This model generates a candidate pool of Wikipedia pages for each full mention by looking at the pages that string links to the most number of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 21s, sys: 5 s, total: 1min 26s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Sort dataframe by anchor text and then most frequently linked page\n",
    "anchor_texts = anchor_texts.sort_values(['norm_anchor_text', 'anchor_target_count'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.3 s, sys: 5.38 s, total: 1min 3s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Return just the top N most linked entities to create our candidate pool for each anchor link\n",
    "top_N = 10\n",
    "anchor_text_link_frequency = anchor_texts.groupby('norm_anchor_text').head(top_N).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>norm_anchor_text</th>\n",
       "      <th>target_page_id</th>\n",
       "      <th>target_item_id</th>\n",
       "      <th>target_page_title</th>\n",
       "      <th>target_page_views</th>\n",
       "      <th>anchor_target_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>950752</th>\n",
       "      <td>united states</td>\n",
       "      <td>3434750</td>\n",
       "      <td>30</td>\n",
       "      <td>United_States</td>\n",
       "      <td>460156</td>\n",
       "      <td>152451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950753</th>\n",
       "      <td>united states</td>\n",
       "      <td>582488</td>\n",
       "      <td>164134</td>\n",
       "      <td>United_States_men's_national_soccer_team</td>\n",
       "      <td>25804</td>\n",
       "      <td>1466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950754</th>\n",
       "      <td>united states</td>\n",
       "      <td>647757</td>\n",
       "      <td>334526</td>\n",
       "      <td>United_States_women's_national_soccer_team</td>\n",
       "      <td>12292</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950755</th>\n",
       "      <td>united states</td>\n",
       "      <td>1145226</td>\n",
       "      <td>1143805</td>\n",
       "      <td>United_States_national_rugby_union_team</td>\n",
       "      <td>1165</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950756</th>\n",
       "      <td>united states</td>\n",
       "      <td>945923</td>\n",
       "      <td>913651</td>\n",
       "      <td>United_States_men's_national_ice_hockey_team</td>\n",
       "      <td>2537</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950757</th>\n",
       "      <td>united states</td>\n",
       "      <td>924170</td>\n",
       "      <td>279283</td>\n",
       "      <td>Elections_in_the_United_States</td>\n",
       "      <td>14936</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950758</th>\n",
       "      <td>united states</td>\n",
       "      <td>378405</td>\n",
       "      <td>3054793</td>\n",
       "      <td>Secondary_education_in_the_United_States</td>\n",
       "      <td>6907</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950759</th>\n",
       "      <td>united states</td>\n",
       "      <td>980450</td>\n",
       "      <td>2738955</td>\n",
       "      <td>United_States_national_cricket_team</td>\n",
       "      <td>2043</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950760</th>\n",
       "      <td>united states</td>\n",
       "      <td>6311052</td>\n",
       "      <td>1389353</td>\n",
       "      <td>United_States_Davis_Cup_team</td>\n",
       "      <td>335</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950761</th>\n",
       "      <td>united states</td>\n",
       "      <td>89611</td>\n",
       "      <td>244847</td>\n",
       "      <td>United_States_men's_national_basketball_team</td>\n",
       "      <td>10624</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       norm_anchor_text  target_page_id  target_item_id  \\\n",
       "950752    united states         3434750              30   \n",
       "950753    united states          582488          164134   \n",
       "950754    united states          647757          334526   \n",
       "950755    united states         1145226         1143805   \n",
       "950756    united states          945923          913651   \n",
       "950757    united states          924170          279283   \n",
       "950758    united states          378405         3054793   \n",
       "950759    united states          980450         2738955   \n",
       "950760    united states         6311052         1389353   \n",
       "950761    united states           89611          244847   \n",
       "\n",
       "                                   target_page_title  target_page_views  \\\n",
       "950752                                 United_States             460156   \n",
       "950753      United_States_men's_national_soccer_team              25804   \n",
       "950754    United_States_women's_national_soccer_team              12292   \n",
       "950755       United_States_national_rugby_union_team               1165   \n",
       "950756  United_States_men's_national_ice_hockey_team               2537   \n",
       "950757                Elections_in_the_United_States              14936   \n",
       "950758      Secondary_education_in_the_United_States               6907   \n",
       "950759           United_States_national_cricket_team               2043   \n",
       "950760                  United_States_Davis_Cup_team                335   \n",
       "950761  United_States_men's_national_basketball_team              10624   \n",
       "\n",
       "        anchor_target_count  \n",
       "950752               152451  \n",
       "950753                 1466  \n",
       "950754                  594  \n",
       "950755                  352  \n",
       "950756                  257  \n",
       "950757                  243  \n",
       "950758                  225  \n",
       "950759                  223  \n",
       "950760                  218  \n",
       "950761                  177  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually test United States to assess resulting dataframe\n",
    "anchor_text_link_frequency[anchor_text_link_frequency['norm_anchor_text'] == 'united states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique anchor links numbered 15,265,648\n",
      "Remaining dataframe contains 14,009,323 rows\n"
     ]
    }
   ],
   "source": [
    "# Assess remaining rows\n",
    "print(\"Unique anchor links numbered {:,}\".format(len(anchor_texts)))\n",
    "print(\"Remaining dataframe contains {:,} rows\".format(len(anchor_text_link_frequency)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did not reduce the dataframe by much, suggesting only a few anchor texts have more than our selected N number of distinct links. To append to our ACY Input data, we produce a dictionary of anchor text to its candidate pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In case of prior road, load saved json file before re-running the whole thing\n",
    "# # Load dictionary\n",
    "# with open('../../predictions/dict_anchor_pool_frequency.json', 'r') as filepath:\n",
    "#     dict_anchor_pool_frequency = json.load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 52s, sys: 21.8 s, total: 11min 14s\n",
      "Wall time: 11min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Group by anchor text to produce list of item IDs, page IDs and page titles (our candidate pools)\n",
    "anchor_text_candidate_pools = anchor_text_link_frequency.groupby('norm_anchor_text')\\\n",
    "                                    [['target_page_id', 'target_page_title', 'target_item_id']]\\\n",
    "                                    .agg(lambda x: list(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11327029/11327029 [19:56<00:00, 9464.89it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 16s, sys: 1min 11s, total: 19min 27s\n",
      "Wall time: 19min 56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Add to dictionary for faster searching later in the pipeline\n",
    "\n",
    "# Create dictionary\n",
    "dict_anchor_pool_frequency = {}\n",
    "\n",
    "# Add lists to dictionary with anchor text as search term\n",
    "# This should match the full mention search when measuring accuracy later\n",
    "for i in tqdm(range(len(anchor_text_candidate_pools))):\n",
    "    row = anchor_text_candidate_pools.loc[i]\n",
    "    dict_anchor_pool_frequency[row['norm_anchor_text']] = [row['target_page_id'], row['target_page_title'], row['target_item_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demonstrate search performance boost of dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 7 µs, total: 11 µs\n",
      "Wall time: 12.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Demonstrate search benefit of storing as dictionary\n",
    "o = dict_anchor_pool_frequency['united states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.31 s, sys: 7.88 s, total: 13.2 s\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Compare Pandas dataframe search to dictionary search\n",
    "o = anchor_text_candidate_pools[anchor_text_candidate_pools['norm_anchor_text'] == 'united states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dictionary\n",
    "with open('../../predictions/dict_anchor_pool_frequency.json', 'w') as filepath:\n",
    "    json.dump(dict_anchor_pool_frequency, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchor Link Popularity\n",
    "\n",
    "This model generates a candidate pool of Wikipedia pages for each full mention by looking at the popularity of pages that string has linked to and sorting by the pages with the most views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 7s, sys: 8.52 s, total: 1min 15s\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Sort dataframe by anchor text and then most frequently linked page\n",
    "anchor_texts = anchor_texts.sort_values(['norm_anchor_text', 'target_page_views'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.7 s, sys: 4.26 s, total: 59.9 s\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Return just the top N most viewed entities to create our candidate pool for each anchor link\n",
    "top_N = 10\n",
    "anchor_text_link_popularity = anchor_texts.groupby('norm_anchor_text').head(top_N).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>norm_anchor_text</th>\n",
       "      <th>target_page_id</th>\n",
       "      <th>target_item_id</th>\n",
       "      <th>target_page_title</th>\n",
       "      <th>target_page_views</th>\n",
       "      <th>anchor_target_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>950752</th>\n",
       "      <td>united states</td>\n",
       "      <td>3434750</td>\n",
       "      <td>30</td>\n",
       "      <td>United_States</td>\n",
       "      <td>460156</td>\n",
       "      <td>152451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950753</th>\n",
       "      <td>united states</td>\n",
       "      <td>3434750</td>\n",
       "      <td>30</td>\n",
       "      <td>United_States</td>\n",
       "      <td>460156</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950754</th>\n",
       "      <td>united states</td>\n",
       "      <td>63136490</td>\n",
       "      <td>83873577</td>\n",
       "      <td>COVID-19_pandemic_in_the_United_States</td>\n",
       "      <td>428030</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950755</th>\n",
       "      <td>united states</td>\n",
       "      <td>58993617</td>\n",
       "      <td>41174436</td>\n",
       "      <td>2020_Formula_One_World_Championship</td>\n",
       "      <td>343066</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950756</th>\n",
       "      <td>united states</td>\n",
       "      <td>44751865</td>\n",
       "      <td>19600530</td>\n",
       "      <td>Black_Lives_Matter</td>\n",
       "      <td>250974</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950757</th>\n",
       "      <td>united states</td>\n",
       "      <td>12610470</td>\n",
       "      <td>1682357</td>\n",
       "      <td>List_of_states_and_territories_of_the_United_S...</td>\n",
       "      <td>185044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950758</th>\n",
       "      <td>united states</td>\n",
       "      <td>54803678</td>\n",
       "      <td>37093861</td>\n",
       "      <td>Antifa_(United_States)</td>\n",
       "      <td>183516</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950759</th>\n",
       "      <td>united states</td>\n",
       "      <td>1649321</td>\n",
       "      <td>131079</td>\n",
       "      <td>List_of_United_States_cities_by_population</td>\n",
       "      <td>163698</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950760</th>\n",
       "      <td>united states</td>\n",
       "      <td>18618239</td>\n",
       "      <td>35657</td>\n",
       "      <td>U.S._state</td>\n",
       "      <td>155646</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950761</th>\n",
       "      <td>united states</td>\n",
       "      <td>3356</td>\n",
       "      <td>1124</td>\n",
       "      <td>Bill_Clinton</td>\n",
       "      <td>155162</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       norm_anchor_text  target_page_id  target_item_id  \\\n",
       "950752    united states         3434750              30   \n",
       "950753    united states         3434750              30   \n",
       "950754    united states        63136490        83873577   \n",
       "950755    united states        58993617        41174436   \n",
       "950756    united states        44751865        19600530   \n",
       "950757    united states        12610470         1682357   \n",
       "950758    united states        54803678        37093861   \n",
       "950759    united states         1649321          131079   \n",
       "950760    united states        18618239           35657   \n",
       "950761    united states            3356            1124   \n",
       "\n",
       "                                        target_page_title  target_page_views  \\\n",
       "950752                                      United_States             460156   \n",
       "950753                                      United_States             460156   \n",
       "950754             COVID-19_pandemic_in_the_United_States             428030   \n",
       "950755                2020_Formula_One_World_Championship             343066   \n",
       "950756                                 Black_Lives_Matter             250974   \n",
       "950757  List_of_states_and_territories_of_the_United_S...             185044   \n",
       "950758                             Antifa_(United_States)             183516   \n",
       "950759         List_of_United_States_cities_by_population             163698   \n",
       "950760                                         U.S._state             155646   \n",
       "950761                                       Bill_Clinton             155162   \n",
       "\n",
       "        anchor_target_count  \n",
       "950752               152451  \n",
       "950753                    5  \n",
       "950754                   31  \n",
       "950755                    1  \n",
       "950756                    1  \n",
       "950757                    1  \n",
       "950758                    1  \n",
       "950759                    1  \n",
       "950760                    3  \n",
       "950761                    1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually test United States to assess resulting dataframe\n",
    "anchor_text_link_popularity[anchor_text_link_popularity['norm_anchor_text'] == 'united states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique anchor links numbered 15,265,648\n",
      "Remaining dataframe contains 14,009,323 rows\n"
     ]
    }
   ],
   "source": [
    "# Assess remaining rows\n",
    "print(\"Unique anchor links numbered {:,}\".format(len(anchor_texts)))\n",
    "print(\"Remaining dataframe contains {:,} rows\".format(len(anchor_text_link_popularity)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In case of prior road, load saved json file before re-running the whole thing\n",
    "# # Load dictionary\n",
    "# with open('../../predictions/dict_anchor_pool_popularity.json', 'r') as filepath:\n",
    "#     dict_anchor_pool_popularity = json.load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 7s, sys: 2min 11s, total: 13min 18s\n",
      "Wall time: 14min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Group by anchor text to produce list of item IDs, page IDs and page titles (our candidate pools)\n",
    "anchor_text_candidate_pools = anchor_text_link_popularity.groupby('norm_anchor_text')\\\n",
    "                                    [['target_page_id', 'target_page_title', 'target_item_id']]\\\n",
    "                                    .agg(lambda x: list(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11327029/11327029 [20:57<00:00, 9009.42it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 18s, sys: 1min 48s, total: 20min 6s\n",
      "Wall time: 20min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Add to dictionary for faster searching later in the pipeline\n",
    "\n",
    "# Create dictionary\n",
    "dict_anchor_pool_popularity = {}\n",
    "\n",
    "# Add lists to dictionary with anchor text as search term\n",
    "# This should match the full mention search when measuring accuracy later\n",
    "for i in tqdm(range(len(anchor_text_candidate_pools))):\n",
    "    row = anchor_text_candidate_pools.loc[i]\n",
    "    dict_anchor_pool_popularity[row['norm_anchor_text']] = [row['target_page_id'], row['target_page_title'], row['target_item_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dictionary\n",
    "with open('../../predictions/dict_anchor_pool_popularity.json', 'w') as filepath:\n",
    "    json.dump(dict_anchor_pool_popularity, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess Accuracy of Anchor Link Models without Congruence\n",
    "\n",
    "For each full mention in our ACY input dataset, we now append the generated candidate pool as a column and save our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize full mentions for direct comparison with normalized anchor texts\n",
    "acy_input['norm_full_mention'] = acy_input['full_mention'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchor Link Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy input dataframe\n",
    "preds_anchor_frequency = acy_input.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29312/29312 [00:00<00:00, 86908.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# For each full mention, retrieve the candidate pool generated by the model\n",
    "mention_candidate_pools_page_ids = []\n",
    "mention_candidate_pools_item_ids = []\n",
    "mention_candidate_pools_titles = []\n",
    "\n",
    "# Track metrics\n",
    "oov_error = 0\n",
    "\n",
    "for i in tqdm(range(len(acy_input))):\n",
    "    \n",
    "    # Retrieve normalized full mention\n",
    "    full_mention = acy_input['norm_full_mention'][i]\n",
    "    \n",
    "    # Retrieve candidate pools for full mention\n",
    "    try:\n",
    "        dicts = dict_anchor_pool_frequency[full_mention]\n",
    "    except KeyError:\n",
    "        oov_error += 1\n",
    "        dicts = (None, None, None)\n",
    "        \n",
    "    candidate_pool_page_ids = dicts[0]\n",
    "    candidate_pool_titles = dicts[1]\n",
    "    candidate_pool_item_ids = dicts[2]\n",
    "    \n",
    "    # Save candidate pools\n",
    "    mention_candidate_pools_page_ids.append(candidate_pool_page_ids)\n",
    "    mention_candidate_pools_item_ids.append(candidate_pool_item_ids)\n",
    "    mention_candidate_pools_titles.append(candidate_pool_titles)\n",
    "    \n",
    "preds_anchor_frequency['mention_candidate_pools_page_ids'] = mention_candidate_pools_page_ids\n",
    "preds_anchor_frequency['mention_candidate_pools_item_ids'] = mention_candidate_pools_item_ids\n",
    "preds_anchor_frequency['candidate_pools_titles'] = mention_candidate_pools_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We received 4,625 Out-of-Vocabulary Errors.\n"
     ]
    }
   ],
   "source": [
    "print(f\"We received {oov_error:,} Out-of-Vocabulary Errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>full_mention</th>\n",
       "      <th>wikipedia_URL</th>\n",
       "      <th>wikipedia_page_ID</th>\n",
       "      <th>wikipedia_title</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>congruent_mentions</th>\n",
       "      <th>norm_full_mention</th>\n",
       "      <th>mention_candidate_pools_page_ids</th>\n",
       "      <th>mention_candidate_pools_item_ids</th>\n",
       "      <th>candidate_pools_titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>EU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>eu</td>\n",
       "      <td>[9317, 9239, 21347120, 9477, 1882861, 3261189,...</td>\n",
       "      <td>[458, 46, 211593, 1396, 363404, 3327447, 40537...</td>\n",
       "      <td>[European_Union, Europe, Eu,_Seine-Maritime, E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>German</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Germany</td>\n",
       "      <td>11867.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>german</td>\n",
       "      <td>[11867, 11884, 152735, 21212, 12674, 290327, 1...</td>\n",
       "      <td>[183, 188, 42884, 7318, 43287, 141817, 181287,...</td>\n",
       "      <td>[Germany, German_language, Germans, Nazi_Germa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>British</td>\n",
       "      <td>http://en.wikipedia.org/wiki/United_Kingdom</td>\n",
       "      <td>31717.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>british</td>\n",
       "      <td>[31717, 19097669, 13530298, 4721, 158019, 1522...</td>\n",
       "      <td>[145, 842438, 23666, 8680, 161885, 174193, 354...</td>\n",
       "      <td>[United_Kingdom, British_people, Great_Britain...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mention full_mention                                wikipedia_URL  \\\n",
       "0       B           EU                                          NaN   \n",
       "1       B       German         http://en.wikipedia.org/wiki/Germany   \n",
       "2       B      British  http://en.wikipedia.org/wiki/United_Kingdom   \n",
       "\n",
       "   wikipedia_page_ID wikipedia_title  sentence_id  doc_id  \\\n",
       "0                NaN             NaN            0       0   \n",
       "1            11867.0         Germany            0       0   \n",
       "2            31717.0  United Kingdom            0       0   \n",
       "\n",
       "            congruent_mentions norm_full_mention  \\\n",
       "0  ['EU', 'German', 'British']                eu   \n",
       "1  ['EU', 'German', 'British']            german   \n",
       "2  ['EU', 'German', 'British']           british   \n",
       "\n",
       "                    mention_candidate_pools_page_ids  \\\n",
       "0  [9317, 9239, 21347120, 9477, 1882861, 3261189,...   \n",
       "1  [11867, 11884, 152735, 21212, 12674, 290327, 1...   \n",
       "2  [31717, 19097669, 13530298, 4721, 158019, 1522...   \n",
       "\n",
       "                    mention_candidate_pools_item_ids  \\\n",
       "0  [458, 46, 211593, 1396, 363404, 3327447, 40537...   \n",
       "1  [183, 188, 42884, 7318, 43287, 141817, 181287,...   \n",
       "2  [145, 842438, 23666, 8680, 161885, 174193, 354...   \n",
       "\n",
       "                              candidate_pools_titles  \n",
       "0  [European_Union, Europe, Eu,_Seine-Maritime, E...  \n",
       "1  [Germany, German_language, Germans, Nazi_Germa...  \n",
       "2  [United_Kingdom, British_people, Great_Britain...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview dataframe\n",
    "preds_anchor_frequency.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************\n",
      "Predictive Accuracy: 54.609%\n",
      "****************************\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accurate_predictions = 0\n",
    "for i in range(len(preds_anchor_frequency)):\n",
    "    try:\n",
    "        if preds_anchor_frequency['wikipedia_page_ID'][i] == preds_anchor_frequency['mention_candidate_pools_page_ids'][i][0]:\n",
    "            accurate_predictions += 1\n",
    "    except TypeError:\n",
    "        pass\n",
    "print(\"****************************\")\n",
    "print(f\"Predictive Accuracy: {round(accurate_predictions / len(preds_anchor_frequency) * 100, 3)}%\")\n",
    "print(\"****************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answer is present in 68.661% of generated candidate pools via Anchor Links Frequency method.\n"
     ]
    }
   ],
   "source": [
    "# Calculate percentage of candidate pools with the correct answer present\n",
    "# Necessary to determine if shuffling pool could even get the right answer\n",
    "response_present = 0\n",
    "for i in range(len(preds_anchor_frequency)):\n",
    "    try:\n",
    "        if preds_anchor_frequency['wikipedia_page_ID'][i] in preds_anchor_frequency['mention_candidate_pools_page_ids'][i]:\n",
    "            response_present += 1\n",
    "    except TypeError:\n",
    "        pass\n",
    "print(f\"Correct answer is present in {round(response_present / len(preds_anchor_frequency) * 100, 3)}% of generated candidate pools via Anchor Links Frequency method.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base path to input\n",
    "preds_path = '../../predictions/'\n",
    "\n",
    "# Save candidate pools dataframe\n",
    "preds_anchor_frequency.to_csv(os.path.join(preds_path, \"anchortext_frequency.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchor Link Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy input dataframe\n",
    "preds_anchor_popularity = acy_input.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29312/29312 [00:00<00:00, 159631.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# For each full mention, retrieve the candidate pool generated by the model\n",
    "mention_candidate_pools_page_ids = []\n",
    "mention_candidate_pools_item_ids = []\n",
    "mention_candidate_pools_titles = []\n",
    "\n",
    "# Track metrics\n",
    "oov_error = 0\n",
    "\n",
    "for i in tqdm(range(len(acy_input))):\n",
    "    \n",
    "    # Retrieve normalized full mention\n",
    "    full_mention = acy_input['norm_full_mention'][i]\n",
    "    \n",
    "    # Retrieve candidate pools for full mention\n",
    "    try:\n",
    "        dicts = dict_anchor_pool_popularity[full_mention]\n",
    "    except KeyError:\n",
    "        oov_error += 1\n",
    "        dicts = (None, None, None)\n",
    "        \n",
    "    candidate_pool_page_ids = dicts[0]\n",
    "    candidate_pool_titles = dicts[1]\n",
    "    candidate_pool_item_ids = dicts[2]\n",
    "    \n",
    "    # Save candidate pools\n",
    "    mention_candidate_pools_page_ids.append(candidate_pool_page_ids)\n",
    "    mention_candidate_pools_item_ids.append(candidate_pool_item_ids)\n",
    "    mention_candidate_pools_titles.append(candidate_pool_titles)\n",
    "    \n",
    "preds_anchor_popularity['mention_candidate_pools_page_ids'] = mention_candidate_pools_page_ids\n",
    "preds_anchor_popularity['mention_candidate_pools_item_ids'] = mention_candidate_pools_item_ids\n",
    "preds_anchor_popularity['candidate_pools_titles'] = mention_candidate_pools_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We received 4,625 Out-of-Vocabulary Errors.\n"
     ]
    }
   ],
   "source": [
    "print(f\"We received {oov_error:,} Out-of-Vocabulary Errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>full_mention</th>\n",
       "      <th>wikipedia_URL</th>\n",
       "      <th>wikipedia_page_ID</th>\n",
       "      <th>wikipedia_title</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>congruent_mentions</th>\n",
       "      <th>norm_full_mention</th>\n",
       "      <th>mention_candidate_pools_page_ids</th>\n",
       "      <th>mention_candidate_pools_item_ids</th>\n",
       "      <th>candidate_pools_titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>EU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>eu</td>\n",
       "      <td>[9317, 9239, 9891, 9472, 10890716, 2780146, 18...</td>\n",
       "      <td>[458, 46, 45003, 4916, 185441, 932442, 8268, 8...</td>\n",
       "      <td>[European_Union, Europe, Entropy, Euro, Member...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>German</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Germany</td>\n",
       "      <td>11867.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>german</td>\n",
       "      <td>[11867, 11867, 27318, 21148, 21212, 21212, 269...</td>\n",
       "      <td>[183, 183, 334, 55, 7318, 7318, 40, 12548, 825...</td>\n",
       "      <td>[Germany, Germany, Singapore, Netherlands, Naz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>British</td>\n",
       "      <td>http://en.wikipedia.org/wiki/United_Kingdom</td>\n",
       "      <td>31717.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>british</td>\n",
       "      <td>[3434750, 31717, 31717, 19344654, 26061, 85699...</td>\n",
       "      <td>[30, 145, 145, 9531, 172771, 1860, 21, 22, 868...</td>\n",
       "      <td>[United_States, United_Kingdom, United_Kingdom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mention full_mention                                wikipedia_URL  \\\n",
       "0       B           EU                                          NaN   \n",
       "1       B       German         http://en.wikipedia.org/wiki/Germany   \n",
       "2       B      British  http://en.wikipedia.org/wiki/United_Kingdom   \n",
       "\n",
       "   wikipedia_page_ID wikipedia_title  sentence_id  doc_id  \\\n",
       "0                NaN             NaN            0       0   \n",
       "1            11867.0         Germany            0       0   \n",
       "2            31717.0  United Kingdom            0       0   \n",
       "\n",
       "            congruent_mentions norm_full_mention  \\\n",
       "0  ['EU', 'German', 'British']                eu   \n",
       "1  ['EU', 'German', 'British']            german   \n",
       "2  ['EU', 'German', 'British']           british   \n",
       "\n",
       "                    mention_candidate_pools_page_ids  \\\n",
       "0  [9317, 9239, 9891, 9472, 10890716, 2780146, 18...   \n",
       "1  [11867, 11867, 27318, 21148, 21212, 21212, 269...   \n",
       "2  [3434750, 31717, 31717, 19344654, 26061, 85699...   \n",
       "\n",
       "                    mention_candidate_pools_item_ids  \\\n",
       "0  [458, 46, 45003, 4916, 185441, 932442, 8268, 8...   \n",
       "1  [183, 183, 334, 55, 7318, 7318, 40, 12548, 825...   \n",
       "2  [30, 145, 145, 9531, 172771, 1860, 21, 22, 868...   \n",
       "\n",
       "                              candidate_pools_titles  \n",
       "0  [European_Union, Europe, Entropy, Euro, Member...  \n",
       "1  [Germany, Germany, Singapore, Netherlands, Naz...  \n",
       "2  [United_States, United_Kingdom, United_Kingdom...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview dataframe\n",
    "preds_anchor_popularity.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************\n",
      "Predictive Accuracy: 46.571%\n",
      "****************************\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accurate_predictions = 0\n",
    "for i in range(len(preds_anchor_popularity)):\n",
    "    try:\n",
    "        if preds_anchor_popularity['wikipedia_page_ID'][i] == preds_anchor_popularity['mention_candidate_pools_page_ids'][i][0]:\n",
    "            accurate_predictions += 1\n",
    "    except TypeError:\n",
    "        pass\n",
    "print(\"****************************\")\n",
    "print(f\"Predictive Accuracy: {round(accurate_predictions / len(preds_anchor_popularity) * 100, 3)}%\")\n",
    "print(\"****************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answer is present in 67.535% of generated candidate pools via Anchor Links popularity method.\n"
     ]
    }
   ],
   "source": [
    "# Calculate percentage of candidate pools with the correct answer present\n",
    "# Necessary to determine if shuffling pool could even get the right answer\n",
    "response_present = 0\n",
    "for i in range(len(preds_anchor_popularity)):\n",
    "    try:\n",
    "        if preds_anchor_popularity['wikipedia_page_ID'][i] in preds_anchor_popularity['mention_candidate_pools_page_ids'][i]:\n",
    "            response_present += 1\n",
    "    except TypeError:\n",
    "        pass\n",
    "print(f\"Correct answer is present in {round(response_present / len(preds_anchor_popularity) * 100, 3)}% of generated candidate pools via Anchor Links popularity method.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save candidate pools dataframe\n",
    "preds_anchor_popularity.to_csv(os.path.join(preds_path, \"anchortext_popularity.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
