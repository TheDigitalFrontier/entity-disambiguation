{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congruence via Graph Distance\n",
    "\n",
    "In this notebook, we try to calculate candidate node similarity via a simpler computational method than N-Degree Relations. This is also where we try to explore the potential of utilizing knowledge graphs. We take a list of candidate entities, represented as Item IDs, and search for that Item ID in either `source_item_id` or `target_item_id` in `statements_df`. This guarantees one layer of surrounding graph from the candidates, the potential for overlap and lets us measure candidate node importance via \"Density\" (number of first degree connections) or \"Connectivity\" (number of dendritic connections between candidate nodes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Progress bar\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Load Data\n",
    "### Integrate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>full_mention</th>\n",
       "      <th>wikipedia_URL</th>\n",
       "      <th>wikipedia_page_ID</th>\n",
       "      <th>wikipedia_title</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>congruent_mentions</th>\n",
       "      <th>norm_full_mention</th>\n",
       "      <th>mention_candidate_pools_page_ids</th>\n",
       "      <th>mention_candidate_pools_item_ids</th>\n",
       "      <th>candidate_pools_titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>EU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>eu</td>\n",
       "      <td>[9317, 9239, 21347120, 9477, 1882861, 3261189,...</td>\n",
       "      <td>[458, 46, 211593, 1396, 363404, 3327447, 40537...</td>\n",
       "      <td>['European_Union', 'Europe', 'Eu,_Seine-Mariti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>German</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Germany</td>\n",
       "      <td>11867.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>german</td>\n",
       "      <td>[11867, 11884, 152735, 21212, 12674, 290327, 1...</td>\n",
       "      <td>[183, 188, 42884, 7318, 43287, 141817, 181287,...</td>\n",
       "      <td>['Germany', 'German_language', 'Germans', 'Naz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>British</td>\n",
       "      <td>http://en.wikipedia.org/wiki/United_Kingdom</td>\n",
       "      <td>31717.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>british</td>\n",
       "      <td>[31717, 19097669, 13530298, 4721, 158019, 1522...</td>\n",
       "      <td>[145, 842438, 23666, 8680, 161885, 174193, 354...</td>\n",
       "      <td>['United_Kingdom', 'British_people', 'Great_Br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>Peter Blackburn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Peter Blackburn', 'BRUSSELS', 'European Comm...</td>\n",
       "      <td>peter blackburn</td>\n",
       "      <td>[56783206, 9643132, 56873217]</td>\n",
       "      <td>[2073954, 7172840, 26634508]</td>\n",
       "      <td>['Peter_Blackburn_(badminton)', 'Peter_Blackbu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>Peter Blackburn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Peter Blackburn', 'BRUSSELS', 'European Comm...</td>\n",
       "      <td>peter blackburn</td>\n",
       "      <td>[56783206, 9643132, 56873217]</td>\n",
       "      <td>[2073954, 7172840, 26634508]</td>\n",
       "      <td>['Peter_Blackburn_(badminton)', 'Peter_Blackbu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B</td>\n",
       "      <td>BRUSSELS</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Brussels</td>\n",
       "      <td>3708.0</td>\n",
       "      <td>Brussels</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Peter Blackburn', 'BRUSSELS', 'European Comm...</td>\n",
       "      <td>brussels</td>\n",
       "      <td>[3708, 575501, 1437181, 269753, 4152470, 23283...</td>\n",
       "      <td>[240, 239, 1050331, 28934, 800587, 994375, 142...</td>\n",
       "      <td>['Brussels', 'City_of_Brussels', 'R.W.D.M._Bru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B</td>\n",
       "      <td>European Commission</td>\n",
       "      <td>http://en.wikipedia.org/wiki/European_Commission</td>\n",
       "      <td>9974.0</td>\n",
       "      <td>European Commission</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Peter Blackburn', 'BRUSSELS', 'European Comm...</td>\n",
       "      <td>european commission</td>\n",
       "      <td>[9974, 9974, 24468, 1130631, 1549462, 656283, ...</td>\n",
       "      <td>[8880, 8880, 8882, 388354, 1780232, 2661677, 8...</td>\n",
       "      <td>['European_Commission', 'European_Commission',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I</td>\n",
       "      <td>European Commission</td>\n",
       "      <td>http://en.wikipedia.org/wiki/European_Commission</td>\n",
       "      <td>9974.0</td>\n",
       "      <td>European Commission</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Peter Blackburn', 'BRUSSELS', 'European Comm...</td>\n",
       "      <td>european commission</td>\n",
       "      <td>[9974, 9974, 24468, 1130631, 1549462, 656283, ...</td>\n",
       "      <td>[8880, 8880, 8882, 388354, 1780232, 2661677, 8...</td>\n",
       "      <td>['European_Commission', 'European_Commission',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B</td>\n",
       "      <td>German</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Germany</td>\n",
       "      <td>11867.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Peter Blackburn', 'BRUSSELS', 'European Comm...</td>\n",
       "      <td>german</td>\n",
       "      <td>[11867, 11884, 152735, 21212, 12674, 290327, 1...</td>\n",
       "      <td>[183, 188, 42884, 7318, 43287, 141817, 181287,...</td>\n",
       "      <td>['Germany', 'German_language', 'Germans', 'Naz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B</td>\n",
       "      <td>British</td>\n",
       "      <td>http://en.wikipedia.org/wiki/United_Kingdom</td>\n",
       "      <td>31717.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Peter Blackburn', 'BRUSSELS', 'European Comm...</td>\n",
       "      <td>british</td>\n",
       "      <td>[31717, 19097669, 13530298, 4721, 158019, 1522...</td>\n",
       "      <td>[145, 842438, 23666, 8680, 161885, 174193, 354...</td>\n",
       "      <td>['United_Kingdom', 'British_people', 'Great_Br...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mention         full_mention  \\\n",
       "0       B                   EU   \n",
       "1       B               German   \n",
       "2       B              British   \n",
       "3       B      Peter Blackburn   \n",
       "4       I      Peter Blackburn   \n",
       "5       B             BRUSSELS   \n",
       "6       B  European Commission   \n",
       "7       I  European Commission   \n",
       "8       B               German   \n",
       "9       B              British   \n",
       "\n",
       "                                      wikipedia_URL  wikipedia_page_ID  \\\n",
       "0                                               NaN                NaN   \n",
       "1              http://en.wikipedia.org/wiki/Germany            11867.0   \n",
       "2       http://en.wikipedia.org/wiki/United_Kingdom            31717.0   \n",
       "3                                               NaN                NaN   \n",
       "4                                               NaN                NaN   \n",
       "5             http://en.wikipedia.org/wiki/Brussels             3708.0   \n",
       "6  http://en.wikipedia.org/wiki/European_Commission             9974.0   \n",
       "7  http://en.wikipedia.org/wiki/European_Commission             9974.0   \n",
       "8              http://en.wikipedia.org/wiki/Germany            11867.0   \n",
       "9       http://en.wikipedia.org/wiki/United_Kingdom            31717.0   \n",
       "\n",
       "       wikipedia_title  sentence_id  doc_id  \\\n",
       "0                  NaN            0       0   \n",
       "1              Germany            0       0   \n",
       "2       United Kingdom            0       0   \n",
       "3                  NaN            1       0   \n",
       "4                  NaN            1       0   \n",
       "5             Brussels            1       0   \n",
       "6  European Commission            1       0   \n",
       "7  European Commission            1       0   \n",
       "8              Germany            1       0   \n",
       "9       United Kingdom            1       0   \n",
       "\n",
       "                                  congruent_mentions    norm_full_mention  \\\n",
       "0                        ['EU', 'German', 'British']                   eu   \n",
       "1                        ['EU', 'German', 'British']               german   \n",
       "2                        ['EU', 'German', 'British']              british   \n",
       "3  ['Peter Blackburn', 'BRUSSELS', 'European Comm...      peter blackburn   \n",
       "4  ['Peter Blackburn', 'BRUSSELS', 'European Comm...      peter blackburn   \n",
       "5  ['Peter Blackburn', 'BRUSSELS', 'European Comm...             brussels   \n",
       "6  ['Peter Blackburn', 'BRUSSELS', 'European Comm...  european commission   \n",
       "7  ['Peter Blackburn', 'BRUSSELS', 'European Comm...  european commission   \n",
       "8  ['Peter Blackburn', 'BRUSSELS', 'European Comm...               german   \n",
       "9  ['Peter Blackburn', 'BRUSSELS', 'European Comm...              british   \n",
       "\n",
       "                    mention_candidate_pools_page_ids  \\\n",
       "0  [9317, 9239, 21347120, 9477, 1882861, 3261189,...   \n",
       "1  [11867, 11884, 152735, 21212, 12674, 290327, 1...   \n",
       "2  [31717, 19097669, 13530298, 4721, 158019, 1522...   \n",
       "3                      [56783206, 9643132, 56873217]   \n",
       "4                      [56783206, 9643132, 56873217]   \n",
       "5  [3708, 575501, 1437181, 269753, 4152470, 23283...   \n",
       "6  [9974, 9974, 24468, 1130631, 1549462, 656283, ...   \n",
       "7  [9974, 9974, 24468, 1130631, 1549462, 656283, ...   \n",
       "8  [11867, 11884, 152735, 21212, 12674, 290327, 1...   \n",
       "9  [31717, 19097669, 13530298, 4721, 158019, 1522...   \n",
       "\n",
       "                    mention_candidate_pools_item_ids  \\\n",
       "0  [458, 46, 211593, 1396, 363404, 3327447, 40537...   \n",
       "1  [183, 188, 42884, 7318, 43287, 141817, 181287,...   \n",
       "2  [145, 842438, 23666, 8680, 161885, 174193, 354...   \n",
       "3                       [2073954, 7172840, 26634508]   \n",
       "4                       [2073954, 7172840, 26634508]   \n",
       "5  [240, 239, 1050331, 28934, 800587, 994375, 142...   \n",
       "6  [8880, 8880, 8882, 388354, 1780232, 2661677, 8...   \n",
       "7  [8880, 8880, 8882, 388354, 1780232, 2661677, 8...   \n",
       "8  [183, 188, 42884, 7318, 43287, 141817, 181287,...   \n",
       "9  [145, 842438, 23666, 8680, 161885, 174193, 354...   \n",
       "\n",
       "                              candidate_pools_titles  \n",
       "0  ['European_Union', 'Europe', 'Eu,_Seine-Mariti...  \n",
       "1  ['Germany', 'German_language', 'Germans', 'Naz...  \n",
       "2  ['United_Kingdom', 'British_people', 'Great_Br...  \n",
       "3  ['Peter_Blackburn_(badminton)', 'Peter_Blackbu...  \n",
       "4  ['Peter_Blackburn_(badminton)', 'Peter_Blackbu...  \n",
       "5  ['Brussels', 'City_of_Brussels', 'R.W.D.M._Bru...  \n",
       "6  ['European_Commission', 'European_Commission',...  \n",
       "7  ['European_Commission', 'European_Commission',...  \n",
       "8  ['Germany', 'German_language', 'Germans', 'Naz...  \n",
       "9  ['United_Kingdom', 'British_people', 'Great_Br...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base path to input\n",
    "preds_path = '../../predictions/'\n",
    "\n",
    "#instead of using wikipedia2vec sim candidate pools, use anchor link\n",
    "entity_disambiguation2 = pd.read_csv(os.path.join(preds_path, \"anchortext_frequency.csv\"), delimiter=\",\")\n",
    "entity_disambiguation2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29312"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm length\n",
    "len(entity_disambiguation2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "#since it's a bit too large, we'll use the same as in the smaller dataset: first 1000 rows\n",
    "entity_disambiguation_new = entity_disambiguation2[:1000].copy()\n",
    "print(len(entity_disambiguation_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Saved Candidate Pool\n",
    "\n",
    "Candidate pools when exported are typically stored as the string of a list. The below function parses the string back into a list with proper formatted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['European_Union',\n",
       " 'Europe',\n",
       " 'Eu,_Seine-Maritime',\n",
       " 'Europium',\n",
       " 'Citizenship_of_the_European_Union',\n",
       " 'United_Left_(Galicia)',\n",
       " 'EU_(group)',\n",
       " 'European_Union_law',\n",
       " 'Eu_station',\n",
       " 'Entropy']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "entity_disambiguation_new['candidate_pools_titles'][0][2:-2].split(\"', '\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse list as string\n",
    "def parse_list_string(list_string, value_type=int):\n",
    "    \n",
    "    parsed_list = []\n",
    "    \n",
    "    # If candidate pool is empty\n",
    "    if list_string == \"[]\" or isinstance(list_string, float):\n",
    "        pass\n",
    "    # Else parse\n",
    "    else:\n",
    "        # Parses lists of titles as strings\n",
    "        if value_type==str:\n",
    "            # Eliminate bracket and parenthesis on either side, split by comma pattern\n",
    "            parsed_list = re.split(\"', '|\\\", \\\"|', \\\"|\\\", \\'\", list_string[2:-2])\n",
    "\n",
    "        # Parses lists of IDs as ints\n",
    "        elif value_type==int:\n",
    "            # Eliminate brackets and convert each number from string to int\n",
    "            parsed_list = list(map(int, list_string[1:-1].split(', ')))\n",
    "            \n",
    "        \n",
    "    return parsed_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['European_Union',\n",
       " 'Europe',\n",
       " 'Eu,_Seine-Maritime',\n",
       " 'Europium',\n",
       " 'Citizenship_of_the_European_Union',\n",
       " 'United_Left_(Galicia)',\n",
       " 'EU_(group)',\n",
       " 'European_Union_law',\n",
       " 'Eu_station',\n",
       " 'Entropy']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually test function\n",
    "# 0 is the hard one. See how some value is stored with '' and some with \"\". Unsure why.\n",
    "parse_list_string(entity_disambiguation_new['candidate_pools_titles'][0], value_type=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [European_Union, Europe, Eu,_Seine-Maritime, E...\n",
       "1    [Germany, German_language, Germans, Nazi_Germa...\n",
       "2    [United_Kingdom, British_people, Great_Britain...\n",
       "Name: candidate_pools_titles, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply defined function\n",
    "parsed_candidate_pool = entity_disambiguation_new['candidate_pools_titles'].apply(parse_list_string, value_type=str)\n",
    "entity_disambiguation_new['candidate_pools_titles'] = parsed_candidate_pool\n",
    "entity_disambiguation_new['candidate_pools_titles'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [458, 46, 211593, 1396, 363404, 3327447, 40537...\n",
       "1    [183, 188, 42884, 7318, 43287, 141817, 181287,...\n",
       "2    [145, 842438, 23666, 8680, 161885, 174193, 354...\n",
       "Name: mention_candidate_pools_item_ids, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply defined function\n",
    "parsed_candidate_pool = entity_disambiguation_new['mention_candidate_pools_item_ids'].apply(parse_list_string, value_type=int)\n",
    "entity_disambiguation_new['mention_candidate_pools_item_ids'] = parsed_candidate_pool\n",
    "entity_disambiguation_new['mention_candidate_pools_item_ids'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [9317, 9239, 21347120, 9477, 1882861, 3261189,...\n",
       "1    [11867, 11884, 152735, 21212, 12674, 290327, 1...\n",
       "2    [31717, 19097669, 13530298, 4721, 158019, 1522...\n",
       "Name: mention_candidate_pools_page_ids, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply defined function\n",
    "parsed_candidate_pool = entity_disambiguation_new['mention_candidate_pools_page_ids'].apply(parse_list_string, value_type=int)\n",
    "entity_disambiguation_new['mention_candidate_pools_page_ids'] = parsed_candidate_pool\n",
    "entity_disambiguation_new['mention_candidate_pools_page_ids'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>6199</td>\n",
       "      <td>Anarchism</td>\n",
       "      <td>31335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>38404</td>\n",
       "      <td>Autism</td>\n",
       "      <td>49693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>101038</td>\n",
       "      <td>Albedo</td>\n",
       "      <td>14573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_id  item_id      title  views\n",
       "0       12     6199  Anarchism  31335\n",
       "1       25    38404     Autism  49693\n",
       "2       39   101038     Albedo  14573"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Integrate page.csv\n",
    "page_df = pd.read_csv(\"../../data/kdkg/page.csv\", delimiter=',')\n",
    "assert type(page_df) is not None\n",
    "display(page_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1352883</th>\n",
       "      <td>9808786</td>\n",
       "      <td>3308075</td>\n",
       "      <td>Russians in the United Kingdom</td>\n",
       "      <td>684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         page_id  item_id                           title  views\n",
       "1352883  9808786  3308075  Russians in the United Kingdom    684"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test manual search\n",
    "page_df[page_df['title'] == \"Russians in the United Kingdom\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>full_mention</th>\n",
       "      <th>wikipedia_URL</th>\n",
       "      <th>wikipedia_page_ID</th>\n",
       "      <th>wikipedia_title</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>congruent_mentions</th>\n",
       "      <th>norm_full_mention</th>\n",
       "      <th>mention_candidate_pools_page_ids</th>\n",
       "      <th>mention_candidate_pools_item_ids</th>\n",
       "      <th>candidate_pools_titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>EU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>eu</td>\n",
       "      <td>[9317, 9239, 21347120, 9477, 1882861, 3261189,...</td>\n",
       "      <td>[458, 46, 211593, 1396, 363404, 3327447, 40537...</td>\n",
       "      <td>[European_Union, Europe, Eu,_Seine-Maritime, E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>German</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Germany</td>\n",
       "      <td>11867.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>german</td>\n",
       "      <td>[11867, 11884, 152735, 21212, 12674, 290327, 1...</td>\n",
       "      <td>[183, 188, 42884, 7318, 43287, 141817, 181287,...</td>\n",
       "      <td>[Germany, German_language, Germans, Nazi_Germa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>British</td>\n",
       "      <td>http://en.wikipedia.org/wiki/United_Kingdom</td>\n",
       "      <td>31717.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>british</td>\n",
       "      <td>[31717, 19097669, 13530298, 4721, 158019, 1522...</td>\n",
       "      <td>[145, 842438, 23666, 8680, 161885, 174193, 354...</td>\n",
       "      <td>[United_Kingdom, British_people, Great_Britain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>Peter Blackburn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Peter Blackburn', 'BRUSSELS', 'European Comm...</td>\n",
       "      <td>peter blackburn</td>\n",
       "      <td>[56783206, 9643132, 56873217]</td>\n",
       "      <td>[2073954, 7172840, 26634508]</td>\n",
       "      <td>[Peter_Blackburn_(badminton), Peter_Blackburn_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>Peter Blackburn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Peter Blackburn', 'BRUSSELS', 'European Comm...</td>\n",
       "      <td>peter blackburn</td>\n",
       "      <td>[56783206, 9643132, 56873217]</td>\n",
       "      <td>[2073954, 7172840, 26634508]</td>\n",
       "      <td>[Peter_Blackburn_(badminton), Peter_Blackburn_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mention     full_mention                                wikipedia_URL  \\\n",
       "0       B               EU                                          NaN   \n",
       "1       B           German         http://en.wikipedia.org/wiki/Germany   \n",
       "2       B          British  http://en.wikipedia.org/wiki/United_Kingdom   \n",
       "3       B  Peter Blackburn                                          NaN   \n",
       "4       I  Peter Blackburn                                          NaN   \n",
       "\n",
       "   wikipedia_page_ID wikipedia_title  sentence_id  doc_id  \\\n",
       "0                NaN             NaN            0       0   \n",
       "1            11867.0         Germany            0       0   \n",
       "2            31717.0  United Kingdom            0       0   \n",
       "3                NaN             NaN            1       0   \n",
       "4                NaN             NaN            1       0   \n",
       "\n",
       "                                  congruent_mentions norm_full_mention  \\\n",
       "0                        ['EU', 'German', 'British']                eu   \n",
       "1                        ['EU', 'German', 'British']            german   \n",
       "2                        ['EU', 'German', 'British']           british   \n",
       "3  ['Peter Blackburn', 'BRUSSELS', 'European Comm...   peter blackburn   \n",
       "4  ['Peter Blackburn', 'BRUSSELS', 'European Comm...   peter blackburn   \n",
       "\n",
       "                    mention_candidate_pools_page_ids  \\\n",
       "0  [9317, 9239, 21347120, 9477, 1882861, 3261189,...   \n",
       "1  [11867, 11884, 152735, 21212, 12674, 290327, 1...   \n",
       "2  [31717, 19097669, 13530298, 4721, 158019, 1522...   \n",
       "3                      [56783206, 9643132, 56873217]   \n",
       "4                      [56783206, 9643132, 56873217]   \n",
       "\n",
       "                    mention_candidate_pools_item_ids  \\\n",
       "0  [458, 46, 211593, 1396, 363404, 3327447, 40537...   \n",
       "1  [183, 188, 42884, 7318, 43287, 141817, 181287,...   \n",
       "2  [145, 842438, 23666, 8680, 161885, 174193, 354...   \n",
       "3                       [2073954, 7172840, 26634508]   \n",
       "4                       [2073954, 7172840, 26634508]   \n",
       "\n",
       "                              candidate_pools_titles  \n",
       "0  [European_Union, Europe, Eu,_Seine-Maritime, E...  \n",
       "1  [Germany, German_language, Germans, Nazi_Germa...  \n",
       "2  [United_Kingdom, British_people, Great_Britain...  \n",
       "3  [Peter_Blackburn_(badminton), Peter_Blackburn_...  \n",
       "4  [Peter_Blackburn_(badminton), Peter_Blackburn_...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_disambiguation_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append congruent mention ids\n",
    "#Here we take 'anchor link most viewed' as 'ground truth' labels\n",
    "\n",
    "congruent_mention_ids_anchor_link = []\n",
    "for i in range(len(entity_disambiguation_new)):\n",
    "    full_mention = entity_disambiguation_new.full_mention[i]\n",
    "    sentence_id = entity_disambiguation_new.sentence_id[i]\n",
    "    new_df = entity_disambiguation_new[entity_disambiguation_new.sentence_id==sentence_id]\n",
    "    new_df = new_df[new_df.full_mention!=full_mention]\n",
    "    ids = new_df.mention_candidate_pools_item_ids.values\n",
    "    ids_final = []\n",
    "    for j in ids:\n",
    "        try:\n",
    "            ids_final.append(j[0])\n",
    "        except:\n",
    "            pass\n",
    "    congruent_mention_ids_anchor_link.append(ids_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>full_mention</th>\n",
       "      <th>wikipedia_URL</th>\n",
       "      <th>wikipedia_page_ID</th>\n",
       "      <th>wikipedia_title</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>congruent_mentions</th>\n",
       "      <th>norm_full_mention</th>\n",
       "      <th>mention_candidate_pools_page_ids</th>\n",
       "      <th>mention_candidate_pools_item_ids</th>\n",
       "      <th>candidate_pools_titles</th>\n",
       "      <th>congruent_mention_ids_anchor_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>EU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>eu</td>\n",
       "      <td>[9317, 9239, 21347120, 9477, 1882861, 3261189,...</td>\n",
       "      <td>[458, 46, 211593, 1396, 363404, 3327447, 40537...</td>\n",
       "      <td>[European_Union, Europe, Eu,_Seine-Maritime, E...</td>\n",
       "      <td>[183, 145]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>German</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Germany</td>\n",
       "      <td>11867.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>german</td>\n",
       "      <td>[11867, 11884, 152735, 21212, 12674, 290327, 1...</td>\n",
       "      <td>[183, 188, 42884, 7318, 43287, 141817, 181287,...</td>\n",
       "      <td>[Germany, German_language, Germans, Nazi_Germa...</td>\n",
       "      <td>[458, 145]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>British</td>\n",
       "      <td>http://en.wikipedia.org/wiki/United_Kingdom</td>\n",
       "      <td>31717.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>british</td>\n",
       "      <td>[31717, 19097669, 13530298, 4721, 158019, 1522...</td>\n",
       "      <td>[145, 842438, 23666, 8680, 161885, 174193, 354...</td>\n",
       "      <td>[United_Kingdom, British_people, Great_Britain...</td>\n",
       "      <td>[458, 183]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>Peter Blackburn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Peter Blackburn', 'BRUSSELS', 'European Comm...</td>\n",
       "      <td>peter blackburn</td>\n",
       "      <td>[56783206, 9643132, 56873217]</td>\n",
       "      <td>[2073954, 7172840, 26634508]</td>\n",
       "      <td>[Peter_Blackburn_(badminton), Peter_Blackburn_...</td>\n",
       "      <td>[240, 8880, 8880, 183, 145]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>Peter Blackburn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Peter Blackburn', 'BRUSSELS', 'European Comm...</td>\n",
       "      <td>peter blackburn</td>\n",
       "      <td>[56783206, 9643132, 56873217]</td>\n",
       "      <td>[2073954, 7172840, 26634508]</td>\n",
       "      <td>[Peter_Blackburn_(badminton), Peter_Blackburn_...</td>\n",
       "      <td>[240, 8880, 8880, 183, 145]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mention     full_mention                                wikipedia_URL  \\\n",
       "0       B               EU                                          NaN   \n",
       "1       B           German         http://en.wikipedia.org/wiki/Germany   \n",
       "2       B          British  http://en.wikipedia.org/wiki/United_Kingdom   \n",
       "3       B  Peter Blackburn                                          NaN   \n",
       "4       I  Peter Blackburn                                          NaN   \n",
       "\n",
       "   wikipedia_page_ID wikipedia_title  sentence_id  doc_id  \\\n",
       "0                NaN             NaN            0       0   \n",
       "1            11867.0         Germany            0       0   \n",
       "2            31717.0  United Kingdom            0       0   \n",
       "3                NaN             NaN            1       0   \n",
       "4                NaN             NaN            1       0   \n",
       "\n",
       "                                  congruent_mentions norm_full_mention  \\\n",
       "0                        ['EU', 'German', 'British']                eu   \n",
       "1                        ['EU', 'German', 'British']            german   \n",
       "2                        ['EU', 'German', 'British']           british   \n",
       "3  ['Peter Blackburn', 'BRUSSELS', 'European Comm...   peter blackburn   \n",
       "4  ['Peter Blackburn', 'BRUSSELS', 'European Comm...   peter blackburn   \n",
       "\n",
       "                    mention_candidate_pools_page_ids  \\\n",
       "0  [9317, 9239, 21347120, 9477, 1882861, 3261189,...   \n",
       "1  [11867, 11884, 152735, 21212, 12674, 290327, 1...   \n",
       "2  [31717, 19097669, 13530298, 4721, 158019, 1522...   \n",
       "3                      [56783206, 9643132, 56873217]   \n",
       "4                      [56783206, 9643132, 56873217]   \n",
       "\n",
       "                    mention_candidate_pools_item_ids  \\\n",
       "0  [458, 46, 211593, 1396, 363404, 3327447, 40537...   \n",
       "1  [183, 188, 42884, 7318, 43287, 141817, 181287,...   \n",
       "2  [145, 842438, 23666, 8680, 161885, 174193, 354...   \n",
       "3                       [2073954, 7172840, 26634508]   \n",
       "4                       [2073954, 7172840, 26634508]   \n",
       "\n",
       "                              candidate_pools_titles  \\\n",
       "0  [European_Union, Europe, Eu,_Seine-Maritime, E...   \n",
       "1  [Germany, German_language, Germans, Nazi_Germa...   \n",
       "2  [United_Kingdom, British_people, Great_Britain...   \n",
       "3  [Peter_Blackburn_(badminton), Peter_Blackburn_...   \n",
       "4  [Peter_Blackburn_(badminton), Peter_Blackburn_...   \n",
       "\n",
       "  congruent_mention_ids_anchor_link  \n",
       "0                        [183, 145]  \n",
       "1                        [458, 145]  \n",
       "2                        [458, 183]  \n",
       "3       [240, 8880, 8880, 183, 145]  \n",
       "4       [240, 8880, 8880, 183, 145]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Append the produced congruent mention ids\n",
    "entity_disambiguation_new['congruent_mention_ids_anchor_link'] = congruent_mention_ids_anchor_link\n",
    "entity_disambiguation_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.96402877697841% of true ids are in candidate ids\n"
     ]
    }
   ],
   "source": [
    "#how many true ids are actually in candidate ids\n",
    "true = entity_disambiguation_new.wikipedia_page_ID\n",
    "notnull = np.where(~np.isnan(true))[0]\n",
    "true = [true[i] for i in notnull]\n",
    "can = entity_disambiguation_new.mention_candidate_pools_page_ids.values\n",
    "can = [can[i] for i in notnull]\n",
    "in_or_not = [true[i] in can[i] for i in range(len(true))]\n",
    "\n",
    "print('{}% of true ids are in candidate ids'.format(sum(in_or_not)/len(true)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_item_id</th>\n",
       "      <th>edge_property_id</th>\n",
       "      <th>target_item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>36906466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>279</td>\n",
       "      <td>3695190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>398</td>\n",
       "      <td>497745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_item_id  edge_property_id  target_item_id\n",
       "0               1                31        36906466\n",
       "1               1               279         3695190\n",
       "2               1               398          497745"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Integrate statements.csv\n",
    "#This is our knowledge graph\n",
    "statements_df = pd.read_csv(\"../../data/kdkg/statements.csv\", delimiter=',')\n",
    "assert type(statements_df) is not None\n",
    "display(statements_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141206853"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(statements_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221 sentences in our data.\n"
     ]
    }
   ],
   "source": [
    "# How many sentences exist in our data\n",
    "sentence_count = max(entity_disambiguation_new['sentence_id'])\n",
    "print(\"{:,} sentences in our data.\".format(sentence_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Modeling\n",
    "\n",
    "### 2.1 Shortest Path Approach\n",
    "\n",
    "Generate Graph of Dendrites\n",
    "\n",
    "From this pool of candidate IDs, we are going to generate our one-degree in both direction dendritic graph from `statements.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Values for 1: German\n",
      "Testing dataframe search time\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_item_id</th>\n",
       "      <th>edge_property_id</th>\n",
       "      <th>target_item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>371</td>\n",
       "      <td>16</td>\n",
       "      <td>530</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>16</td>\n",
       "      <td>530</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>16</td>\n",
       "      <td>530</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>433</td>\n",
       "      <td>16</td>\n",
       "      <td>807</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>434</td>\n",
       "      <td>16</td>\n",
       "      <td>807</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141201967</td>\n",
       "      <td>77254864</td>\n",
       "      <td>1412</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141202910</td>\n",
       "      <td>77255368</td>\n",
       "      <td>17</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141205122</td>\n",
       "      <td>77256485</td>\n",
       "      <td>921</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141205152</td>\n",
       "      <td>77256499</td>\n",
       "      <td>27</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141206291</td>\n",
       "      <td>77257096</td>\n",
       "      <td>17</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2187009 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           source_item_id  edge_property_id  target_item_id\n",
       "371                    16               530             145\n",
       "375                    16               530             183\n",
       "397                    16               530             458\n",
       "433                    16               807             145\n",
       "434                    16               807             145\n",
       "...                   ...               ...             ...\n",
       "141201967        77254864              1412             188\n",
       "141202910        77255368                17             183\n",
       "141205122        77256485               921             183\n",
       "141205152        77256499                27             145\n",
       "141206291        77257096                17             145\n",
       "\n",
       "[2187009 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.15 s, sys: 5.42 s, total: 9.57 s\n",
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Manually test on one candidate pool\n",
    "rand_idx = 1\n",
    "print(\"Generating Values for {}: {}\".format(rand_idx, entity_disambiguation_new['full_mention'][rand_idx]))\n",
    "print('Testing dataframe search time')\n",
    "candidate_pool = entity_disambiguation_new['mention_candidate_pools_item_ids'][rand_idx] + entity_disambiguation_new['congruent_mention_ids_anchor_link'][rand_idx]\n",
    "candidate_pool_dendrites = statements_df[statements_df['source_item_id'].isin(candidate_pool)\\\n",
    "             | statements_df['target_item_id'].isin(candidate_pool)]\n",
    "display(candidate_pool_dendrites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Dendritic Graph using NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import NetworkX\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing networkx object creation time\n",
      "CPU times: user 18.4 s, sys: 4.03 s, total: 22.4 s\n",
      "Wall time: 23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create NX graph from Pandas dataframe\n",
    "print('testing networkx object creation time')\n",
    "G = nx.from_pandas_edgelist(candidate_pool_dendrites,\n",
    "                           source='source_item_id', target='target_item_id',\n",
    "                           edge_attr=True, create_using=nx.MultiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes:  2000602\n",
      "Number of links:  2187009\n"
     ]
    }
   ],
   "source": [
    "# Print number of nodes in graph\n",
    "print(\"Number of nodes: \", G.number_of_nodes())\n",
    "print(\"Number of links: \", G.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Distance Matrix\n",
    "\n",
    "By taking every candidate and computing the distance to every other candidate, we can create a distance matrix showing which nodes (if any) are closer to each other. We will then select the most connected or closest connected node from the candidate pool as the predicted entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix will be of size 10x2\n"
     ]
    }
   ],
   "source": [
    "h = len(entity_disambiguation_new['mention_candidate_pools_item_ids'][rand_idx])\n",
    "w = len(entity_disambiguation_new['congruent_mention_ids_anchor_link'][rand_idx])\n",
    "print(\"Matrix will be of size {}x{}\".format(h, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 329 ms, sys: 36.3 ms, total: 365 ms\n",
      "Wall time: 364 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Iteratively create matrix\n",
    "shortest_path_matrix = []\n",
    "for candidate_src in entity_disambiguation_new['mention_candidate_pools_item_ids'][rand_idx]:\n",
    "    shortest_paths = []\n",
    "#     print(\"Source: \", candidate_src)\n",
    "    for candidate_trgt in entity_disambiguation_new['congruent_mention_ids_anchor_link'][rand_idx]:\n",
    "#         print(\"Target: \", candidate_trgt)\n",
    "        if candidate_src is None or candidate_trgt is None:\n",
    "            shortest_paths.append(None)\n",
    "        else:\n",
    "            try:\n",
    "                shortest_paths.append(int(nx.shortest_path_length(G, source=candidate_src, target=candidate_trgt)))\n",
    "            except:\n",
    "                shortest_paths.append(-1)\n",
    "    shortest_path_matrix.append(shortest_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_261307ce_3d5d_11eb_b284_acde48001122row0_col0 {\n",
       "            background:  skyblue;\n",
       "        }    #T_261307ce_3d5d_11eb_b284_acde48001122row0_col1 {\n",
       "            background:  skyblue;\n",
       "        }    #T_261307ce_3d5d_11eb_b284_acde48001122row1_col0 {\n",
       "            background:  skyblue;\n",
       "        }</style><table id=\"T_261307ce_3d5d_11eb_b284_acde48001122\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >0</th>        <th class=\"col_heading level0 col1\" >1</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_261307ce_3d5d_11eb_b284_acde48001122level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_261307ce_3d5d_11eb_b284_acde48001122row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "                        <td id=\"T_261307ce_3d5d_11eb_b284_acde48001122row0_col1\" class=\"data row0 col1\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_261307ce_3d5d_11eb_b284_acde48001122level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_261307ce_3d5d_11eb_b284_acde48001122row1_col0\" class=\"data row1 col0\" >1</td>\n",
       "                        <td id=\"T_261307ce_3d5d_11eb_b284_acde48001122row1_col1\" class=\"data row1 col1\" >2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_261307ce_3d5d_11eb_b284_acde48001122level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_261307ce_3d5d_11eb_b284_acde48001122row2_col0\" class=\"data row2 col0\" >2</td>\n",
       "                        <td id=\"T_261307ce_3d5d_11eb_b284_acde48001122row2_col1\" class=\"data row2 col1\" >2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_261307ce_3d5d_11eb_b284_acde48001122level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_261307ce_3d5d_11eb_b284_acde48001122row3_col0\" class=\"data row3 col0\" >2</td>\n",
       "                        <td id=\"T_261307ce_3d5d_11eb_b284_acde48001122row3_col1\" class=\"data row3 col1\" >2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_261307ce_3d5d_11eb_b284_acde48001122level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_261307ce_3d5d_11eb_b284_acde48001122row4_col0\" class=\"data row4 col0\" >2</td>\n",
       "                        <td id=\"T_261307ce_3d5d_11eb_b284_acde48001122row4_col1\" class=\"data row4 col1\" >2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_261307ce_3d5d_11eb_b284_acde48001122level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_261307ce_3d5d_11eb_b284_acde48001122row5_col0\" class=\"data row5 col0\" >2</td>\n",
       "                        <td id=\"T_261307ce_3d5d_11eb_b284_acde48001122row5_col1\" class=\"data row5 col1\" >2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_261307ce_3d5d_11eb_b284_acde48001122level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_261307ce_3d5d_11eb_b284_acde48001122row6_col0\" class=\"data row6 col0\" >3</td>\n",
       "                        <td id=\"T_261307ce_3d5d_11eb_b284_acde48001122row6_col1\" class=\"data row6 col1\" >2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_261307ce_3d5d_11eb_b284_acde48001122level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_261307ce_3d5d_11eb_b284_acde48001122row7_col0\" class=\"data row7 col0\" >2</td>\n",
       "                        <td id=\"T_261307ce_3d5d_11eb_b284_acde48001122row7_col1\" class=\"data row7 col1\" >2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_261307ce_3d5d_11eb_b284_acde48001122level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_261307ce_3d5d_11eb_b284_acde48001122row8_col0\" class=\"data row8 col0\" >3</td>\n",
       "                        <td id=\"T_261307ce_3d5d_11eb_b284_acde48001122row8_col1\" class=\"data row8 col1\" >3</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_261307ce_3d5d_11eb_b284_acde48001122level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_261307ce_3d5d_11eb_b284_acde48001122row9_col0\" class=\"data row9 col0\" >3</td>\n",
       "                        <td id=\"T_261307ce_3d5d_11eb_b284_acde48001122row9_col1\" class=\"data row9 col1\" >2</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7faf9c7f9cd0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display matrix with closest nodes highlighted\n",
    "shortest_path_df = pd.DataFrame(shortest_path_matrix)\n",
    "shortest_path_df.style.apply(lambda x: [\"background: skyblue\" if v == 1 else \"\" for v in x], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    1.5\n",
       "2    2.0\n",
       "3    2.0\n",
       "4    2.0\n",
       "5    2.0\n",
       "7    2.0\n",
       "6    2.5\n",
       "9    2.5\n",
       "8    3.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Values for 1: German\n",
      "Prediction would be ['Germany']\n"
     ]
    }
   ],
   "source": [
    "# Count node with lowest average distance\n",
    "rank_by_mean_path = np.mean(shortest_path_df, axis=1).sort_values(ascending=True)\n",
    "display(rank_by_mean_path)\n",
    "# Filter out -1 values representing no path\n",
    "prediction_by_mean_rank = rank_by_mean_path[rank_by_mean_path >= 0].index[0]\n",
    "print(\"Generating Values for {}: {}\".format(rand_idx, entity_disambiguation_new['full_mention'][rand_idx]))\n",
    "print(\"Prediction would be {}\".format(page_df[page_df['item_id'] == candidate_pool[prediction_by_mean_rank]]['title'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test running the model on a sentence\n",
    "Here we try predicting a whole sentence instead of single mentions in order to save time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 entities in total in this sentence (including candidates)\n"
     ]
    }
   ],
   "source": [
    "#candidate pool: all entities and candidates within this one sentence\n",
    "\n",
    "sentence_id = 2\n",
    "sentence_df = entity_disambiguation_new[entity_disambiguation_new.sentence_id==sentence_id]\n",
    "#all candidates\n",
    "t = list(sentence_df.mention_candidate_pools_item_ids)\n",
    "candidates = [item for sublist in t for item in sublist]\n",
    "#all mentions\n",
    "t1 = list(sentence_df.congruent_mention_ids_anchor_link)\n",
    "congruence = [item for sublist in t1 for item in sublist]\n",
    "#the whole list we need from edges dataframe\n",
    "candidate_pool = candidates + congruence\n",
    "candidate_pool = list(set(candidate_pool))\n",
    "print('{} entities in total in this sentence (including candidates)'.format(len(candidate_pool)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing dataframe search time\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_item_id</th>\n",
       "      <th>edge_property_id</th>\n",
       "      <th>target_item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>371</td>\n",
       "      <td>16</td>\n",
       "      <td>530</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>16</td>\n",
       "      <td>530</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>16</td>\n",
       "      <td>530</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>433</td>\n",
       "      <td>16</td>\n",
       "      <td>807</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>434</td>\n",
       "      <td>16</td>\n",
       "      <td>807</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141201961</td>\n",
       "      <td>77254864</td>\n",
       "      <td>27</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141202910</td>\n",
       "      <td>77255368</td>\n",
       "      <td>17</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141205122</td>\n",
       "      <td>77256485</td>\n",
       "      <td>921</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141205152</td>\n",
       "      <td>77256499</td>\n",
       "      <td>27</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141206291</td>\n",
       "      <td>77257096</td>\n",
       "      <td>17</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1990365 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           source_item_id  edge_property_id  target_item_id\n",
       "371                    16               530             145\n",
       "375                    16               530             183\n",
       "397                    16               530             458\n",
       "433                    16               807             145\n",
       "434                    16               807             145\n",
       "...                   ...               ...             ...\n",
       "141201961        77254864                27             183\n",
       "141202910        77255368                17             183\n",
       "141205122        77256485               921             183\n",
       "141205152        77256499                27             145\n",
       "141206291        77257096                17             145\n",
       "\n",
       "[1990365 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.05 s, sys: 7.81 s, total: 16.9 s\n",
      "Wall time: 18.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('Testing dataframe search time')\n",
    "candidate_pool_dendrites = statements_df[statements_df['source_item_id'].isin(candidate_pool)\\\n",
    "             | statements_df['target_item_id'].isin(candidate_pool)]\n",
    "display(candidate_pool_dendrites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution time:  0.4146684686342875  mins\n"
     ]
    }
   ],
   "source": [
    "#networkx object\n",
    "\n",
    "start = time.time()\n",
    "G = nx.from_pandas_edgelist(candidate_pool_dendrites,\n",
    "                       source='source_item_id', target='target_item_id',\n",
    "                       edge_attr=True, create_using=nx.MultiGraph())\n",
    "execution_time = (time.time()-start)/60\n",
    "print('execution time: ', execution_time, ' mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create shortest path matrix\n",
    "shortest_path_matrix = []\n",
    "for candidate_src in candidates:\n",
    "    shortest_paths = []\n",
    "    for candidate_trgt in congruence:\n",
    "        if candidate_src is None or candidate_trgt is None:\n",
    "            shortest_paths.append(None)\n",
    "        else:\n",
    "            try:\n",
    "                shortest_paths.append(int(nx.shortest_path_length(G, source=candidate_src, target=candidate_trgt)))\n",
    "            except:\n",
    "                shortest_paths.append(-1)\n",
    "    shortest_path_matrix.append(shortest_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[183, 1376407, 1376407, None, None, 977566]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict on each mention\n",
    "pred = []\n",
    "for i in range(len(sentence_df)):\n",
    "    sub_candidates = sentence_df['mention_candidate_pools_item_ids'].values[i]\n",
    "    sub_candidates_indices = [candidates.index(k) for k in sub_candidates]\n",
    "    sub_congruent = sentence_df.congruent_mention_ids_anchor_link.values[i]\n",
    "    sub_congruent_indices = [congruence.index(k) for k in sub_congruent]\n",
    "    new_mtx = np.take(shortest_path_matrix, sub_candidates_indices, 0)\n",
    "    new_mtx = np.take(new_mtx, sub_congruent_indices, 1)\n",
    "    rank_by_mean_path = np.mean(new_mtx, axis=1).argsort() #lowest to highest\n",
    "    # Filter out -1 values representing no path\n",
    "    try:\n",
    "        prediction_by_mean_rank = rank_by_mean_path[0]\n",
    "    except:\n",
    "        #if we didn't find any ranks, then take the first candidate (most similar by wikipedia2vec)\n",
    "        prediction_by_mean_rank = 0\n",
    "#     print(i, sub_candidates, prediction_by_mean_rank)\n",
    "    try:\n",
    "        pred.append(sub_candidates[prediction_by_mean_rank])\n",
    "    except:\n",
    "        pred.append(None)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting on each sentence and produce accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put it all in one function\n",
    "def predict_sentence(sentence_id):\n",
    "    sentence_df = entity_disambiguation_new[entity_disambiguation_new.sentence_id==sentence_id]\n",
    "    #all candidates\n",
    "    t = list(sentence_df.mention_candidate_pools_item_ids)\n",
    "    candidates = [item for sublist in t for item in sublist]\n",
    "    #all mentions\n",
    "    t1 = list(sentence_df.congruent_mention_ids_anchor_link)\n",
    "    congruence = [item for sublist in t1 for item in sublist]\n",
    "    #the whole list we need from edges dataframe\n",
    "    candidate_pool = candidates + congruence\n",
    "    candidate_pool = list(set(candidate_pool))\n",
    "    \n",
    "    candidate_pool_dendrites = statements_df[statements_df['source_item_id'].isin(candidate_pool)\\\n",
    "         | statements_df['target_item_id'].isin(candidate_pool)]\n",
    "    \n",
    "    G = nx.from_pandas_edgelist(candidate_pool_dendrites,\n",
    "                       source='source_item_id', target='target_item_id',\n",
    "                       edge_attr=True, create_using=nx.MultiGraph())\n",
    "    \n",
    "    #create shortest path matrix\n",
    "    shortest_path_matrix = []\n",
    "    for candidate_src in candidates:\n",
    "        shortest_paths = []\n",
    "        for candidate_trgt in congruence:\n",
    "            if candidate_src is None or candidate_trgt is None:\n",
    "                shortest_paths.append(None)\n",
    "            else:\n",
    "                try:\n",
    "                    shortest_paths.append(int(nx.shortest_path_length(G, source=candidate_src, target=candidate_trgt)))\n",
    "                except:\n",
    "                    shortest_paths.append(-1)\n",
    "        shortest_path_matrix.append(shortest_paths)\n",
    "        \n",
    "    #predict on each mention\n",
    "    pred = []\n",
    "    for i in range(len(sentence_df)):\n",
    "        sub_candidates = sentence_df['mention_candidate_pools_item_ids'].values[i]\n",
    "        sub_candidates_indices = [candidates.index(k) for k in sub_candidates]\n",
    "        sub_congruent = sentence_df.congruent_mention_ids_anchor_link.values[i]\n",
    "        sub_congruent_indices = [congruence.index(k) for k in sub_congruent]\n",
    "        new_mtx = np.take(shortest_path_matrix, sub_candidates_indices, 0)\n",
    "        new_mtx = np.take(new_mtx, sub_congruent_indices, 1)\n",
    "        rank_by_mean_path = np.mean(new_mtx, axis=1).argsort() #lowest to highest\n",
    "        # Filter out -1 values representing no path\n",
    "        try:\n",
    "            prediction_by_mean_rank = rank_by_mean_path[0]\n",
    "        except:\n",
    "            prediction_by_mean_rank = 0\n",
    "        \n",
    "        try:\n",
    "            pred.append(sub_candidates[prediction_by_mean_rank])\n",
    "        except:\n",
    "            pred.append(None)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 1/50 [00:41<34:14, 41.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 2/50 [02:03<43:08, 53.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 3/50 [02:51<40:41, 51.94s/it]\u001b[A\u001b[A/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "\n",
      "\n",
      "  8%|▊         | 4/50 [02:58<29:28, 38.46s/it]\u001b[A\u001b[A/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "\n",
      "\n",
      " 10%|█         | 5/50 [03:01<21:02, 28.05s/it]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 6/50 [03:06<15:26, 21.05s/it]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 7/50 [05:13<37:55, 52.91s/it]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 8/50 [05:21<27:26, 39.20s/it]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 9/50 [05:45<23:40, 34.66s/it]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 10/50 [06:19<23:03, 34.58s/it]\u001b[A\u001b[A/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "\n",
      "\n",
      " 22%|██▏       | 11/50 [06:24<16:46, 25.81s/it]\u001b[A\u001b[A/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "\n",
      "\n",
      " 24%|██▍       | 12/50 [06:28<12:12, 19.27s/it]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 13/50 [07:15<17:00, 27.58s/it]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 14/50 [07:22<12:46, 21.30s/it]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 15/50 [07:41<12:00, 20.60s/it]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 16/50 [08:12<13:21, 23.59s/it]\u001b[A\u001b[A/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "\n",
      "\n",
      " 34%|███▍      | 17/50 [08:28<11:47, 21.43s/it]\u001b[A\u001b[A/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "\n",
      "\n",
      " 36%|███▌      | 18/50 [08:32<08:38, 16.19s/it]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 19/50 [09:09<11:34, 22.40s/it]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 20/50 [09:23<09:54, 19.83s/it]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 21/50 [12:34<34:26, 71.27s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 22/50 [12:43<24:36, 52.73s/it]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 23/50 [12:56<18:15, 40.59s/it]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 24/50 [13:14<14:39, 33.84s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 25/50 [14:11<17:04, 40.98s/it]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 26/50 [15:44<22:36, 56.50s/it]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 27/50 [15:51<15:58, 41.67s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 28/50 [16:10<12:49, 34.96s/it]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 29/50 [16:47<12:26, 35.57s/it]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 30/50 [17:05<10:05, 30.29s/it]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 31/50 [17:27<08:48, 27.81s/it]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 32/50 [17:31<06:12, 20.67s/it]\u001b[A\u001b[A/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "\n",
      "\n",
      " 66%|██████▌   | 33/50 [17:49<05:37, 19.84s/it]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 34/50 [18:11<05:25, 20.35s/it]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 35/50 [18:30<04:59, 19.95s/it]\u001b[A\u001b[A/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "\n",
      "\n",
      " 72%|███████▏  | 36/50 [18:47<04:25, 18.96s/it]\u001b[A\u001b[A/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "\n",
      "\n",
      " 74%|███████▍  | 37/50 [18:48<02:57, 13.65s/it]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 38/50 [18:52<02:10, 10.89s/it]\u001b[A\u001b[A/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "\n",
      "\n",
      " 78%|███████▊  | 39/50 [18:56<01:37,  8.86s/it]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 40/50 [19:04<01:25,  8.58s/it]\u001b[A\u001b[A/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "\n",
      "\n",
      " 82%|████████▏ | 41/50 [19:08<01:05,  7.23s/it]\u001b[A\u001b[A/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "\n",
      "\n",
      " 84%|████████▍ | 42/50 [19:12<00:50,  6.27s/it]\u001b[A\u001b[A/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "\n",
      "\n",
      " 86%|████████▌ | 43/50 [19:18<00:41,  5.95s/it]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 44/50 [19:27<00:42,  7.05s/it]\u001b[A\u001b[A/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "\n",
      "\n",
      " 90%|█████████ | 45/50 [19:28<00:25,  5.20s/it]\u001b[A\u001b[A/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/esthe/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:154: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "\n",
      "\n",
      " 92%|█████████▏| 46/50 [19:35<00:23,  5.81s/it]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 47/50 [19:41<00:17,  5.68s/it]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 48/50 [28:00<05:07, 153.71s/it]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 49/50 [28:12<01:51, 111.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 50/50 [1:13:04<00:00, 87.68s/it] \u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "#predict on our dataframe\n",
    "#also save the networkx object for later modeling on embeddings\n",
    "pred1 = []\n",
    "for i in tqdm(entity_disambiguation_new.sentence_id.unique()[:50]):\n",
    "    pred = predict_sentence(i)\n",
    "    pred1.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function that converts a list of item ids to mention texts\n",
    "def item_to_mention(l):\n",
    "    mentions = []\n",
    "    for i in l:\n",
    "        try:\n",
    "            mentions.append(page_df[page_df.item_id==i].title.values[0])\n",
    "        except:\n",
    "            mentions.append(None)\n",
    "    return mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************\n",
      "Predictive Accuracy: 60.163%\n",
      "****************************\n"
     ]
    }
   ],
   "source": [
    "#evaluate accuracy\n",
    "#first flatten our list\n",
    "pred_mention = [item for sublist in pred1 for item in sublist]\n",
    "pred_mention = item_to_mention(pred_mention)\n",
    "true = [str(i).lower() for i in entity_disambiguation_new['wikipedia_title'][:len(pred_mention)]]\n",
    "#only filter not null values and test accuracies\n",
    "notnull_new = [i for i in notnull if i<=len(true)]\n",
    "true = [true[i] for i in notnull_new]\n",
    "\n",
    "pred_mention = [str(i).lower() for i in pred_mention]\n",
    "#only filter not null values and test accuracies\n",
    "pred_mention = [pred_mention[i] for i in notnull_new]\n",
    "\n",
    "accurate_predictions = sum([true[i]==pred_mention[i] for i in range(len(true))])\n",
    "print(\"****************************\")\n",
    "print(f\"Predictive Accuracy: {round(accurate_predictions / len(true) *100, 3)}%\")\n",
    "print(\"****************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Embeddings and Euclidean distance / cosine similarity\n",
    "\n",
    "#### Example with one sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>full_mention</th>\n",
       "      <th>wikipedia_URL</th>\n",
       "      <th>wikipedia_page_ID</th>\n",
       "      <th>wikipedia_title</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>congruent_mentions</th>\n",
       "      <th>norm_full_mention</th>\n",
       "      <th>mention_candidate_pools_page_ids</th>\n",
       "      <th>mention_candidate_pools_item_ids</th>\n",
       "      <th>candidate_pools_titles</th>\n",
       "      <th>congruent_mention_ids_anchor_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B</td>\n",
       "      <td>Germany</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Germany</td>\n",
       "      <td>11867.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>['Germany', 'European Union', 'Werner Zwingman...</td>\n",
       "      <td>germany</td>\n",
       "      <td>[11867, 250204, 21212, 12674, 33685, 662281, 1...</td>\n",
       "      <td>[183, 43310, 7318, 43287, 41304, 154408, 12031...</td>\n",
       "      <td>[Germany, Germany_national_football_team, Nazi...</td>\n",
       "      <td>[458, 458, 145]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>European Union</td>\n",
       "      <td>http://en.wikipedia.org/wiki/European_Union</td>\n",
       "      <td>9317.0</td>\n",
       "      <td>European Union</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>['Germany', 'European Union', 'Werner Zwingman...</td>\n",
       "      <td>european union</td>\n",
       "      <td>[9317, 1933156, 9317, 10890716, 276436, 265743...</td>\n",
       "      <td>[458, 1376407, 458, 185441, 208202, 319328, 36...</td>\n",
       "      <td>[European_Union, European_Boxing_Union, Europe...</td>\n",
       "      <td>[183, 145]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I</td>\n",
       "      <td>European Union</td>\n",
       "      <td>http://en.wikipedia.org/wiki/European_Union</td>\n",
       "      <td>9317.0</td>\n",
       "      <td>European Union</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>['Germany', 'European Union', 'Werner Zwingman...</td>\n",
       "      <td>european union</td>\n",
       "      <td>[9317, 1933156, 9317, 10890716, 276436, 265743...</td>\n",
       "      <td>[458, 1376407, 458, 185441, 208202, 319328, 36...</td>\n",
       "      <td>[European_Union, European_Boxing_Union, Europe...</td>\n",
       "      <td>[183, 145]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>B</td>\n",
       "      <td>Werner Zwingmann</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>['Germany', 'European Union', 'Werner Zwingman...</td>\n",
       "      <td>werner zwingmann</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[183, 458, 458, 145]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I</td>\n",
       "      <td>Werner Zwingmann</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>['Germany', 'European Union', 'Werner Zwingman...</td>\n",
       "      <td>werner zwingmann</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[183, 458, 458, 145]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>B</td>\n",
       "      <td>Britain</td>\n",
       "      <td>http://en.wikipedia.org/wiki/United_Kingdom</td>\n",
       "      <td>31717.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>['Germany', 'European Union', 'Werner Zwingman...</td>\n",
       "      <td>britain</td>\n",
       "      <td>[31717, 13530298, 152256, 158019, 13525, 4721,...</td>\n",
       "      <td>[145, 23666, 174193, 161885, 185103, 8680, 977...</td>\n",
       "      <td>[United_Kingdom, Great_Britain, United_Kingdom...</td>\n",
       "      <td>[183, 458, 458]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mention      full_mention                                wikipedia_URL  \\\n",
       "10       B           Germany         http://en.wikipedia.org/wiki/Germany   \n",
       "11       B    European Union  http://en.wikipedia.org/wiki/European_Union   \n",
       "12       I    European Union  http://en.wikipedia.org/wiki/European_Union   \n",
       "13       B  Werner Zwingmann                                          NaN   \n",
       "14       I  Werner Zwingmann                                          NaN   \n",
       "15       B           Britain  http://en.wikipedia.org/wiki/United_Kingdom   \n",
       "\n",
       "    wikipedia_page_ID wikipedia_title  sentence_id  doc_id  \\\n",
       "10            11867.0         Germany            2       0   \n",
       "11             9317.0  European Union            2       0   \n",
       "12             9317.0  European Union            2       0   \n",
       "13                NaN             NaN            2       0   \n",
       "14                NaN             NaN            2       0   \n",
       "15            31717.0  United Kingdom            2       0   \n",
       "\n",
       "                                   congruent_mentions norm_full_mention  \\\n",
       "10  ['Germany', 'European Union', 'Werner Zwingman...           germany   \n",
       "11  ['Germany', 'European Union', 'Werner Zwingman...    european union   \n",
       "12  ['Germany', 'European Union', 'Werner Zwingman...    european union   \n",
       "13  ['Germany', 'European Union', 'Werner Zwingman...  werner zwingmann   \n",
       "14  ['Germany', 'European Union', 'Werner Zwingman...  werner zwingmann   \n",
       "15  ['Germany', 'European Union', 'Werner Zwingman...           britain   \n",
       "\n",
       "                     mention_candidate_pools_page_ids  \\\n",
       "10  [11867, 250204, 21212, 12674, 33685, 662281, 1...   \n",
       "11  [9317, 1933156, 9317, 10890716, 276436, 265743...   \n",
       "12  [9317, 1933156, 9317, 10890716, 276436, 265743...   \n",
       "13                                                 []   \n",
       "14                                                 []   \n",
       "15  [31717, 13530298, 152256, 158019, 13525, 4721,...   \n",
       "\n",
       "                     mention_candidate_pools_item_ids  \\\n",
       "10  [183, 43310, 7318, 43287, 41304, 154408, 12031...   \n",
       "11  [458, 1376407, 458, 185441, 208202, 319328, 36...   \n",
       "12  [458, 1376407, 458, 185441, 208202, 319328, 36...   \n",
       "13                                                 []   \n",
       "14                                                 []   \n",
       "15  [145, 23666, 174193, 161885, 185103, 8680, 977...   \n",
       "\n",
       "                               candidate_pools_titles  \\\n",
       "10  [Germany, Germany_national_football_team, Nazi...   \n",
       "11  [European_Union, European_Boxing_Union, Europe...   \n",
       "12  [European_Union, European_Boxing_Union, Europe...   \n",
       "13                                                 []   \n",
       "14                                                 []   \n",
       "15  [United_Kingdom, Great_Britain, United_Kingdom...   \n",
       "\n",
       "   congruent_mention_ids_anchor_link  \n",
       "10                   [458, 458, 145]  \n",
       "11                        [183, 145]  \n",
       "12                        [183, 145]  \n",
       "13              [183, 458, 458, 145]  \n",
       "14              [183, 458, 458, 145]  \n",
       "15                   [183, 458, 458]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_df = entity_disambiguation_new[entity_disambiguation_new.sentence_id == 2]\n",
    "sentence_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in pretrained embeddings by graphvite\n",
    "#downloaded here:\n",
    "#https://graphvite.io/docs/latest/pretrained_model.html\n",
    "import pickle\n",
    "with open(\"../../data/transe_wikidata5m.pkl\", \"rb\") as fin:\n",
    "    model = pickle.load(fin)\n",
    "entity2id = model.graph.entity2id\n",
    "relation2id = model.graph.relation2id\n",
    "entity_embeddings = model.solver.entity_embeddings\n",
    "relation_embeddings = model.solver.relation_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function from graphvite package\n",
    "#https://github.com/DeepGraphLearning/graphvite/blob/master/python/graphvite/dataset.py\n",
    "#would be easier to use the package directly, I am using the raw file here because of downloading issues\n",
    "def load_alias(alias_file):\n",
    "    alias2object = {}\n",
    "    ambiguous = set()\n",
    "    with open(alias_file, \"r\") as fin:\n",
    "        for line in fin:\n",
    "            tokens = line.strip().split(\"\\t\")\n",
    "            object = tokens[0]\n",
    "            for alias in tokens[1:]:\n",
    "                if alias in alias2object and alias2object[alias] != object:\n",
    "                    ambiguous.add(alias)\n",
    "                alias2object[alias] = object\n",
    "        for alias in ambiguous:\n",
    "            alias2object.pop(alias)\n",
    "    return alias2object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in the entity file, downloaded here: \n",
    "#https://www.dropbox.com/s/bgmgvk8brjwpc9w/entity.txt.gz?dl=1\n",
    "my_file = \"../../data/entity.txt\"\n",
    "entity = load_alias(my_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final embedding is 512 dimensions\n"
     ]
    }
   ],
   "source": [
    "#for one entity, this is how we will find its embeddings:\n",
    "e = 'germany'\n",
    "ind = entity[e]\n",
    "ind = entity2id[ind]\n",
    "embedding = entity_embeddings[ind]\n",
    "print('final embedding is {} dimensions'.format(len(embedding)))\n",
    "\n",
    "#put this into a helper function\n",
    "def ent2emb(ent):\n",
    "    ind = entity[ent]\n",
    "    ind = entity2id[ind]\n",
    "    embedding = entity_embeddings[ind]\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance between germany and berlin: 0.4656655788421631\n",
      "distance between germany and michael jordan: 1.042931318283081\n"
     ]
    }
   ],
   "source": [
    "#sanity check: germany - berlin is shorter distance to germany - michael jordan\n",
    "close = 'berlin'\n",
    "far = 'michael jordan'\n",
    "dis_close = np.linalg.norm(ent2emb(e) - ent2emb(close))\n",
    "dis_far = np.linalg.norm(ent2emb(e) - ent2emb(far))\n",
    "print('distance between {} and {}: {}'.format(e, close, dis_close))\n",
    "print('distance between {} and {}: {}'.format(e, far, dis_far))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#euclidean distance\n",
    "\n",
    "def ed(l1, l2):\n",
    "    return np.linalg.norm(l1-l2)\n",
    "\n",
    "from scipy import spatial\n",
    "def cd(l1, l2):\n",
    "    return spatial.distance.cosine(l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the algorithm for Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all candidates\n",
    "t = list(sentence_df.candidate_pools_titles)\n",
    "candidates = [item for sublist in t for item in sublist]\n",
    "#all mentions\n",
    "t1 = list(sentence_df.congruent_mentions)\n",
    "congruence = [item for sublist in t1 for item in sublist]\n",
    "#the whole list we need from edges dataframe\n",
    "candidate_pool = candidates + congruence\n",
    "#remove duplicates\n",
    "candidate_pool = list(set(candidate_pool))\n",
    "\n",
    "#create shortest path matrix\n",
    "shortest_path_matrix = []\n",
    "for candidate_src in candidates:\n",
    "    shortest_paths = []\n",
    "    for candidate_trgt in congruence:\n",
    "        if candidate_src is None or candidate_trgt is None:\n",
    "            shortest_paths.append(None)\n",
    "        else:\n",
    "            try:\n",
    "                shortest_paths.append(ed(ent2emb(candidate_src), ent2emb(candidate_trgt)))\n",
    "            except:\n",
    "                shortest_paths.append(-1)\n",
    "    shortest_path_matrix.append(shortest_paths)\n",
    "\n",
    "#predict on each mention\n",
    "pred = []\n",
    "for i in range(len(sentence_df)):\n",
    "    sub_candidates = sentence_df['candidate_pools_titles'].values[i]\n",
    "    sub_candidates_indices = [candidates.index(k) for k in sub_candidates]\n",
    "    sub_congruent = sentence_df.congruent_mentions.values[i]\n",
    "    sub_congruent_indices = [congruence.index(k) for k in sub_congruent]\n",
    "    new_mtx = np.take(shortest_path_matrix, sub_candidates_indices, 0)\n",
    "    new_mtx = np.take(new_mtx, sub_congruent_indices, 1)\n",
    "    rank_by_mean_path = np.mean(new_mtx, axis=1).argsort() #lowest to highest\n",
    "    # Filter out -1 values representing no path\n",
    "    try:\n",
    "        prediction_by_mean_rank = rank_by_mean_path[0]\n",
    "    except:\n",
    "        prediction_by_mean_rank = 0\n",
    "\n",
    "    try:\n",
    "        pred.append(sub_candidates[prediction_by_mean_rank])\n",
    "    except:\n",
    "        pred.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Germany', 'European_Union', 'European_Union', None, None, 'United_Kingdom']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the algorithm for Cosine Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all candidates\n",
    "t = list(sentence_df.candidate_pools_titles)\n",
    "candidates = [item for sublist in t for item in sublist]\n",
    "#all mentions\n",
    "t1 = list(sentence_df.congruent_mentions)\n",
    "congruence = [item for sublist in t1 for item in sublist]\n",
    "#the whole list we need from edges dataframe\n",
    "candidate_pool = candidates + congruence\n",
    "#remove duplicates\n",
    "candidate_pool = list(set(candidate_pool))\n",
    "\n",
    "#create shortest path matrix\n",
    "shortest_path_matrix = []\n",
    "for candidate_src in candidates:\n",
    "    shortest_paths = []\n",
    "    for candidate_trgt in congruence:\n",
    "        if candidate_src is None or candidate_trgt is None:\n",
    "            shortest_paths.append(None)\n",
    "        else:\n",
    "            try:\n",
    "                shortest_paths.append(cd(ent2emb(candidate_src), ent2emb(candidate_trgt)))\n",
    "            except:\n",
    "                shortest_paths.append(-1)\n",
    "    shortest_path_matrix.append(shortest_paths)\n",
    "\n",
    "#predict on each mention\n",
    "pred = []\n",
    "for i in range(len(sentence_df)):\n",
    "    sub_candidates = sentence_df['candidate_pools_titles'].values[i]\n",
    "    sub_candidates_indices = [candidates.index(k) for k in sub_candidates]\n",
    "    sub_congruent = sentence_df.congruent_mentions.values[i]\n",
    "    sub_congruent_indices = [congruence.index(k) for k in sub_congruent]\n",
    "    new_mtx = np.take(shortest_path_matrix, sub_candidates_indices, 0)\n",
    "    new_mtx = np.take(new_mtx, sub_congruent_indices, 1)\n",
    "    rank_by_mean_path = np.mean(new_mtx, axis=1).argsort() #lowest to highest\n",
    "    # Filter out -1 values representing no path\n",
    "    try:\n",
    "        prediction_by_mean_rank = rank_by_mean_path[0]\n",
    "    except:\n",
    "        prediction_by_mean_rank = 0\n",
    "\n",
    "    try:\n",
    "        pred.append(sub_candidates[prediction_by_mean_rank])\n",
    "    except:\n",
    "        pred.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Germany', 'European_Union', 'European_Union', None, None, 'United_Kingdom']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat this and produce accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentence_emb(sentence_id, method):\n",
    "    sentence_df = entity_disambiguation_new[entity_disambiguation_new.sentence_id==sentence_id]\n",
    "    #all candidates\n",
    "    t = list(sentence_df.candidate_pools_titles)\n",
    "    candidates = [item for sublist in t for item in sublist]\n",
    "    #all mentions\n",
    "    t1 = list(sentence_df.congruent_mentions)\n",
    "    congruence = [item for sublist in t1 for item in sublist]\n",
    "    #the whole list we need from edges dataframe\n",
    "    candidate_pool = candidates + congruence\n",
    "    #remove duplicates\n",
    "    candidate_pool = list(set(candidate_pool))\n",
    "\n",
    "    #create shortest path matrix\n",
    "    shortest_path_matrix = []\n",
    "    for candidate_src in candidates:\n",
    "        shortest_paths = []\n",
    "        for candidate_trgt in congruence:\n",
    "            if candidate_src is None or candidate_trgt is None:\n",
    "                shortest_paths.append(None)\n",
    "            else:\n",
    "                try:\n",
    "                    if method=='euclidean distance':\n",
    "                        shortest_paths.append(ed(ent2emb(candidate_src), ent2emb(candidate_trgt)))\n",
    "                    if method=='cosine distance':\n",
    "                        shortest_paths.append(ed(ent2emb(candidate_src), ent2emb(candidate_trgt)))\n",
    "                except:\n",
    "                    shortest_paths.append(-1)\n",
    "        shortest_path_matrix.append(shortest_paths)\n",
    "\n",
    "    #predict on each mention\n",
    "    pred = []\n",
    "    for i in range(len(sentence_df)):\n",
    "        try:\n",
    "            sub_candidates = sentence_df['candidate_pools_titles'].values[i]\n",
    "            sub_candidates_indices = [candidates.index(k) for k in sub_candidates]\n",
    "            sub_congruent = sentence_df.congruent_mentions.values[i]\n",
    "            sub_congruent_indices = [congruence.index(k) for k in sub_congruent]\n",
    "            new_mtx = np.take(shortest_path_matrix, sub_candidates_indices, 0)\n",
    "            new_mtx = np.take(new_mtx, sub_congruent_indices, 1)\n",
    "            rank_by_mean_path = np.mean(new_mtx, axis=1).argsort() #lowest to highest\n",
    "            # Filter out -1 values representing no path\n",
    "            prediction_by_mean_rank = rank_by_mean_path[0]\n",
    "        except:\n",
    "            prediction_by_mean_rank = 0\n",
    "\n",
    "        try:\n",
    "            pred.append(sub_candidates[prediction_by_mean_rank])\n",
    "        except:\n",
    "            pred.append(None)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 44.63it/s]\n"
     ]
    }
   ],
   "source": [
    "#EUCLIDEAN DISTANCE\n",
    "#predict on our dataframe\n",
    "pred_ed = []\n",
    "for i in tqdm(entity_disambiguation_new.sentence_id.unique()[:100]):\n",
    "    pred = predict_sentence_emb(i, 'euclidean distance')\n",
    "    pred_ed.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUCLIDEAN DISTANCE:\n",
      "predicted 318 entities\n",
      "****************************\n",
      "Predictive Accuracy: 74.528%\n",
      "****************************\n"
     ]
    }
   ],
   "source": [
    "#evaluate accuracy\n",
    "#first flatten our list\n",
    "pred_mention = [item for sublist in pred_ed for item in sublist]\n",
    "true = [str(i).lower() for i in entity_disambiguation_new['wikipedia_title'][:len(pred_mention)]]\n",
    "#only filter not null values and test accuracies\n",
    "notnull_new = [i for i in notnull if i<=len(true)]\n",
    "true = [true[i] for i in notnull_new]\n",
    "\n",
    "pred_mention = [str(i).lower().replace('_', ' ') for i in pred_mention]\n",
    "#only filter not null values and test accuracies\n",
    "pred_mention = [pred_mention[i] for i in notnull_new]\n",
    "print('EUCLIDEAN DISTANCE:')\n",
    "print('predicted {} entities'.format(len(true)))\n",
    "accurate_predictions = sum([true[i]==pred_mention[i] for i in range(len(true))])\n",
    "print(\"****************************\")\n",
    "print(f\"Predictive Accuracy: {round(accurate_predictions / len(true) *100, 3)}%\")\n",
    "print(\"****************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 40.23it/s]\n"
     ]
    }
   ],
   "source": [
    "#COSINE DISTANCE\n",
    "#predict on our dataframe\n",
    "pred_cd = []\n",
    "for i in tqdm(entity_disambiguation_new.sentence_id.unique()[:100]):\n",
    "    pred = predict_sentence_emb(i, 'cosine distance')\n",
    "    pred_cd.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUCLIDEAN DISTANCE:\n",
      "****************************\n",
      "Predictive Accuracy: 74.528%\n",
      "****************************\n"
     ]
    }
   ],
   "source": [
    "#evaluate accuracy\n",
    "#first flatten our list\n",
    "pred_mention = [item for sublist in pred_cd for item in sublist]\n",
    "true = [str(i).lower() for i in entity_disambiguation_new['wikipedia_title'][:len(pred_mention)]]\n",
    "#only filter not null values and test accuracies\n",
    "notnull_new = [i for i in notnull if i<=len(true)]\n",
    "true = [true[i] for i in notnull_new]\n",
    "\n",
    "pred_mention = [str(i).lower().replace('_', ' ') for i in pred_mention]\n",
    "#only filter not null values and test accuracies\n",
    "pred_mention = [pred_mention[i] for i in notnull_new]\n",
    "print('EUCLIDEAN DISTANCE:')\n",
    "accurate_predictions = sum([true[i]==pred_mention[i] for i in range(len(true))])\n",
    "print(\"****************************\")\n",
    "print(f\"Predictive Accuracy: {round(accurate_predictions / len(true) *100, 3)}%\")\n",
    "print(\"****************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
