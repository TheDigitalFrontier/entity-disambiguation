{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congruence via Entity Vector Similarity\n",
    "\n",
    "In this notebook, we calculate the centroid distance measure between vectors of each entity candidate. The vectors will be retrieved from Wikipedia2vec's pre-trained API, which creates vectors for the entire Wikipedia page. Comparing two vectors in this way thus lets us make a statement about similar pages and update our likelihood scores based on that.\n",
    "\n",
    "#### (i) Via Centroid Distance\n",
    "\n",
    "In Phase 4, we calculate congruence between candidates in pools for mentions in the same sentence. Congruence is defined as the average candidate distance to the centroid vector of the candidate set. This lets us compare entire sets of candidates across all mentions at a time, instead of making pairwise comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from itertools import product\n",
    "\n",
    "# Progress bar\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>full_mention</th>\n",
       "      <th>wikipedia_URL</th>\n",
       "      <th>wikipedia_page_ID</th>\n",
       "      <th>wikipedia_title</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>congruent_mentions</th>\n",
       "      <th>norm_full_mention</th>\n",
       "      <th>candidate_pool_page_ids</th>\n",
       "      <th>candidate_pool_item_ids</th>\n",
       "      <th>candidate_pool_titles</th>\n",
       "      <th>candidate_pool_likelihoods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>EU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>eu</td>\n",
       "      <td>[9317, 9239, 21347120, 9477, 1882861]</td>\n",
       "      <td>[458, 46, 211593, 1396, 363404]</td>\n",
       "      <td>['European_Union', 'Europe', 'Eu,_Seine-Mariti...</td>\n",
       "      <td>[0.9227799000000001, 0.024651, 0.0201960000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>German</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Germany</td>\n",
       "      <td>11867.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>german</td>\n",
       "      <td>[11867, 11884, 152735, 21212, 12674]</td>\n",
       "      <td>[183, 188, 42884, 7318, 43287]</td>\n",
       "      <td>['Germany', 'German_language', 'Germans', 'Naz...</td>\n",
       "      <td>[0.4192066, 0.2893363, 0.1470461, 0.03832, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>British</td>\n",
       "      <td>http://en.wikipedia.org/wiki/United_Kingdom</td>\n",
       "      <td>31717.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>british</td>\n",
       "      <td>[31717, 19097669, 13530298, 4721, 158019]</td>\n",
       "      <td>[145, 842438, 23666, 8680, 161885]</td>\n",
       "      <td>['United_Kingdom', 'British_people', 'Great_Br...</td>\n",
       "      <td>[0.6101255999999999, 0.1146913, 0.0681775, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>Peter Blackburn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Peter Blackburn', 'BRUSSELS', 'European Comm...</td>\n",
       "      <td>peter blackburn</td>\n",
       "      <td>[56783206, 9643132, 56873217]</td>\n",
       "      <td>[2073954, 7172840, 26634508]</td>\n",
       "      <td>['Peter_Blackburn_(badminton)', 'Peter_Blackbu...</td>\n",
       "      <td>[0.5, 0.3, 0.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>Peter Blackburn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Peter Blackburn', 'BRUSSELS', 'European Comm...</td>\n",
       "      <td>peter blackburn</td>\n",
       "      <td>[56783206, 9643132, 56873217]</td>\n",
       "      <td>[2073954, 7172840, 26634508]</td>\n",
       "      <td>['Peter_Blackburn_(badminton)', 'Peter_Blackbu...</td>\n",
       "      <td>[0.5, 0.3, 0.2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mention     full_mention                                wikipedia_URL  \\\n",
       "0       B               EU                                          NaN   \n",
       "1       B           German         http://en.wikipedia.org/wiki/Germany   \n",
       "2       B          British  http://en.wikipedia.org/wiki/United_Kingdom   \n",
       "3       B  Peter Blackburn                                          NaN   \n",
       "4       I  Peter Blackburn                                          NaN   \n",
       "\n",
       "   wikipedia_page_ID wikipedia_title  sentence_id  doc_id  \\\n",
       "0                NaN             NaN            0       0   \n",
       "1            11867.0         Germany            0       0   \n",
       "2            31717.0  United Kingdom            0       0   \n",
       "3                NaN             NaN            1       0   \n",
       "4                NaN             NaN            1       0   \n",
       "\n",
       "                                  congruent_mentions norm_full_mention  \\\n",
       "0                        ['EU', 'German', 'British']                eu   \n",
       "1                        ['EU', 'German', 'British']            german   \n",
       "2                        ['EU', 'German', 'British']           british   \n",
       "3  ['Peter Blackburn', 'BRUSSELS', 'European Comm...   peter blackburn   \n",
       "4  ['Peter Blackburn', 'BRUSSELS', 'European Comm...   peter blackburn   \n",
       "\n",
       "                     candidate_pool_page_ids  \\\n",
       "0      [9317, 9239, 21347120, 9477, 1882861]   \n",
       "1       [11867, 11884, 152735, 21212, 12674]   \n",
       "2  [31717, 19097669, 13530298, 4721, 158019]   \n",
       "3              [56783206, 9643132, 56873217]   \n",
       "4              [56783206, 9643132, 56873217]   \n",
       "\n",
       "              candidate_pool_item_ids  \\\n",
       "0     [458, 46, 211593, 1396, 363404]   \n",
       "1      [183, 188, 42884, 7318, 43287]   \n",
       "2  [145, 842438, 23666, 8680, 161885]   \n",
       "3        [2073954, 7172840, 26634508]   \n",
       "4        [2073954, 7172840, 26634508]   \n",
       "\n",
       "                               candidate_pool_titles  \\\n",
       "0  ['European_Union', 'Europe', 'Eu,_Seine-Mariti...   \n",
       "1  ['Germany', 'German_language', 'Germans', 'Naz...   \n",
       "2  ['United_Kingdom', 'British_people', 'Great_Br...   \n",
       "3  ['Peter_Blackburn_(badminton)', 'Peter_Blackbu...   \n",
       "4  ['Peter_Blackburn_(badminton)', 'Peter_Blackbu...   \n",
       "\n",
       "                          candidate_pool_likelihoods  \n",
       "0  [0.9227799000000001, 0.024651, 0.0201960000000...  \n",
       "1  [0.4192066, 0.2893363, 0.1470461, 0.03832, 0.0...  \n",
       "2  [0.6101255999999999, 0.1146913, 0.0681775, 0.0...  \n",
       "3                                    [0.5, 0.3, 0.2]  \n",
       "4                                    [0.5, 0.3, 0.2]  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base path to input\n",
    "preds_path = '../../predictions/'\n",
    "\n",
    "# Load data\n",
    "predictions = pd.read_csv(os.path.join(preds_path, \"anchortext_frequency_5x5.csv\"), delimiter=\",\")\n",
    "predictions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13781 3935\n"
     ]
    }
   ],
   "source": [
    "print(len(predictions), len(predictions['sentence_id'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Saved Candidate Pool\n",
    "\n",
    "Candidate pools when exported are typically stored as the string of a list. The below function parses the string back into a list with proper formatted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demonstrate that list is string\n",
    "type(predictions['candidate_pool_page_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse list as string\n",
    "def parse_list_string(list_string, value_type=int):\n",
    "    \n",
    "    parsed_list = []\n",
    "    \n",
    "    # If candidate pool is empty\n",
    "    if list_string == \"[]\" or isinstance(list_string, float):\n",
    "        pass\n",
    "    # Else parse\n",
    "    else:\n",
    "        # Parses lists of titles as strings\n",
    "        if value_type==str:\n",
    "            # Eliminate bracket and parenthesis on either side, split by comma pattern\n",
    "            parsed_list = re.split(\"', '|\\\", \\\"|', \\\"|\\\", \\'\", list_string[2:-2])\n",
    "\n",
    "        # Parses lists of IDs as ints\n",
    "        elif value_type==int:\n",
    "            # Eliminate brackets and convert each number from string to int\n",
    "            parsed_list = list(map(int, list_string[1:-1].split(', ')))\n",
    "        elif value_type==float:\n",
    "            # Eliminate brackets and convert each number from string to int\n",
    "            parsed_list = list(map(float, list_string[1:-1].split(', ')))\n",
    "            \n",
    "        \n",
    "    return parsed_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['European_Union',\n",
       " 'Europe',\n",
       " 'Eu,_Seine-Maritime',\n",
       " 'Europium',\n",
       " 'Citizenship_of_the_European_Union']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually test function\n",
    "# 0 is the hard one. See how some value is stored with '' and some with \"\". Unsure why.\n",
    "parse_list_string(predictions['candidate_pool_titles'][0], value_type=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9317, 9239, 21347120, 9477, 1882861]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually test function\n",
    "# 0 is the hard one. See how some value is stored with '' and some with \"\". Unsure why.\n",
    "parse_list_string(predictions['candidate_pool_page_ids'][0], value_type=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually test function\n",
    "parse_list_string(predictions['candidate_pool_page_ids'][13], value_type=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9227799000000001, 0.024651, 0.020196000000000002, 0.005346, 0.002079]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually test function\n",
    "parse_list_string(predictions['candidate_pool_likelihoods'][0], value_type=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ['Peter Blackburn', 'BRUSSELS', 'European Commission', 'German', 'British']\n",
      "After ['Peter Blackburn', 'BRUSSELS', 'European Commission', 'German', 'British']\n",
      "Before [56783206, 9643132, 56873217]\n",
      "After [56783206, 9643132, 56873217]\n",
      "Before [2073954, 7172840, 26634508]\n",
      "After [2073954, 7172840, 26634508]\n",
      "Before ['Peter_Blackburn_(badminton)', 'Peter_Blackburn_(bishop)', 'Peter_Blackburn_(MP)']\n",
      "After ['Peter_Blackburn_(badminton)', 'Peter_Blackburn_(bishop)', 'Peter_Blackburn_(MP)']\n",
      "Before [0.5, 0.3, 0.2]\n",
      "After [0.5, 0.3, 0.2]\n",
      "CPU times: user 240 ms, sys: 412 ms, total: 652 ms\n",
      "Wall time: 1.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "### Apply defined function to entire dataframe for all candidate pool columns\n",
    "\n",
    "column = 'congruent_mentions'\n",
    "print(\"Before\", predictions[column][3])\n",
    "parsed_candidate_pool = predictions[column].apply(parse_list_string, value_type=str)\n",
    "predictions[column] = parsed_candidate_pool\n",
    "print(\"After\", predictions[column][3])\n",
    "\n",
    "column = 'candidate_pool_page_ids'\n",
    "print(\"Before\", predictions[column][3])\n",
    "parsed_candidate_pool = predictions[column].apply(parse_list_string, value_type=int)\n",
    "predictions[column] = parsed_candidate_pool\n",
    "print(\"After\", predictions[column][3])\n",
    "\n",
    "\n",
    "column = 'candidate_pool_item_ids'\n",
    "print(\"Before\", predictions[column][3])\n",
    "parsed_candidate_pool = predictions[column].apply(parse_list_string, value_type=int)\n",
    "predictions[column] = parsed_candidate_pool\n",
    "print(\"After\", predictions[column][3])\n",
    "\n",
    "\n",
    "column = 'candidate_pool_titles'\n",
    "print(\"Before\", predictions[column][3])\n",
    "parsed_candidate_pool = predictions[column].apply(parse_list_string, value_type=str)\n",
    "predictions[column] = parsed_candidate_pool\n",
    "print(\"After\", predictions[column][3])\n",
    "\n",
    "column = 'candidate_pool_likelihoods'\n",
    "print(\"Before\", predictions[column][3])\n",
    "parsed_candidate_pool = predictions[column].apply(parse_list_string, value_type=float)\n",
    "predictions[column] = parsed_candidate_pool\n",
    "print(\"After\", predictions[column][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Entity Vectors from Wikipedia2Vec\n",
    "\n",
    "For provided wikipedia pages, we retrieve a representative entity vector from Wikipedia2vec. This involves passing the normalized title into their get_entity_vector() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package\n",
    "from wikipedia2vec import Wikipedia2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 101 ms, sys: 158 ms, total: 259 ms\n",
      "Wall time: 684 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load unzipped pkl file with word embeddings\n",
    "w2v = Wikipedia2Vec.load(\"../../embeddings/enwiki_20180420_100d.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess Coverage of Candidate Pools in Wikipedia2vec\n",
    "\n",
    "We need to measure what percent of candidates in our candidate pools successfully return a vector from Wikipedia2vec. This should conceivably be 100% given we're passing known Wikipedia pages into this package trained over Wikipedia pages, but there may be some drop-off due to different creation dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define text normalization function\n",
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    We define normalized as:\n",
    "    - strip whitespace\n",
    "    - Spaces, not underlines\n",
    "    \"\"\"\n",
    "    return str(text).strip().replace(\"_\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13781/13781 [00:01<00:00, 7551.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia2vec returned an entity vector for 94.86% of 42,453 searches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over candidate pool titles to see what can be returned\n",
    "\n",
    "found_entity = 0\n",
    "searched_entity = 0\n",
    "\n",
    "for i in tqdm(range(len(predictions))):\n",
    "    \n",
    "    # Retrieve candidate pool\n",
    "    candidate_pool = predictions['candidate_pool_titles'][i]\n",
    "    \n",
    "    # Query for each candidate\n",
    "    for candidate in candidate_pool:\n",
    "        # Normalize candidate title to form necessary to input into Wikipedia2vec\n",
    "        candidate = normalize_text(candidate)\n",
    "        \n",
    "        # Query Wikipedia2vec get_entity_vector()\n",
    "        try:\n",
    "            entity_vector = w2v.get_entity_vector(candidate)\n",
    "        except KeyError:\n",
    "            entity_vector = None\n",
    "        \n",
    "        # Check if result\n",
    "        if entity_vector is not None:\n",
    "            found_entity += 1\n",
    "        \n",
    "        # Increment count\n",
    "        searched_entity += 1\n",
    "\n",
    "print(f\"Wikipedia2vec returned an entity vector for {round(found_entity/searched_entity*100,3)}% of {searched_entity:,} searches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Congruence Metric between Congruent Entities\n",
    "\n",
    "First, let's get a sense for what the upper bound of congruent calculations might be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the maximum number of congruent entities in a single sentence\n",
    "max(predictions['congruent_mentions'].apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What is the distribution of congruent mention counts\n",
    "plt.figure(figsize=(20,5))\n",
    "predictions['congruent_mentions'].apply(len).hist(bins=50)\n",
    "plt.title(\"distribution of congruent mention counts\", size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's get a sense for the average ranking of the right answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13781/13781 [00:01<00:00, 7119.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answer not present 35.9% of the time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare tracking metrics\n",
    "correct_answer_rank = []\n",
    "correct_answer_likelihood = {0:[],1:[],2:[],3:[],4:[]}\n",
    "correct_answer_not_present = 0\n",
    "\n",
    "# Iterate over whole dataframe\n",
    "for i in tqdm(range(len(predictions))):\n",
    "    row = predictions.iloc[i]\n",
    "    correct_answer = row['wikipedia_page_ID']\n",
    "    try:\n",
    "        correct_rank = row['candidate_pool_page_ids'].index(correct_answer)\n",
    "        correct_answer_rank.append(correct_rank)\n",
    "        correct_answer_likelihood[correct_rank].append(row['candidate_pool_likelihoods'][correct_rank])\n",
    "    except ValueError:\n",
    "        correct_answer_not_present += 1\n",
    "\n",
    "print(f\"Correct answer not present {round(correct_answer_not_present/len(predictions)*100,1)}% of the time.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot rank\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.hist(correct_answer_rank, bins=20)\n",
    "plt.title(\"Ordering of Correct Answer Candidate Rank\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7015\n",
       "1    1190\n",
       "2     364\n",
       "3     177\n",
       "4      85\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(correct_answer_rank).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Candidate Rank: 0 - Average Prior Confidence: 0.88192\n",
      "Correct Candidate Rank: 1 - Average Prior Confidence: 0.17509\n",
      "Correct Candidate Rank: 2 - Average Prior Confidence: 0.07656\n",
      "Correct Candidate Rank: 3 - Average Prior Confidence: 0.03768\n",
      "Correct Candidate Rank: 4 - Average Prior Confidence: 0.02739\n"
     ]
    }
   ],
   "source": [
    "for k,v in correct_answer_likelihood.items():\n",
    "    print(f\"Correct Candidate Rank: {k} - Average Prior Confidence: {round(np.mean(v),5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "80% are in the top position, another 11% in the second place, 3% in 3rd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capturing Current Design Thinking\n",
    "\n",
    "We need to iterate through every mention's every candidate to develop the total of all sets in entity vector form. From there, we can iterate through sets to A) create the centroid vector and B) calculate each candidate distance to the centroid. With each candidate distance, we can average into a single distance congruence measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions to Create Modular Congruent Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate candidate lists of vectors\n",
    "def get_candidate_pool_vectors(candidate_pool_titles, verbose=False):\n",
    "    \"\"\"\n",
    "    Function to return entity vectors from Wikipedia2Vec\n",
    "    Takes as input a list of page titles, representing the candidate pool\n",
    "    Normalizes each page title to match necessary input format\n",
    "    Returns entity vector or empty vector if no match\n",
    "    \"\"\"\n",
    "    # Track failed vector queries\n",
    "    no_vector_count = 0\n",
    "    candidate_pool_vectors = []\n",
    "    for candidate in candidate_pool_titles:\n",
    "        candidate = normalize_text(candidate)\n",
    "        if verbose: print(candidate)\n",
    "        try:\n",
    "            candidate_vectors = w2v.get_entity_vector(candidate)\n",
    "        except KeyError:\n",
    "            # Keep empty vector representation to maintain index locations\n",
    "            candidate_vectors = np.zeros(100)\n",
    "            no_vector_count += 1\n",
    "        candidate_pool_vectors.append(candidate_vectors)\n",
    "    \n",
    "    # Handle case where candidate pool is empty from Phase 3\n",
    "    # Add arbitrarily chosen 3 arrays of zeros\n",
    "    if len(candidate_pool_titles) == 0:\n",
    "        candidate_pool_vectors = [np.zeros(100), np.zeros(100), np.zeros(100)]\n",
    "    \n",
    "    if verbose: print(f\"Failed Wikipedia2Vec Entity Vector Queries: {no_vector_count}\")\n",
    "    return candidate_pool_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to retrieve entity vectors\n",
    "def create_entity_vector_dict(sentence_mention_ids, sentence_predictions, verbose=False):\n",
    "    \"\"\"\n",
    "    Function iterates over a provided list of congruent mentions,\n",
    "    finds the associated candidate pool for each mention\n",
    "    and returns the candidate pool vector\n",
    "    \"\"\"\n",
    "    # Save vectors in dictionary\n",
    "    vector_dict = {}\n",
    "    \n",
    "    # For each full mention we are analyzing in the contextual domain\n",
    "    for m in sentence_mention_ids:\n",
    "        \n",
    "        # Retrieve candidate pool titles\n",
    "        candidate_pool_titles = sentence_predictions['candidate_pool_titles'][m]\n",
    "        if verbose: print(candidate_pool_titles)\n",
    "        \n",
    "        # Convert candidate pool titles to candidate pool vectors\n",
    "        candidate_pool_vectors = get_candidate_pool_vectors(candidate_pool_titles, verbose=verbose)\n",
    "        \n",
    "        # Save candidate pool vectors to dictionary\n",
    "        vector_dict[m] = candidate_pool_vectors\n",
    "    \n",
    "    if verbose:\n",
    "        print(vector_dict.keys())\n",
    "        for k in vector_dict.keys():\n",
    "            print(len(vector_dict[k]))\n",
    "    return vector_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to create every set of candidates across all mentions\n",
    "def create_candidate_combos(vector_dict, verbose=False):\n",
    "    \"\"\"\n",
    "    Function takes as input vector_dict, which represents candidate pool vectors for each mention\n",
    "    Iterates through all candidate vectors to create single list of all combinations of candidates\n",
    "    Returns that list\n",
    "    \"\"\"\n",
    "    # Prepare list for combination\n",
    "    candidate_counts = [range(len(v)) for v in vector_dict.values()]\n",
    "    if verbose: print(candidate_counts)\n",
    "    \n",
    "    # Create product combination of all candidates\n",
    "    unique_combinations = list(product(*candidate_counts))\n",
    "    \n",
    "    return unique_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate centroids\n",
    "def calculate_centroid_candidate_dist(unique_combinations, vector_dict, verbose=False):\n",
    "    \"\"\"\n",
    "    Function takes a list of all possible unique combinations of candidates in vector form,\n",
    "    Calculates the centroid of the vectors of that combination,\n",
    "    Calculates the distance of each candidate to the centroid\n",
    "    Calculates the mean distance for that combination\n",
    "    Returns a list of mean distance for each candidate combination to its centroid\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare list for each combination's mean distance\n",
    "    combination_distance = []\n",
    "    \n",
    "    # For every unique combination of candidates\n",
    "    for combo in unique_combinations:\n",
    "        \n",
    "        # Translate combination from idx values to vectors\n",
    "        combo_vector = []\n",
    "        for i in range(len(combo)):\n",
    "            combo_vector.append(vector_dict[i][combo[i]]) # Retrieve the vector representation\n",
    "\n",
    "        # Calculate centroid\n",
    "        centroid = sum(combo_vector)/len(combo) # Can select sum or mean by removing denominator\n",
    "                \n",
    "        # Calculate distance from each candidate to its combination centroid\n",
    "        candidate_distances = []\n",
    "        for candidate in combo_vector:\n",
    "            candidate_dist = cosine_similarity(candidate.reshape(-1,1), centroid.reshape(-1,1))\n",
    "            candidate_distances.append(candidate_dist)\n",
    "        \n",
    "        combination_distance.append(np.mean(candidate_distances))\n",
    "        \n",
    "    return combination_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Congruent Predictions Function\n",
    "\n",
    "This is our main function that takes a sentence ID, calculates congruence for all candidates, updates the prior likelihood from Phase 3 with that congruence and selects predictions iteratively based on that number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate congruent predictions\n",
    "def get_congruent_predictions(sentence_id, dataframe, verbose=False):\n",
    "    \"\"\"\n",
    "    Function to calculate congruence metrics over a set of entity full mentions\n",
    "    and return the predicted candidates based on the congruent metric\n",
    "    Input:\n",
    "    - Sentence ID used to filter dataframe\n",
    "    - Dataframe over which to process\n",
    "    Output:\n",
    "    - Prediction for each entity mention\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter to dataframe representing single sentence\n",
    "    # Drop duplicates necessary for sentences with the same mention included twice\n",
    "    sentence_predictions = dataframe[dataframe['sentence_id'] == sentence_id]\\\n",
    "                        .drop_duplicates(['full_mention', 'wikipedia_URL', 'wikipedia_page_ID', 'wikipedia_title'])\\\n",
    "                        .reset_index(drop=True)\n",
    "    if verbose: display(sentence_predictions)\n",
    "    \n",
    "    # Define numerical representation of congruent mention list\n",
    "    sentence_congruent_mentions = sentence_predictions['congruent_mentions'][0]\n",
    "    sentence_mention_ids = np.arange(len(sentence_congruent_mentions))\n",
    "    if verbose:\n",
    "        print(\"Congruent Mentions: \", sentence_congruent_mentions)\n",
    "        print(\"Congruent Mentions as numbers: \", sentence_mention_ids)\n",
    "    \n",
    "    # Retrieve dictionary of candidate pool vectors for each mention\n",
    "    vectors_dict = create_entity_vector_dict(sentence_mention_ids, sentence_predictions, verbose=verbose)\n",
    "    if verbose: print(\"Mentions with Vectors: \", vectors_dict.keys())\n",
    "        \n",
    "    # Create full list of all unique combinations\n",
    "    unique_combinations = create_candidate_combos(vectors_dict, verbose=verbose)\n",
    "    # todo standardize on vector or vectors\n",
    "\n",
    "    # Calculate average candidate distance to that combination's centroid for comparison\n",
    "    combination_distance = calculate_centroid_candidate_dist(unique_combinations, vectors_dict, verbose=verbose)\n",
    "    \n",
    "    # Select combination with smallest distance metric, i.e. most congruent combination\n",
    "    select_idx = np.argmin(combination_distance)\n",
    "    most_congruent_combination = unique_combinations[select_idx]\n",
    "    if verbose: print(\"Most Congruent Combination: \", most_congruent_combination)\n",
    "    \n",
    "    # Create predictions dictionary\n",
    "    mention_predictions = {}\n",
    "    \n",
    "    # Translate combination list into dictionary\n",
    "    for i in range(len(most_congruent_combination)):\n",
    "        mention_predictions[i] = most_congruent_combination[i]\n",
    "    if verbose: print(\"Numerical Predictions: \", mention_predictions)\n",
    "    \n",
    "    # Use mention predictions to return titles\n",
    "    readable_predictions = {}\n",
    "    for k, v in mention_predictions.items():\n",
    "        if verbose: print(k, v)\n",
    "        readable_key = sentence_congruent_mentions[k]\n",
    "        try:\n",
    "            readable_value = sentence_predictions['candidate_pool_titles'][k][v]\n",
    "            readable_id = sentence_predictions['candidate_pool_page_ids'][k][v]\n",
    "        except IndexError: # Handles case where no candidate pool was provided from Phase 3\n",
    "            readable_value = None \n",
    "            readable_id = None\n",
    "        except TypeError:\n",
    "            # Handles case where no congruence can be calculated\n",
    "            # Either due to one mention in sentence or two mentions but one with no candidate pool\n",
    "            readable_value = sentence_predictions['candidate_pool_titles'][0][0] # Just return top value from Phase 3\n",
    "            readable_id = sentence_predictions['candidate_pool_page_ids'][0][0]\n",
    "        if verbose: print(readable_key, readable_value, readable_id)\n",
    "        readable_predictions[readable_key] = (readable_value, readable_id)\n",
    "    \n",
    "    # Output dictionary with predictions for each entity mention based on congruence\n",
    "    return readable_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>full_mention</th>\n",
       "      <th>wikipedia_URL</th>\n",
       "      <th>wikipedia_page_ID</th>\n",
       "      <th>wikipedia_title</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>congruent_mentions</th>\n",
       "      <th>norm_full_mention</th>\n",
       "      <th>candidate_pool_page_ids</th>\n",
       "      <th>candidate_pool_item_ids</th>\n",
       "      <th>candidate_pool_titles</th>\n",
       "      <th>candidate_pool_likelihoods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>EU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[EU, Franz Fischler]</td>\n",
       "      <td>eu</td>\n",
       "      <td>[9317, 9239, 21347120, 9477, 1882861]</td>\n",
       "      <td>[458, 46, 211593, 1396, 363404]</td>\n",
       "      <td>[European_Union, Europe, Eu,_Seine-Maritime, E...</td>\n",
       "      <td>[0.9227799000000001, 0.024651, 0.0201960000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>Franz Fischler</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Franz_Fischler</td>\n",
       "      <td>626779.0</td>\n",
       "      <td>Franz Fischler</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[EU, Franz Fischler]</td>\n",
       "      <td>franz fischler</td>\n",
       "      <td>[626779]</td>\n",
       "      <td>[78587]</td>\n",
       "      <td>[Franz_Fischler]</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mention    full_mention                                wikipedia_URL  \\\n",
       "0       B              EU                                          NaN   \n",
       "1       B  Franz Fischler  http://en.wikipedia.org/wiki/Franz_Fischler   \n",
       "\n",
       "   wikipedia_page_ID wikipedia_title  sentence_id  doc_id  \\\n",
       "0                NaN             NaN            5       0   \n",
       "1           626779.0  Franz Fischler            5       0   \n",
       "\n",
       "     congruent_mentions norm_full_mention  \\\n",
       "0  [EU, Franz Fischler]                eu   \n",
       "1  [EU, Franz Fischler]    franz fischler   \n",
       "\n",
       "                 candidate_pool_page_ids          candidate_pool_item_ids  \\\n",
       "0  [9317, 9239, 21347120, 9477, 1882861]  [458, 46, 211593, 1396, 363404]   \n",
       "1                               [626779]                          [78587]   \n",
       "\n",
       "                               candidate_pool_titles  \\\n",
       "0  [European_Union, Europe, Eu,_Seine-Maritime, E...   \n",
       "1                                   [Franz_Fischler]   \n",
       "\n",
       "                          candidate_pool_likelihoods  \n",
       "0  [0.9227799000000001, 0.024651, 0.0201960000000...  \n",
       "1                                              [1.0]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congruent Mentions:  ['EU', 'Franz Fischler']\n",
      "Congruent Mentions as numbers:  [0 1]\n",
      "['European_Union', 'Europe', 'Eu,_Seine-Maritime', 'Europium', 'Citizenship_of_the_European_Union']\n",
      "European Union\n",
      "Europe\n",
      "Eu, Seine-Maritime\n",
      "Europium\n",
      "Citizenship of the European Union\n",
      "Failed Wikipedia2Vec Entity Vector Queries: 0\n",
      "['Franz_Fischler']\n",
      "Franz Fischler\n",
      "Failed Wikipedia2Vec Entity Vector Queries: 0\n",
      "dict_keys([0, 1])\n",
      "5\n",
      "1\n",
      "Mentions with Vectors:  dict_keys([0, 1])\n",
      "[range(0, 5), range(0, 1)]\n",
      "Most Congruent Combination:  (4, 0)\n",
      "Numerical Predictions:  {0: 4, 1: 0}\n",
      "0 4\n",
      "EU Citizenship_of_the_European_Union 1882861\n",
      "1 0\n",
      "Franz Fischler Franz_Fischler 626779\n",
      "{'EU': ('Citizenship_of_the_European_Union', 1882861), 'Franz Fischler': ('Franz_Fischler', 626779)}\n",
      "CPU times: user 24.2 ms, sys: 5.29 ms, total: 29.5 ms\n",
      "Wall time: 35.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Test out function\n",
    "sentence_id = 5\n",
    "congruent_predictions = get_congruent_predictions(sentence_id=sentence_id, dataframe=predictions, verbose=True)\n",
    "print(congruent_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>full_mention</th>\n",
       "      <th>wikipedia_URL</th>\n",
       "      <th>wikipedia_page_ID</th>\n",
       "      <th>wikipedia_title</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>congruent_mentions</th>\n",
       "      <th>norm_full_mention</th>\n",
       "      <th>candidate_pool_page_ids</th>\n",
       "      <th>candidate_pool_item_ids</th>\n",
       "      <th>candidate_pool_titles</th>\n",
       "      <th>candidate_pool_likelihoods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>EU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[EU, Franz Fischler]</td>\n",
       "      <td>eu</td>\n",
       "      <td>[9317, 9239, 21347120, 9477, 1882861]</td>\n",
       "      <td>[458, 46, 211593, 1396, 363404]</td>\n",
       "      <td>[European_Union, Europe, Eu,_Seine-Maritime, E...</td>\n",
       "      <td>[0.9227799000000001, 0.024651, 0.0201960000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>Franz Fischler</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Franz_Fischler</td>\n",
       "      <td>626779.0</td>\n",
       "      <td>Franz Fischler</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[EU, Franz Fischler]</td>\n",
       "      <td>franz fischler</td>\n",
       "      <td>[626779]</td>\n",
       "      <td>[78587]</td>\n",
       "      <td>[Franz_Fischler]</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I</td>\n",
       "      <td>Franz Fischler</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Franz_Fischler</td>\n",
       "      <td>626779.0</td>\n",
       "      <td>Franz Fischler</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[EU, Franz Fischler]</td>\n",
       "      <td>franz fischler</td>\n",
       "      <td>[626779]</td>\n",
       "      <td>[78587]</td>\n",
       "      <td>[Franz_Fischler]</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mention    full_mention                                wikipedia_URL  \\\n",
       "0       B              EU                                          NaN   \n",
       "1       B  Franz Fischler  http://en.wikipedia.org/wiki/Franz_Fischler   \n",
       "2       I  Franz Fischler  http://en.wikipedia.org/wiki/Franz_Fischler   \n",
       "\n",
       "   wikipedia_page_ID wikipedia_title  sentence_id  doc_id  \\\n",
       "0                NaN             NaN            5       0   \n",
       "1           626779.0  Franz Fischler            5       0   \n",
       "2           626779.0  Franz Fischler            5       0   \n",
       "\n",
       "     congruent_mentions norm_full_mention  \\\n",
       "0  [EU, Franz Fischler]                eu   \n",
       "1  [EU, Franz Fischler]    franz fischler   \n",
       "2  [EU, Franz Fischler]    franz fischler   \n",
       "\n",
       "                 candidate_pool_page_ids          candidate_pool_item_ids  \\\n",
       "0  [9317, 9239, 21347120, 9477, 1882861]  [458, 46, 211593, 1396, 363404]   \n",
       "1                               [626779]                          [78587]   \n",
       "2                               [626779]                          [78587]   \n",
       "\n",
       "                               candidate_pool_titles  \\\n",
       "0  [European_Union, Europe, Eu,_Seine-Maritime, E...   \n",
       "1                                   [Franz_Fischler]   \n",
       "2                                   [Franz_Fischler]   \n",
       "\n",
       "                          candidate_pool_likelihoods  \n",
       "0  [0.9227799000000001, 0.024651, 0.0201960000000...  \n",
       "1                                              [1.0]  \n",
       "2                                              [1.0]  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define testing sentence_id\n",
    "sentence_predictions = predictions[predictions['sentence_id'] == sentence_id].reset_index(drop=True)\n",
    "sentence_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EU', 'Franz Fischler']\n"
     ]
    }
   ],
   "source": [
    "print(sentence_predictions['congruent_mentions'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU -> nan =? Citizenship of the European Union\n",
      "Franz Fischler -> Franz Fischler =? Franz Fischler\n",
      "*************************************************\n",
      "This congruent experiment is 50.0% accurate comparing page titles.\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for mention, pred in congruent_predictions.items():\n",
    "    pred_title = normalize_text(pred[0])\n",
    "    true_title = sentence_predictions[sentence_predictions['full_mention'] == mention]['wikipedia_title'].values[0]\n",
    "    print(mention, \"->\", true_title, \"=?\", pred_title)\n",
    "    if sentence_predictions[sentence_predictions['full_mention'] == mention]['wikipedia_title'].values[0] == pred_title:\n",
    "        accuracy += 1\n",
    "print(\"*************************************************\")\n",
    "print(f\"This congruent experiment is {round(accuracy/len(congruent_predictions)*100,3)}% accurate comparing page titles.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU -> None =? 1882861\n",
      "Franz Fischler -> 626779 =? 626779\n",
      "*************************************************\n",
      "This congruent experiment is 50.0% accurate comparing page IDs.\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for mention, pred in congruent_predictions.items():\n",
    "    pred_page_id = pred[1]\n",
    "    try:\n",
    "        true_page_id = int(sentence_predictions[sentence_predictions['full_mention'] == mention]['wikipedia_page_ID'].values[0])\n",
    "    except ValueError:\n",
    "        true_page_id = None\n",
    "    print(mention, \"->\", true_page_id, \"=?\", pred_page_id)\n",
    "    if sentence_predictions[sentence_predictions['full_mention'] == mention]['wikipedia_page_ID'].values[0] == pred_page_id:\n",
    "        accuracy += 1\n",
    "print(\"*************************************************\")\n",
    "print(f\"This congruent experiment is {round(accuracy/len(congruent_predictions)*100,3)}% accurate comparing page IDs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Congruence Predictions and Assess Accuracy over Entire Dataframe\n",
    "\n",
    "We now apply the per-sentence structure over the whole ACY dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 3,935 sentences to predict.\n"
     ]
    }
   ],
   "source": [
    "# Max sentence_id in dataframe\n",
    "max_sentence_id = len(predictions['sentence_id'].unique())\n",
    "print(\"We have {:,} sentences to predict.\".format(max_sentence_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3935/3935 [09:59<00:00,  6.56it/s] \n"
     ]
    }
   ],
   "source": [
    "# Iterate over whole dataframe to produce mention predictions for each sentence\n",
    "dataframe_predictions = {}\n",
    "for sid in tqdm(predictions['sentence_id'].unique()):\n",
    "    dataframe_predictions[sid] = get_congruent_predictions(sid, dataframe=predictions, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13781/13781 [00:02<00:00, 5818.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After congruence, we have achieved 25.158% accuracy comparing title.\n",
      "After congruence, we have achieved 27.081% accuracy comparing page ID.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over whole dataframe to calculate accuracy\n",
    "accurate_predictions_title = 0\n",
    "accurate_predictions_id = 0\n",
    "for row in tqdm(range(len(predictions))):\n",
    "    mention_df = predictions.iloc[row]\n",
    "    sid = mention_df['sentence_id']\n",
    "    fm = mention_df['full_mention']\n",
    "    title = mention_df['wikipedia_title']\n",
    "    page_id = mention_df['wikipedia_page_ID']\n",
    "    pred = dataframe_predictions[sid][fm]\n",
    "    norm_pred_title = normalize_text(pred[0])\n",
    "    pred_page_id = pred[1]\n",
    "#     print(fm, sid, \"||| True:\", title, \"==? Pred:\", norm_pred_title, \"|||\", norm_pred_title==title,\\\n",
    "#                  \"||| True ID: \", page_id, \"==? Pred:\", pred_page_id, \"|||\", pred_page_id==page_id)\n",
    "    if title == norm_pred_title:\n",
    "        accurate_predictions_title += 1\n",
    "    if page_id == pred_page_id:\n",
    "        accurate_predictions_id += 1\n",
    "print(\"After congruence, we have achieved {}% accuracy comparing title.\".format(round(accurate_predictions_title/len(predictions)*100, 3)))\n",
    "print(\"After congruence, we have achieved {}% accuracy comparing page ID.\".format(round(accurate_predictions_id/len(predictions)*100, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'candidate_pool_page_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-9ce3f58292a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mpred_page_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     print(fm, sid, \"||| True:\", title, page_id, \"==? Pred:\", norm_pred_title, pred_page_id, \"|||\",\\\n\u001b[0;32m---> 16\u001b[0;31m           norm_pred_title==title, pred_page_id==page_id, \" ||| Present? \", (page_id in candidate_pool_page_ids))\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnorm_pred_title\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0maccurate_predictions_title\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'candidate_pool_page_ids' is not defined"
     ]
    }
   ],
   "source": [
    "# Iterate over subset of dataframe to calculate accuracy and study output results\n",
    "accurate_predictions_title = 0\n",
    "accurate_predictions_id = 0\n",
    "rand_idx = np.random.randint(len(predictions)) # Observe random subsection of predictions\n",
    "window_size = 10\n",
    "for row in range(rand_idx, rand_idx+window_size):\n",
    "    mention_df = predictions.iloc[row]\n",
    "    sid = mention_df['sentence_id']\n",
    "    fm = mention_df['full_mention']\n",
    "    title = mention_df['wikipedia_title']\n",
    "    page_id = mention_df['wikipedia_page_ID']\n",
    "    pred = dataframe_predictions[sid][fm]\n",
    "    norm_pred_title = normalize_text(pred[0])\n",
    "    pred_page_id = pred[1]\n",
    "    print(fm, sid, \"||| True:\", title, page_id, \"==? Pred:\", norm_pred_title, pred_page_id, \"|||\",\\\n",
    "          norm_pred_title==title, pred_page_id==page_id, \" ||| Present? \", (page_id in candidate_pool_page_ids))\n",
    "    if title == norm_pred_title:\n",
    "        accurate_predictions_title += 1\n",
    "    if page_id == pred_page_id:\n",
    "        accurate_predictions_id += 1\n",
    "print(\"After congruence, we have achieved {}% accuracy comparing title.\".format(round(accurate_predictions_title/window_size*100, 3)))\n",
    "print(\"After congruence, we have achieved {}% accuracy comparing page ID.\".format(round(accurate_predictions_id/window_size*100, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Accuracy only with Full Mentions with Known True\n",
    "\n",
    "This is a better reflection of our success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9785\n"
     ]
    }
   ],
   "source": [
    "# Calculate length of input with known true values\n",
    "known_true = sum(predictions['wikipedia_page_ID'].notnull())\n",
    "print(known_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13781/13781 [00:01<00:00, 6949.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After congruence, we have achieved 35.432% accuracy comparing title.\n",
      "After congruence, we have achieved 38.14% accuracy comparing page ID.\n",
      "The right answer was present in 90.25% of candidate pools.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over whole dataframe to calculate accuracy\n",
    "accurate_predictions_title = 0\n",
    "accurate_predictions_id = 0\n",
    "present_predictions_id = 0\n",
    "for row in tqdm(range(len(predictions))):\n",
    "    mention_df = predictions.iloc[row]\n",
    "    sid = mention_df['sentence_id']\n",
    "    fm = mention_df['full_mention']\n",
    "    title = mention_df['wikipedia_title']\n",
    "    page_id = mention_df['wikipedia_page_ID']\n",
    "    candidate_pool_page_ids = mention_df['candidate_pool_page_ids']\n",
    "    if page_id is None:\n",
    "        pass\n",
    "    elif isinstance(title, float):\n",
    "        pass\n",
    "    else:\n",
    "        pred = dataframe_predictions[sid][fm]\n",
    "        norm_pred_title = normalize_text(pred[0])\n",
    "        pred_page_id = pred[1]\n",
    "#         print(fm, sid, \"||| True:\", title, page_id, \"==? Pred:\", norm_pred_title, pred_page_id, \"|||\",\\\n",
    "#               norm_pred_title==title, pred_page_id==page_id, \" ||| Present? \", (page_id in candidate_pool_page_ids))\n",
    "        if title == norm_pred_title:\n",
    "            accurate_predictions_title += 1\n",
    "        if page_id == pred_page_id:\n",
    "            accurate_predictions_id += 1\n",
    "        if page_id in candidate_pool_page_ids:\n",
    "            present_predictions_id += 1\n",
    "print(\"After congruence, we have achieved {}% accuracy comparing title.\".format(round(accurate_predictions_title/known_true*100, 3)))\n",
    "print(\"After congruence, we have achieved {}% accuracy comparing page ID.\".format(round(accurate_predictions_id/known_true*100, 3)))\n",
    "print(\"The right answer was present in {}% of candidate pools.\".format(round(present_predictions_id/known_true*100, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2260 12\n",
      "Los Angeles 2260 ||| True: Los Angeles 18110.0 ==? Pred: Los Angeles County, California 79734 ||| False False  ||| Present?  True\n",
      "Los Angeles 2260 ||| True: Los Angeles 18110.0 ==? Pred: Los Angeles County, California 79734 ||| False False  ||| Present?  True\n",
      "Greg Gagne 2260 ||| True: Greg Gagne (baseball) 4516364.0 ==? Pred: Greg Gagne (wrestler) 1983742 ||| False False  ||| Present?  True\n",
      "Greg Gagne 2260 ||| True: Greg Gagne (baseball) 4516364.0 ==? Pred: Greg Gagne (wrestler) 1983742 ||| False False  ||| Present?  True\n",
      "Chad Curtis 2260 ||| True: Chad Curtis 1821553.0 ==? Pred: Chad Curtis 1821553 ||| True True  ||| Present?  True\n",
      "Chad Curtis 2260 ||| True: Chad Curtis 1821553.0 ==? Pred: Chad Curtis 1821553 ||| True True  ||| Present?  True\n",
      "Los Angeles Dodgers 2260 ||| True: Los Angeles Dodgers 18213.0 ==? Pred: 1959 Los Angeles Dodgers season 12937911 ||| False False  ||| Present?  True\n",
      "Los Angeles Dodgers 2260 ||| True: Los Angeles Dodgers 18213.0 ==? Pred: 1959 Los Angeles Dodgers season 12937911 ||| False False  ||| Present?  True\n",
      "Los Angeles Dodgers 2260 ||| True: Los Angeles Dodgers 18213.0 ==? Pred: 1959 Los Angeles Dodgers season 12937911 ||| False False  ||| Present?  True\n",
      "New York Mets 2260 ||| True: New York Mets 21728.0 ==? Pred: 2006 New York Mets season 12163863 ||| False False  ||| Present?  True\n",
      "New York Mets 2260 ||| True: New York Mets 21728.0 ==? Pred: 2006 New York Mets season 12163863 ||| False False  ||| Present?  True\n",
      "New York Mets 2260 ||| True: New York Mets 21728.0 ==? Pred: 2006 New York Mets season 12163863 ||| False False  ||| Present?  True\n",
      "***************************************\n",
      "After congruence, we have achieved 16.667% accuracy comparing title.\n",
      "After congruence, we have achieved 16.667% accuracy comparing page ID.\n",
      "The right answer was present in 100.0% of candidate pools.\n"
     ]
    }
   ],
   "source": [
    "# Iterate over subset of dataframe to calculate accuracy and study output results\n",
    "accurate_predictions_title = 0\n",
    "accurate_predictions_id = 0\n",
    "present_predictions_id = 0\n",
    "predictions_count = 0\n",
    "\n",
    "# Generate random window\n",
    "rand_idx = np.random.randint(len(predictions)) # Observe random subsection of predictions\n",
    "window_size = 10\n",
    "\n",
    "# Pick random sentence\n",
    "rand_sid = np.random.choice(predictions['sentence_id'])\n",
    "rand_sentence_df = predictions[predictions['sentence_id'] == rand_sid]\n",
    "print(rand_sid, len(rand_sentence_df))\n",
    "\n",
    "for row in range(len(rand_sentence_df)):\n",
    "    mention_df = rand_sentence_df.iloc[row]\n",
    "    sid = mention_df['sentence_id']\n",
    "    fm = mention_df['full_mention']\n",
    "    title = mention_df['wikipedia_title']\n",
    "    page_id = mention_df['wikipedia_page_ID']\n",
    "    candidate_pool_page_ids = mention_df['candidate_pool_page_ids']\n",
    "    if page_id is None: # This handles calculating over only known true\n",
    "        pass\n",
    "    elif isinstance(title, float): # Another way to handle only known true\n",
    "        pass\n",
    "    else:\n",
    "        predictions_count += 1\n",
    "        pred = dataframe_predictions[sid][fm]\n",
    "        norm_pred_title = normalize_text(pred[0])\n",
    "        pred_page_id = pred[1]\n",
    "        print(fm, sid, \"||| True:\", title, page_id, \"==? Pred:\", norm_pred_title, pred_page_id, \"|||\",\\\n",
    "              norm_pred_title==title, pred_page_id==page_id, \" ||| Present? \", (page_id in candidate_pool_page_ids))\n",
    "        if title == norm_pred_title:\n",
    "            accurate_predictions_title += 1\n",
    "        if page_id == pred_page_id:\n",
    "            accurate_predictions_id += 1\n",
    "        if page_id in candidate_pool_page_ids:\n",
    "            present_predictions_id += 1\n",
    "print(\"***************************************\")\n",
    "print(\"After congruence, we have achieved {}% accuracy comparing title.\".format(round(accurate_predictions_title/predictions_count*100, 3)))\n",
    "print(\"After congruence, we have achieved {}% accuracy comparing page ID.\".format(round(accurate_predictions_id/predictions_count*100, 3)))\n",
    "print(\"The right answer was present in {}% of candidate pools.\".format(round(present_predictions_id/predictions_count*100, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>full_mention</th>\n",
       "      <th>wikipedia_URL</th>\n",
       "      <th>wikipedia_page_ID</th>\n",
       "      <th>wikipedia_title</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>congruent_mentions</th>\n",
       "      <th>norm_full_mention</th>\n",
       "      <th>candidate_pool_page_ids</th>\n",
       "      <th>candidate_pool_item_ids</th>\n",
       "      <th>candidate_pool_titles</th>\n",
       "      <th>candidate_pool_likelihoods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12038</th>\n",
       "      <td>B</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>http://en.wikipedia.org/wiki/São_Paulo_(state)</td>\n",
       "      <td>229422.0</td>\n",
       "      <td>São Paulo (state)</td>\n",
       "      <td>2879</td>\n",
       "      <td>471</td>\n",
       "      <td>[Sao Paulo, Mario Covas, Banespa, O Globo]</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>[390875, 229422, 187274]</td>\n",
       "      <td>[174, 175, 38568]</td>\n",
       "      <td>[São_Paulo, São_Paulo_(state), São_Paulo_FC]</td>\n",
       "      <td>[0.9563318999999999, 0.0334789, 0.0101892]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12039</th>\n",
       "      <td>I</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>http://en.wikipedia.org/wiki/São_Paulo_(state)</td>\n",
       "      <td>229422.0</td>\n",
       "      <td>São Paulo (state)</td>\n",
       "      <td>2879</td>\n",
       "      <td>471</td>\n",
       "      <td>[Sao Paulo, Mario Covas, Banespa, O Globo]</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>[390875, 229422, 187274]</td>\n",
       "      <td>[174, 175, 38568]</td>\n",
       "      <td>[São_Paulo, São_Paulo_(state), São_Paulo_FC]</td>\n",
       "      <td>[0.9563318999999999, 0.0334789, 0.0101892]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12040</th>\n",
       "      <td>B</td>\n",
       "      <td>Mario Covas</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Mário_Covas</td>\n",
       "      <td>3386439.0</td>\n",
       "      <td>Mário Covas</td>\n",
       "      <td>2879</td>\n",
       "      <td>471</td>\n",
       "      <td>[Sao Paulo, Mario Covas, Banespa, O Globo]</td>\n",
       "      <td>mario covas</td>\n",
       "      <td>[3386439]</td>\n",
       "      <td>[1669473]</td>\n",
       "      <td>[Mário_Covas]</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12041</th>\n",
       "      <td>I</td>\n",
       "      <td>Mario Covas</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Mário_Covas</td>\n",
       "      <td>3386439.0</td>\n",
       "      <td>Mário Covas</td>\n",
       "      <td>2879</td>\n",
       "      <td>471</td>\n",
       "      <td>[Sao Paulo, Mario Covas, Banespa, O Globo]</td>\n",
       "      <td>mario covas</td>\n",
       "      <td>[3386439]</td>\n",
       "      <td>[1669473]</td>\n",
       "      <td>[Mário_Covas]</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12042</th>\n",
       "      <td>B</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>http://en.wikipedia.org/wiki/São_Paulo_(state)</td>\n",
       "      <td>229422.0</td>\n",
       "      <td>São Paulo (state)</td>\n",
       "      <td>2879</td>\n",
       "      <td>471</td>\n",
       "      <td>[Sao Paulo, Mario Covas, Banespa, O Globo]</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>[390875, 229422, 187274]</td>\n",
       "      <td>[174, 175, 38568]</td>\n",
       "      <td>[São_Paulo, São_Paulo_(state), São_Paulo_FC]</td>\n",
       "      <td>[0.9563318999999999, 0.0334789, 0.0101892]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12043</th>\n",
       "      <td>I</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>http://en.wikipedia.org/wiki/São_Paulo_(state)</td>\n",
       "      <td>229422.0</td>\n",
       "      <td>São Paulo (state)</td>\n",
       "      <td>2879</td>\n",
       "      <td>471</td>\n",
       "      <td>[Sao Paulo, Mario Covas, Banespa, O Globo]</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>[390875, 229422, 187274]</td>\n",
       "      <td>[174, 175, 38568]</td>\n",
       "      <td>[São_Paulo, São_Paulo_(state), São_Paulo_FC]</td>\n",
       "      <td>[0.9563318999999999, 0.0334789, 0.0101892]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12044</th>\n",
       "      <td>B</td>\n",
       "      <td>Banespa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2879</td>\n",
       "      <td>471</td>\n",
       "      <td>[Sao Paulo, Mario Covas, Banespa, O Globo]</td>\n",
       "      <td>banespa</td>\n",
       "      <td>[32820442, 3752752]</td>\n",
       "      <td>[4854074, 169420]</td>\n",
       "      <td>[Banco_Banespa, Altino_Arantes_Building]</td>\n",
       "      <td>[0.8571429, 0.14285710000000001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12045</th>\n",
       "      <td>B</td>\n",
       "      <td>O Globo</td>\n",
       "      <td>http://en.wikipedia.org/wiki/O_Globo</td>\n",
       "      <td>2093729.0</td>\n",
       "      <td>O Globo</td>\n",
       "      <td>2879</td>\n",
       "      <td>471</td>\n",
       "      <td>[Sao Paulo, Mario Covas, Banespa, O Globo]</td>\n",
       "      <td>o globo</td>\n",
       "      <td>[2093729]</td>\n",
       "      <td>[970729]</td>\n",
       "      <td>[O_Globo]</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12046</th>\n",
       "      <td>I</td>\n",
       "      <td>O Globo</td>\n",
       "      <td>http://en.wikipedia.org/wiki/O_Globo</td>\n",
       "      <td>2093729.0</td>\n",
       "      <td>O Globo</td>\n",
       "      <td>2879</td>\n",
       "      <td>471</td>\n",
       "      <td>[Sao Paulo, Mario Covas, Banespa, O Globo]</td>\n",
       "      <td>o globo</td>\n",
       "      <td>[2093729]</td>\n",
       "      <td>[970729]</td>\n",
       "      <td>[O_Globo]</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mention full_mention                                   wikipedia_URL  \\\n",
       "12038       B    Sao Paulo  http://en.wikipedia.org/wiki/São_Paulo_(state)   \n",
       "12039       I    Sao Paulo  http://en.wikipedia.org/wiki/São_Paulo_(state)   \n",
       "12040       B  Mario Covas        http://en.wikipedia.org/wiki/Mário_Covas   \n",
       "12041       I  Mario Covas        http://en.wikipedia.org/wiki/Mário_Covas   \n",
       "12042       B    Sao Paulo  http://en.wikipedia.org/wiki/São_Paulo_(state)   \n",
       "12043       I    Sao Paulo  http://en.wikipedia.org/wiki/São_Paulo_(state)   \n",
       "12044       B      Banespa                                             NaN   \n",
       "12045       B      O Globo            http://en.wikipedia.org/wiki/O_Globo   \n",
       "12046       I      O Globo            http://en.wikipedia.org/wiki/O_Globo   \n",
       "\n",
       "       wikipedia_page_ID    wikipedia_title  sentence_id  doc_id  \\\n",
       "12038           229422.0  São Paulo (state)         2879     471   \n",
       "12039           229422.0  São Paulo (state)         2879     471   \n",
       "12040          3386439.0        Mário Covas         2879     471   \n",
       "12041          3386439.0        Mário Covas         2879     471   \n",
       "12042           229422.0  São Paulo (state)         2879     471   \n",
       "12043           229422.0  São Paulo (state)         2879     471   \n",
       "12044                NaN                NaN         2879     471   \n",
       "12045          2093729.0            O Globo         2879     471   \n",
       "12046          2093729.0            O Globo         2879     471   \n",
       "\n",
       "                               congruent_mentions norm_full_mention  \\\n",
       "12038  [Sao Paulo, Mario Covas, Banespa, O Globo]         sao paulo   \n",
       "12039  [Sao Paulo, Mario Covas, Banespa, O Globo]         sao paulo   \n",
       "12040  [Sao Paulo, Mario Covas, Banespa, O Globo]       mario covas   \n",
       "12041  [Sao Paulo, Mario Covas, Banespa, O Globo]       mario covas   \n",
       "12042  [Sao Paulo, Mario Covas, Banespa, O Globo]         sao paulo   \n",
       "12043  [Sao Paulo, Mario Covas, Banespa, O Globo]         sao paulo   \n",
       "12044  [Sao Paulo, Mario Covas, Banespa, O Globo]           banespa   \n",
       "12045  [Sao Paulo, Mario Covas, Banespa, O Globo]           o globo   \n",
       "12046  [Sao Paulo, Mario Covas, Banespa, O Globo]           o globo   \n",
       "\n",
       "        candidate_pool_page_ids candidate_pool_item_ids  \\\n",
       "12038  [390875, 229422, 187274]       [174, 175, 38568]   \n",
       "12039  [390875, 229422, 187274]       [174, 175, 38568]   \n",
       "12040                 [3386439]               [1669473]   \n",
       "12041                 [3386439]               [1669473]   \n",
       "12042  [390875, 229422, 187274]       [174, 175, 38568]   \n",
       "12043  [390875, 229422, 187274]       [174, 175, 38568]   \n",
       "12044       [32820442, 3752752]       [4854074, 169420]   \n",
       "12045                 [2093729]                [970729]   \n",
       "12046                 [2093729]                [970729]   \n",
       "\n",
       "                              candidate_pool_titles  \\\n",
       "12038  [São_Paulo, São_Paulo_(state), São_Paulo_FC]   \n",
       "12039  [São_Paulo, São_Paulo_(state), São_Paulo_FC]   \n",
       "12040                                 [Mário_Covas]   \n",
       "12041                                 [Mário_Covas]   \n",
       "12042  [São_Paulo, São_Paulo_(state), São_Paulo_FC]   \n",
       "12043  [São_Paulo, São_Paulo_(state), São_Paulo_FC]   \n",
       "12044      [Banco_Banespa, Altino_Arantes_Building]   \n",
       "12045                                     [O_Globo]   \n",
       "12046                                     [O_Globo]   \n",
       "\n",
       "                       candidate_pool_likelihoods  \n",
       "12038  [0.9563318999999999, 0.0334789, 0.0101892]  \n",
       "12039  [0.9563318999999999, 0.0334789, 0.0101892]  \n",
       "12040                                       [1.0]  \n",
       "12041                                       [1.0]  \n",
       "12042  [0.9563318999999999, 0.0334789, 0.0101892]  \n",
       "12043  [0.9563318999999999, 0.0334789, 0.0101892]  \n",
       "12044            [0.8571429, 0.14285710000000001]  \n",
       "12045                                       [1.0]  \n",
       "12046                                       [1.0]  "
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See original dataframe\n",
    "predictions[predictions['sentence_id'] == rand_sid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['São_Paulo', 'São_Paulo_(state)', 'São_Paulo_FC']"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See full candidate pool\n",
    "predictions[predictions['sentence_id'] == rand_sid]['candidate_pool_titles'].iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate with *Popularity* Predictions Known True Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>full_mention</th>\n",
       "      <th>wikipedia_URL</th>\n",
       "      <th>wikipedia_page_ID</th>\n",
       "      <th>wikipedia_title</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>congruent_mentions</th>\n",
       "      <th>norm_full_mention</th>\n",
       "      <th>candidate_pool_page_ids</th>\n",
       "      <th>candidate_pool_item_ids</th>\n",
       "      <th>candidate_pool_titles</th>\n",
       "      <th>candidate_pool_likelihoods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>EU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>eu</td>\n",
       "      <td>[9317, 9239, 9891, 9472, 10890716, 2780146, 18...</td>\n",
       "      <td>[458, 46, 45003, 4916, 185441, 932442, 8268, 8...</td>\n",
       "      <td>['European_Union', 'Europe', 'Entropy', 'Euro'...</td>\n",
       "      <td>[0.2237612, 0.2008411, 0.0962244, 0.0766248, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>German</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Germany</td>\n",
       "      <td>11867.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>german</td>\n",
       "      <td>[11867, 11867, 27318, 21148, 21212, 21212, 269...</td>\n",
       "      <td>[183, 183, 334, 55, 7318, 7318, 40, 12548, 825...</td>\n",
       "      <td>['Germany', 'Germany', 'Singapore', 'Netherlan...</td>\n",
       "      <td>[0.0494115, 0.0494115, 0.0485629, 0.0390487, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>British</td>\n",
       "      <td>http://en.wikipedia.org/wiki/United_Kingdom</td>\n",
       "      <td>31717.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['EU', 'German', 'British']</td>\n",
       "      <td>british</td>\n",
       "      <td>[3434750, 31717, 31717, 19344654, 26061, 85699...</td>\n",
       "      <td>[30, 145, 145, 9531, 172771, 1860, 21, 22, 868...</td>\n",
       "      <td>['United_States', 'United_Kingdom', 'United_Ki...</td>\n",
       "      <td>[0.115186, 0.0611816, 0.0611816, 0.0294143, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>Peter Blackburn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Peter Blackburn', 'BRUSSELS', 'European Comm...</td>\n",
       "      <td>peter blackburn</td>\n",
       "      <td>[56783206, 56873217, 9643132]</td>\n",
       "      <td>[2073954, 26634508, 7172840]</td>\n",
       "      <td>['Peter_Blackburn_(badminton)', 'Peter_Blackbu...</td>\n",
       "      <td>[0.6296296, 0.3703704, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>Peter Blackburn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>['Peter Blackburn', 'BRUSSELS', 'European Comm...</td>\n",
       "      <td>peter blackburn</td>\n",
       "      <td>[56783206, 56873217, 9643132]</td>\n",
       "      <td>[2073954, 26634508, 7172840]</td>\n",
       "      <td>['Peter_Blackburn_(badminton)', 'Peter_Blackbu...</td>\n",
       "      <td>[0.6296296, 0.3703704, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mention     full_mention                                wikipedia_URL  \\\n",
       "0       B               EU                                          NaN   \n",
       "1       B           German         http://en.wikipedia.org/wiki/Germany   \n",
       "2       B          British  http://en.wikipedia.org/wiki/United_Kingdom   \n",
       "3       B  Peter Blackburn                                          NaN   \n",
       "4       I  Peter Blackburn                                          NaN   \n",
       "\n",
       "   wikipedia_page_ID wikipedia_title  sentence_id  doc_id  \\\n",
       "0                NaN             NaN            0       0   \n",
       "1            11867.0         Germany            0       0   \n",
       "2            31717.0  United Kingdom            0       0   \n",
       "3                NaN             NaN            1       0   \n",
       "4                NaN             NaN            1       0   \n",
       "\n",
       "                                  congruent_mentions norm_full_mention  \\\n",
       "0                        ['EU', 'German', 'British']                eu   \n",
       "1                        ['EU', 'German', 'British']            german   \n",
       "2                        ['EU', 'German', 'British']           british   \n",
       "3  ['Peter Blackburn', 'BRUSSELS', 'European Comm...   peter blackburn   \n",
       "4  ['Peter Blackburn', 'BRUSSELS', 'European Comm...   peter blackburn   \n",
       "\n",
       "                             candidate_pool_page_ids  \\\n",
       "0  [9317, 9239, 9891, 9472, 10890716, 2780146, 18...   \n",
       "1  [11867, 11867, 27318, 21148, 21212, 21212, 269...   \n",
       "2  [3434750, 31717, 31717, 19344654, 26061, 85699...   \n",
       "3                      [56783206, 56873217, 9643132]   \n",
       "4                      [56783206, 56873217, 9643132]   \n",
       "\n",
       "                             candidate_pool_item_ids  \\\n",
       "0  [458, 46, 45003, 4916, 185441, 932442, 8268, 8...   \n",
       "1  [183, 183, 334, 55, 7318, 7318, 40, 12548, 825...   \n",
       "2  [30, 145, 145, 9531, 172771, 1860, 21, 22, 868...   \n",
       "3                       [2073954, 26634508, 7172840]   \n",
       "4                       [2073954, 26634508, 7172840]   \n",
       "\n",
       "                               candidate_pool_titles  \\\n",
       "0  ['European_Union', 'Europe', 'Entropy', 'Euro'...   \n",
       "1  ['Germany', 'Germany', 'Singapore', 'Netherlan...   \n",
       "2  ['United_States', 'United_Kingdom', 'United_Ki...   \n",
       "3  ['Peter_Blackburn_(badminton)', 'Peter_Blackbu...   \n",
       "4  ['Peter_Blackburn_(badminton)', 'Peter_Blackbu...   \n",
       "\n",
       "                          candidate_pool_likelihoods  \n",
       "0  [0.2237612, 0.2008411, 0.0962244, 0.0766248, 0...  \n",
       "1  [0.0494115, 0.0494115, 0.0485629, 0.0390487, 0...  \n",
       "2  [0.115186, 0.0611816, 0.0611816, 0.0294143, 0....  \n",
       "3                        [0.6296296, 0.3703704, 0.0]  \n",
       "4                        [0.6296296, 0.3703704, 0.0]  "
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "predictions_pop = pd.read_csv(os.path.join(preds_path, \"anchortext_popularity.csv\"), delimiter=\",\")\n",
    "predictions_pop.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ['Peter Blackburn', 'BRUSSELS', 'European Commission', 'German', 'British']\n",
      "After ['Peter Blackburn', 'BRUSSELS', 'European Commission', 'German', 'British']\n",
      "Before [56783206, 56873217, 9643132]\n",
      "After [56783206, 56873217, 9643132]\n",
      "Before [2073954, 26634508, 7172840]\n",
      "After [2073954, 26634508, 7172840]\n",
      "Before ['Peter_Blackburn_(badminton)', 'Peter_Blackburn_(MP)', 'Peter_Blackburn_(bishop)']\n",
      "After ['Peter_Blackburn_(badminton)', 'Peter_Blackburn_(MP)', 'Peter_Blackburn_(bishop)']\n",
      "Before [0.6296296, 0.3703704, 0.0]\n",
      "After [0.6296296, 0.3703704, 0.0]\n",
      "CPU times: user 683 ms, sys: 306 ms, total: 990 ms\n",
      "Wall time: 1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "### Apply defined function to entire dataframe for all candidate pool columns\n",
    "\n",
    "column = 'congruent_mentions'\n",
    "print(\"Before\", predictions_pop[column][3])\n",
    "parsed_candidate_pool = predictions_pop[column].apply(parse_list_string, value_type=str)\n",
    "predictions_pop[column] = parsed_candidate_pool\n",
    "print(\"After\", predictions_pop[column][3])\n",
    "\n",
    "column = 'candidate_pool_page_ids'\n",
    "print(\"Before\", predictions_pop[column][3])\n",
    "parsed_candidate_pool = predictions_pop[column].apply(parse_list_string, value_type=int)\n",
    "predictions_pop[column] = parsed_candidate_pool\n",
    "print(\"After\", predictions_pop[column][3])\n",
    "\n",
    "\n",
    "column = 'candidate_pool_item_ids'\n",
    "print(\"Before\", predictions_pop[column][3])\n",
    "parsed_candidate_pool = predictions_pop[column].apply(parse_list_string, value_type=int)\n",
    "predictions_pop[column] = parsed_candidate_pool\n",
    "print(\"After\", predictions_pop[column][3])\n",
    "\n",
    "\n",
    "column = 'candidate_pool_titles'\n",
    "print(\"Before\", predictions_pop[column][3])\n",
    "parsed_candidate_pool = predictions_pop[column].apply(parse_list_string, value_type=str)\n",
    "predictions_pop[column] = parsed_candidate_pool\n",
    "print(\"After\", predictions_pop[column][3])\n",
    "\n",
    "column = 'candidate_pool_likelihoods'\n",
    "print(\"Before\", predictions_pop[column][3])\n",
    "parsed_candidate_pool = predictions_pop[column].apply(parse_list_string, value_type=float)\n",
    "predictions_pop[column] = parsed_candidate_pool\n",
    "print(\"After\", predictions_pop[column][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22257\n"
     ]
    }
   ],
   "source": [
    "# Calculate length of input with known true values\n",
    "known_true = sum(predictions_pop['wikipedia_page_ID'].notnull())\n",
    "print(known_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>full_mention</th>\n",
       "      <th>wikipedia_URL</th>\n",
       "      <th>wikipedia_page_ID</th>\n",
       "      <th>wikipedia_title</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>congruent_mentions</th>\n",
       "      <th>norm_full_mention</th>\n",
       "      <th>candidate_pool_page_ids</th>\n",
       "      <th>candidate_pool_item_ids</th>\n",
       "      <th>candidate_pool_titles</th>\n",
       "      <th>candidate_pool_likelihoods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>EU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[EU, German, British]</td>\n",
       "      <td>eu</td>\n",
       "      <td>[9317, 9239, 9891, 9472, 10890716, 2780146, 18...</td>\n",
       "      <td>[458, 46, 45003, 4916, 185441, 932442, 8268, 8...</td>\n",
       "      <td>[European_Union, Europe, Entropy, Euro, Member...</td>\n",
       "      <td>[0.2237612, 0.2008411, 0.0962244, 0.0766248, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>German</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Germany</td>\n",
       "      <td>11867.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[EU, German, British]</td>\n",
       "      <td>german</td>\n",
       "      <td>[11867, 11867, 27318, 21148, 21212, 21212, 269...</td>\n",
       "      <td>[183, 183, 334, 55, 7318, 7318, 40, 12548, 825...</td>\n",
       "      <td>[Germany, Germany, Singapore, Netherlands, Naz...</td>\n",
       "      <td>[0.0494115, 0.0494115, 0.0485629, 0.0390487, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>British</td>\n",
       "      <td>http://en.wikipedia.org/wiki/United_Kingdom</td>\n",
       "      <td>31717.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[EU, German, British]</td>\n",
       "      <td>british</td>\n",
       "      <td>[3434750, 31717, 31717, 19344654, 26061, 85699...</td>\n",
       "      <td>[30, 145, 145, 9531, 172771, 1860, 21, 22, 868...</td>\n",
       "      <td>[United_States, United_Kingdom, United_Kingdom...</td>\n",
       "      <td>[0.115186, 0.0611816, 0.0611816, 0.0294143, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mention full_mention                                wikipedia_URL  \\\n",
       "0       B           EU                                          NaN   \n",
       "1       B       German         http://en.wikipedia.org/wiki/Germany   \n",
       "2       B      British  http://en.wikipedia.org/wiki/United_Kingdom   \n",
       "\n",
       "   wikipedia_page_ID wikipedia_title  sentence_id  doc_id  \\\n",
       "0                NaN             NaN            0       0   \n",
       "1            11867.0         Germany            0       0   \n",
       "2            31717.0  United Kingdom            0       0   \n",
       "\n",
       "      congruent_mentions norm_full_mention  \\\n",
       "0  [EU, German, British]                eu   \n",
       "1  [EU, German, British]            german   \n",
       "2  [EU, German, British]           british   \n",
       "\n",
       "                             candidate_pool_page_ids  \\\n",
       "0  [9317, 9239, 9891, 9472, 10890716, 2780146, 18...   \n",
       "1  [11867, 11867, 27318, 21148, 21212, 21212, 269...   \n",
       "2  [3434750, 31717, 31717, 19344654, 26061, 85699...   \n",
       "\n",
       "                             candidate_pool_item_ids  \\\n",
       "0  [458, 46, 45003, 4916, 185441, 932442, 8268, 8...   \n",
       "1  [183, 183, 334, 55, 7318, 7318, 40, 12548, 825...   \n",
       "2  [30, 145, 145, 9531, 172771, 1860, 21, 22, 868...   \n",
       "\n",
       "                               candidate_pool_titles  \\\n",
       "0  [European_Union, Europe, Entropy, Euro, Member...   \n",
       "1  [Germany, Germany, Singapore, Netherlands, Naz...   \n",
       "2  [United_States, United_Kingdom, United_Kingdom...   \n",
       "\n",
       "                          candidate_pool_likelihoods  \n",
       "0  [0.2237612, 0.2008411, 0.0962244, 0.0766248, 0...  \n",
       "1  [0.0494115, 0.0494115, 0.0485629, 0.0390487, 0...  \n",
       "2  [0.115186, 0.0611816, 0.0611816, 0.0294143, 0....  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congruent Mentions:  ['EU', 'German', 'British']\n",
      "Congruent Mentions as numbers:  [0 1 2]\n",
      "['European_Union', 'Europe', 'Entropy', 'Euro', 'Member_state_of_the_European_Union', 'European_emission_standards', 'Eurozone', 'European_Parliament', 'European_Commission', 'Europe,_the_Middle_East_and_Africa']\n",
      "Failed Wikipedia2Vec Entity Vector Queries: 0\n",
      "['Germany', 'Germany', 'Singapore', 'Netherlands', 'Nazi_Germany', 'Nazi_Germany', 'Austria', 'Holy_Roman_Empire', 'Bundesliga', 'Age_of_Enlightenment']\n",
      "Failed Wikipedia2Vec Entity Vector Queries: 0\n",
      "['United_States', 'United_Kingdom', 'United_Kingdom', 'BBC', 'Royal_Navy', 'English_language', 'England', 'Scotland', 'British_Empire', 'Commonwealth_of_Nations']\n",
      "Failed Wikipedia2Vec Entity Vector Queries: 0\n",
      "dict_keys([0, 1, 2])\n",
      "10\n",
      "10\n",
      "10\n",
      "Mentions with Vectors:  dict_keys([0, 1, 2])\n",
      "Comparing mentions 0 & 1\n",
      "Comparing mentions 0 & 2\n",
      "Comparing mentions 1 & 2\n",
      "First-Level Congruence Keys:  dict_keys([0, 1])\n",
      "Comparing mentions 0 & 1\n",
      "Comparing mentions 0 & 2\n",
      "Comparing mentions 1 & 2\n",
      "Comparing 0 & 1\n",
      "Congruent Pair:  ((1, 3), 0.05630195596694946)\n",
      "Current Most Congruent:  (((None, None), 0.0), (0, 0))\n",
      "Comparing 0 & 2\n",
      "Congruent Pair:  ((1, 0), 0.07658241383750587)\n",
      "Current Most Congruent:  (((1, 3), 0.05630195596694946), (0, 1))\n",
      "Comparing 1 & 2\n",
      "Congruent Pair:  ((0, 0), 0.032764191008694474)\n",
      "Current Most Congruent:  (((1, 0), 0.07658241383750587), (0, 2))\n",
      "Final Most Congruent Pair:  (((1, 0), 0.07658241383750587), (0, 2))\n",
      "(((1, 0), 0.07658241383750587), (0, 2))\n",
      "[1] dict_keys([0, 2])\n",
      "Comparing 0 & 1\n",
      "Congruent Pair:  ((1, 3), 0.05630195596694946)\n",
      "Current Most Congruent:  (((None, None), 0.0), (0, 0))\n",
      "Comparing 1 & 2\n",
      "Congruent Pair:  ((0, 0), 0.032764191008694474)\n",
      "Current Most Congruent:  (((1, 3), 0.05630195596694946), (0, 1))\n",
      "Final Most Congruent Pair:  (((1, 3), 0.05630195596694946), (0, 1))\n",
      "[] dict_keys([0, 2, 1])\n",
      "{0: 1, 2: 0, 1: 3}\n",
      "0 1\n",
      "EU Europe 9239\n",
      "2 0\n",
      "British United_States 3434750\n",
      "1 3\n",
      "German Netherlands 21148\n",
      "{'EU': ('Europe', 9239), 'British': ('United_States', 3434750), 'German': ('Netherlands', 21148)}\n",
      "CPU times: user 26.4 ms, sys: 10 ms, total: 36.4 ms\n",
      "Wall time: 36.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Test out function\n",
    "congruent_predictions = get_congruent_predictions(sentence_id=0, dataframe=predictions_pop, verbose=True)\n",
    "print(congruent_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4516/4516 [02:34<00:00, 29.14it/s] \n"
     ]
    }
   ],
   "source": [
    "# Iterate over whole dataframe to produce mention predictions for each sentence\n",
    "dataframe_predictions_pop = {}\n",
    "for sid in tqdm(predictions_pop['sentence_id'].unique()):\n",
    "    dataframe_predictions_pop[sid] = get_congruent_predictions(sid, dataframe=predictions_pop, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29312/29312 [00:03<00:00, 7468.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After congruence, we have achieved 57.959% accuracy comparing title.\n",
      "After congruence, we have achieved 62.066% accuracy comparing page ID.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over whole dataframe to calculate accuracy\n",
    "accurate_predictions_title = 0\n",
    "accurate_predictions_id = 0\n",
    "for row in tqdm(range(len(predictions_pop))):\n",
    "    mention_df = predictions_pop.iloc[row]\n",
    "    sid = mention_df['sentence_id']\n",
    "    fm = mention_df['full_mention']\n",
    "    title = mention_df['wikipedia_title']\n",
    "    page_id = mention_df['wikipedia_page_ID']\n",
    "    if page_id is None:\n",
    "        pass\n",
    "    else:\n",
    "        pred = dataframe_predictions_pop[sid][fm]\n",
    "        norm_pred_title = normalize_text(pred[0])\n",
    "        pred_page_id = pred[1]\n",
    "    #     print(fm, sid, \"||| True:\", title, \"==? Pred:\", norm_pred_title, \"|||\", norm_pred_title==title,\\\n",
    "    #                  \"||| True ID: \", page_id, \"==? Pred:\", pred_page_id, \"|||\", pred_page_id==page_id)\n",
    "        if title == norm_pred_title:\n",
    "            accurate_predictions_title += 1\n",
    "        if page_id == pred_page_id:\n",
    "            accurate_predictions_id += 1\n",
    "print(\"After congruence, we have achieved {}% accuracy comparing title.\".format(round(accurate_predictions_title/known_true*100, 3)))\n",
    "print(\"After congruence, we have achieved {}% accuracy comparing page ID.\".format(round(accurate_predictions_id/known_true*100, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logical Flow Demonstration\n",
    "\n",
    "The cells below have been included as a more easily understood logical flow to understand how we designed the recursive congruence algorithm for an arbitrary length of full mentions in a sentence. We manually select a sentence and work through that. This is identical to the above but with more printed out breaks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Known Oddities\n",
    "1. Test with sentence_id == 1. We only return unique mentions in a single sentence. Is that ok?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>full_mention</th>\n",
       "      <th>wikipedia_URL</th>\n",
       "      <th>wikipedia_page_ID</th>\n",
       "      <th>wikipedia_title</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>congruent_mentions</th>\n",
       "      <th>norm_full_mention</th>\n",
       "      <th>candidate_pool_page_ids</th>\n",
       "      <th>candidate_pool_item_ids</th>\n",
       "      <th>candidate_pool_titles</th>\n",
       "      <th>candidate_pool_likelihoods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>Peter Blackburn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Peter Blackburn, BRUSSELS, European Commissio...</td>\n",
       "      <td>peter blackburn</td>\n",
       "      <td>[56783206, 9643132, 56873217]</td>\n",
       "      <td>[2073954, 7172840, 26634508]</td>\n",
       "      <td>[Peter_Blackburn_(badminton), Peter_Blackburn_...</td>\n",
       "      <td>[0.5, 0.3, 0.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>BRUSSELS</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Brussels</td>\n",
       "      <td>3708.0</td>\n",
       "      <td>Brussels</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Peter Blackburn, BRUSSELS, European Commissio...</td>\n",
       "      <td>brussels</td>\n",
       "      <td>[3708, 575501, 1437181, 269753, 4152470]</td>\n",
       "      <td>[240, 239, 1050331, 28934, 800587]</td>\n",
       "      <td>[Brussels, City_of_Brussels, R.W.D.M._Brussels...</td>\n",
       "      <td>[0.9631528, 0.011514700000000001, 0.0037143999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>European Commission</td>\n",
       "      <td>http://en.wikipedia.org/wiki/European_Commission</td>\n",
       "      <td>9974.0</td>\n",
       "      <td>European Commission</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Peter Blackburn, BRUSSELS, European Commissio...</td>\n",
       "      <td>european commission</td>\n",
       "      <td>[9974, 24468, 1130631, 1549462, 656283]</td>\n",
       "      <td>[8880, 8882, 388354, 1780232, 2661677]</td>\n",
       "      <td>[European_Commission, President_of_the_Europea...</td>\n",
       "      <td>[0.9959089, 0.0008894, 0.0005336000000000001, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>German</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Germany</td>\n",
       "      <td>11867.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Peter Blackburn, BRUSSELS, European Commissio...</td>\n",
       "      <td>german</td>\n",
       "      <td>[11867, 11884, 152735, 21212, 12674]</td>\n",
       "      <td>[183, 188, 42884, 7318, 43287]</td>\n",
       "      <td>[Germany, German_language, Germans, Nazi_Germa...</td>\n",
       "      <td>[0.4192066, 0.2893363, 0.1470461, 0.03832, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>British</td>\n",
       "      <td>http://en.wikipedia.org/wiki/United_Kingdom</td>\n",
       "      <td>31717.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[Peter Blackburn, BRUSSELS, European Commissio...</td>\n",
       "      <td>british</td>\n",
       "      <td>[31717, 19097669, 13530298, 4721, 158019]</td>\n",
       "      <td>[145, 842438, 23666, 8680, 161885]</td>\n",
       "      <td>[United_Kingdom, British_people, Great_Britain...</td>\n",
       "      <td>[0.6101255999999999, 0.1146913, 0.0681775, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mention         full_mention  \\\n",
       "0       B      Peter Blackburn   \n",
       "1       B             BRUSSELS   \n",
       "2       B  European Commission   \n",
       "3       B               German   \n",
       "4       B              British   \n",
       "\n",
       "                                      wikipedia_URL  wikipedia_page_ID  \\\n",
       "0                                               NaN                NaN   \n",
       "1             http://en.wikipedia.org/wiki/Brussels             3708.0   \n",
       "2  http://en.wikipedia.org/wiki/European_Commission             9974.0   \n",
       "3              http://en.wikipedia.org/wiki/Germany            11867.0   \n",
       "4       http://en.wikipedia.org/wiki/United_Kingdom            31717.0   \n",
       "\n",
       "       wikipedia_title  sentence_id  doc_id  \\\n",
       "0                  NaN            1       0   \n",
       "1             Brussels            1       0   \n",
       "2  European Commission            1       0   \n",
       "3              Germany            1       0   \n",
       "4       United Kingdom            1       0   \n",
       "\n",
       "                                  congruent_mentions    norm_full_mention  \\\n",
       "0  [Peter Blackburn, BRUSSELS, European Commissio...      peter blackburn   \n",
       "1  [Peter Blackburn, BRUSSELS, European Commissio...             brussels   \n",
       "2  [Peter Blackburn, BRUSSELS, European Commissio...  european commission   \n",
       "3  [Peter Blackburn, BRUSSELS, European Commissio...               german   \n",
       "4  [Peter Blackburn, BRUSSELS, European Commissio...              british   \n",
       "\n",
       "                     candidate_pool_page_ids  \\\n",
       "0              [56783206, 9643132, 56873217]   \n",
       "1   [3708, 575501, 1437181, 269753, 4152470]   \n",
       "2    [9974, 24468, 1130631, 1549462, 656283]   \n",
       "3       [11867, 11884, 152735, 21212, 12674]   \n",
       "4  [31717, 19097669, 13530298, 4721, 158019]   \n",
       "\n",
       "                  candidate_pool_item_ids  \\\n",
       "0            [2073954, 7172840, 26634508]   \n",
       "1      [240, 239, 1050331, 28934, 800587]   \n",
       "2  [8880, 8882, 388354, 1780232, 2661677]   \n",
       "3          [183, 188, 42884, 7318, 43287]   \n",
       "4      [145, 842438, 23666, 8680, 161885]   \n",
       "\n",
       "                               candidate_pool_titles  \\\n",
       "0  [Peter_Blackburn_(badminton), Peter_Blackburn_...   \n",
       "1  [Brussels, City_of_Brussels, R.W.D.M._Brussels...   \n",
       "2  [European_Commission, President_of_the_Europea...   \n",
       "3  [Germany, German_language, Germans, Nazi_Germa...   \n",
       "4  [United_Kingdom, British_people, Great_Britain...   \n",
       "\n",
       "                          candidate_pool_likelihoods  \n",
       "0                                    [0.5, 0.3, 0.2]  \n",
       "1  [0.9631528, 0.011514700000000001, 0.0037143999...  \n",
       "2  [0.9959089, 0.0008894, 0.0005336000000000001, ...  \n",
       "3  [0.4192066, 0.2893363, 0.1470461, 0.03832, 0.0...  \n",
       "4  [0.6101255999999999, 0.1146913, 0.0681775, 0.0...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test on manually selected sentence\n",
    "sentence_predictions = predictions[predictions['sentence_id'] == 1].drop_duplicates(['full_mention', 'wikipedia_page_ID', 'sentence_id']).reset_index(drop=True)\n",
    "sentence_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Peter Blackburn', 'BRUSSELS', 'European Commission', 'German', 'British']\n"
     ]
    }
   ],
   "source": [
    "# Congruent Mention\n",
    "print(sentence_predictions['congruent_mentions'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to numerical for easier recursive logic later\n",
    "sentence_mention_nums = np.arange(len(sentence_predictions['congruent_mentions'][0]))\n",
    "sentence_mention_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate candidate lists of vectors\n",
    "def get_candidate_pool_vectors(candidate_pool_titles, verbose=False):\n",
    "    \"\"\"\n",
    "    Function to return entity vectors from Wikipedia2Vec\n",
    "    Takes as input a list of page titles, representing the candidate pool\n",
    "    Normalizes each page title to match necessary input format\n",
    "    Returns entity vector or empty vector if no match\n",
    "    \"\"\"\n",
    "    # Track failed vector queries\n",
    "    no_vector_count = 0\n",
    "    candidate_pool_vectors = []\n",
    "    for candidate in candidate_pool_titles:\n",
    "        candidate = normalize_text(candidate)\n",
    "        try:\n",
    "            candidate_vectors = w2v.get_entity_vector(candidate)\n",
    "        except KeyError:\n",
    "            # Keep empty vector representation to maintain index locations\n",
    "            candidate_vectors = np.zeros(100)\n",
    "            no_vector_count += 1\n",
    "        candidate_pool_vectors.append(candidate_vectors)\n",
    "    \n",
    "    if len(candidate_pool_titles) == 0:\n",
    "        candidate_pool_vectors = [np.zeros(100), np.zeros(100), np.zeros(100)]\n",
    "    \n",
    "    if verbose: print(f\"Failed Wikipedia2Vec Entity Vector Queries: {no_vector_count}\")\n",
    "    return candidate_pool_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed Wikipedia2Vec Entity Vector Queries: 2\n",
      "Failed Wikipedia2Vec Entity Vector Queries: 0\n",
      "Failed Wikipedia2Vec Entity Vector Queries: 0\n",
      "Failed Wikipedia2Vec Entity Vector Queries: 0\n",
      "Failed Wikipedia2Vec Entity Vector Queries: 0\n"
     ]
    }
   ],
   "source": [
    "# Save vectors in dictionary\n",
    "vector_dict = {}\n",
    "\n",
    "# For each full mention we are analyzing in the contextual domain (i.e. sentence)\n",
    "for m in sentence_mention_nums:\n",
    "    \n",
    "    # Retrieve candidate pool titles\n",
    "    candidate_pool_titles = sentence_predictions['candidate_pool_titles'][m]\n",
    "    \n",
    "    # Convert candidate pool titles to candidate pool vectors\n",
    "    candidate_pool_vectors = get_candidate_pool_vectors(candidate_pool_titles, verbose=True)\n",
    "    \n",
    "    # Save candidate pool vectors to dictionary\n",
    "    vector_dict[m] = candidate_pool_vectors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[memmap([ 0.73999596, -0.2850568 ,  0.88725674, -0.50734735, -0.6356713 ,\n",
       "         -0.20261607,  0.01270186, -0.43192133,  0.17652708, -1.2671794 ,\n",
       "          0.25022364, -0.8501609 ,  1.1788144 , -0.9606329 ,  0.2951649 ,\n",
       "          0.28013518,  0.4906645 , -0.04022525,  0.30440256, -0.7108611 ,\n",
       "         -1.0442777 ,  0.23103824, -0.16828535, -0.4928129 , -0.5990831 ,\n",
       "          0.65428317,  0.55305684,  0.09535707,  0.41192013, -0.5112566 ,\n",
       "         -0.03250094, -0.26022622,  0.9529309 ,  0.00581418, -0.40577435,\n",
       "          0.54995644,  0.8707861 ,  0.8141234 ,  0.25183964, -1.4443197 ,\n",
       "         -0.88571143,  0.09944484, -0.5551198 ,  0.951958  , -0.5003791 ,\n",
       "         -0.3015914 , -0.2980206 ,  0.14974946, -0.64372563, -0.63113153,\n",
       "          1.1873055 ,  0.03172509, -0.2136898 , -1.1639937 ,  0.24281068,\n",
       "          0.3994873 ,  0.23474444,  0.60516006, -1.0773419 ,  0.8272827 ,\n",
       "          1.0121135 , -0.5333727 , -0.9532066 ,  0.67113334,  0.62456834,\n",
       "         -0.5706873 , -0.11329702,  1.2998549 , -0.6561267 , -1.5774893 ,\n",
       "          0.6048041 , -0.65593195, -0.04254211, -0.48887396, -0.5335978 ,\n",
       "          0.24304646, -0.34997603, -0.05208633, -0.2791088 , -0.76673913,\n",
       "          0.25704738, -0.9789742 ,  0.37342316, -0.27575028, -0.3059331 ,\n",
       "          1.046559  , -0.00690197, -0.23636982,  0.1740074 , -0.6322686 ,\n",
       "         -0.46409073,  0.10697933,  0.11636787, -0.6818818 ,  0.38791785,\n",
       "         -0.16901833,  0.25792092,  0.69184303, -0.5075059 , -0.837258  ],\n",
       "        dtype=float32),\n",
       " memmap([ 5.6705320e-01, -3.3967879e-01,  6.7967427e-01, -8.8146311e-01,\n",
       "         -9.9295086e-01, -3.8026679e-01,  3.1121460e-01, -1.2859932e-01,\n",
       "          6.6351652e-01, -1.9566450e+00,  3.7053553e-04, -2.7253684e-01,\n",
       "          8.7685895e-01, -9.0732628e-01,  3.2349053e-01,  5.2059549e-01,\n",
       "          5.6463188e-01, -6.1859089e-01,  4.5522106e-01, -7.2353148e-01,\n",
       "         -9.7908747e-01,  1.5604380e+00, -8.5058933e-01, -3.0102137e-01,\n",
       "         -7.3634320e-01,  6.0062087e-01, -5.4628011e-02,  6.4058477e-01,\n",
       "          6.5022165e-01,  2.9072487e-01,  1.2940426e+00, -9.4071068e-02,\n",
       "          4.9198017e-01,  3.0347526e-01, -5.4809892e-01, -2.0429029e-01,\n",
       "          9.0489048e-01,  2.7048671e-01,  3.9246964e-01, -1.1840639e+00,\n",
       "         -4.3033957e-01, -7.5106245e-01, -5.7284772e-01,  1.4852484e+00,\n",
       "         -8.7626231e-01, -7.4376535e-01, -1.5343527e-01, -7.3458463e-02,\n",
       "         -3.2605672e-01, -1.0146785e+00,  1.0237430e+00, -9.4328153e-01,\n",
       "          3.4996659e-02, -2.0044473e-01, -1.9703417e-01,  9.8306006e-01,\n",
       "          1.2443291e+00,  4.4966465e-01, -1.7725631e+00,  1.4776839e+00,\n",
       "          3.4709200e-01, -6.4714819e-01, -1.2517909e+00,  1.3799247e-01,\n",
       "          8.6123645e-01, -7.0240957e-01,  2.6356363e-01,  1.7173262e+00,\n",
       "         -1.1625690e+00, -7.3700833e-01,  8.7417591e-01, -7.2752094e-01,\n",
       "          5.1354527e-01, -1.4106265e-01,  4.3454650e-01, -2.7464458e-01,\n",
       "         -2.5152385e-01, -1.6812341e-01, -9.3517298e-01,  1.0230876e-01,\n",
       "          4.6504697e-01, -1.7253537e+00,  8.3058596e-01, -4.7467527e-01,\n",
       "         -5.2035451e-01,  3.3971253e-01,  1.5667379e+00,  1.4175670e+00,\n",
       "          4.1496566e-01, -8.0814487e-01, -9.0114975e-01,  8.7815797e-01,\n",
       "         -1.3504833e+00, -1.2146077e+00,  1.3884471e-01, -1.1015518e+00,\n",
       "         -1.5871716e-01, -5.3572315e-03, -1.1229993e+00,  3.8020507e-01],\n",
       "        dtype=float32),\n",
       " memmap([-0.32749936,  0.22239937,  0.23898569, -0.8550402 , -0.85611784,\n",
       "         -0.44711158,  0.13595648,  0.39365363,  1.3342729 , -1.2536842 ,\n",
       "         -0.2853296 , -1.099066  ,  0.6528767 , -1.2918848 , -0.74594367,\n",
       "         -0.28895608,  1.9094849 , -0.55642927, -0.24626006, -1.4926728 ,\n",
       "          0.5468181 ,  1.4468939 , -0.19011495, -0.5858889 , -1.4324374 ,\n",
       "          1.2070076 , -0.52515227,  0.77274644, -0.00573518, -0.36234498,\n",
       "          0.35192552, -1.099419  ,  0.82299453, -0.03887451, -0.02446946,\n",
       "         -0.17156638, -0.02022919,  0.01724946, -0.8944577 , -1.1395341 ,\n",
       "         -0.78923655,  0.31393325, -0.95563346,  0.12488271, -0.69004816,\n",
       "         -0.29749197, -0.86809623,  0.7933139 , -0.71426   ,  0.9254206 ,\n",
       "         -0.1382166 ,  0.28578267, -1.1550982 , -0.6735067 ,  0.5257328 ,\n",
       "         -0.19279411,  1.2008257 ,  1.2472584 ,  0.45953104,  0.19035457,\n",
       "         -0.17070356, -0.7877188 , -0.35678363, -0.91281503,  1.7200077 ,\n",
       "          0.31424206, -0.9719698 ,  1.2214743 , -0.49583736, -1.8288046 ,\n",
       "         -0.01189204, -0.404493  ,  0.86855274, -0.69529223, -0.05967084,\n",
       "          0.1467268 ,  0.4243536 ,  0.09690609,  0.1705214 , -0.17994457,\n",
       "          0.18131131, -0.6324867 ,  0.3015342 , -0.44308695, -1.4086918 ,\n",
       "          0.15663816, -1.1484084 ,  0.12123189,  0.28727305, -0.9169716 ,\n",
       "         -0.49255705,  1.8306959 ,  0.23311996, -0.28941548, -0.02125252,\n",
       "         -1.0847679 ,  0.82647645,  1.0584866 , -0.3514583 , -0.01739193],\n",
       "        dtype=float32),\n",
       " memmap([ 0.49636444, -0.86528134,  1.1788532 , -0.30922556, -0.9746154 ,\n",
       "         -0.3006828 , -0.09782214,  0.63527215,  0.42122337, -1.1919249 ,\n",
       "         -0.3059436 , -1.5930003 ,  1.4265698 , -1.2332215 ,  0.1535172 ,\n",
       "         -0.7177122 ,  0.39487252, -0.21477821,  1.4715476 , -1.2706604 ,\n",
       "         -0.7104477 ,  1.1048641 ,  0.25898832, -0.798658  , -0.3222457 ,\n",
       "          0.4416954 ,  0.35707518, -0.26406765,  0.5775286 ,  0.17936766,\n",
       "          0.8198438 ,  0.06974518,  1.0141144 ,  0.06422611, -0.03402249,\n",
       "         -0.3128955 ,  0.41933072,  0.3987855 , -0.24418177, -1.3106128 ,\n",
       "         -1.2324655 , -1.0146224 ,  0.01501042,  0.3660241 , -1.6638688 ,\n",
       "          0.22348987, -0.27600503, -0.6694157 , -1.2813332 , -0.10872387,\n",
       "          1.2395383 , -0.20197892,  0.00286648, -0.3906428 ,  0.07045056,\n",
       "          1.2450467 ,  1.1010966 ,  1.122882  , -0.11116055,  0.9988503 ,\n",
       "         -0.36205414, -2.3066163 , -0.61724466, -0.16229507,  0.86683387,\n",
       "         -1.313807  , -0.6351795 ,  0.9479702 , -0.8548799 , -1.8868064 ,\n",
       "          0.6917876 , -0.51526564,  0.30974808,  0.20916647, -0.38765594,\n",
       "         -0.29028484, -0.03893029, -0.9750075 , -0.4461735 , -1.0264297 ,\n",
       "          0.4592011 , -1.2573234 ,  1.1663984 ,  0.5527039 , -0.05900641,\n",
       "          0.5128983 , -0.3349524 ,  0.71201   , -0.51241827, -0.06634152,\n",
       "          0.40056118,  0.62022644,  0.20883565, -0.81926715,  0.5015126 ,\n",
       "         -0.86500585, -0.64207333,  0.5526563 ,  0.6141147 , -1.3354753 ],\n",
       "        dtype=float32),\n",
       " memmap([ 0.26075822, -0.17177996,  0.54727465, -1.31096   , -1.1041497 ,\n",
       "         -0.10734481, -0.27140617, -0.01273954,  0.5953468 , -1.4077523 ,\n",
       "         -0.24663545, -1.1425214 ,  0.94410515, -2.0732722 , -0.89343405,\n",
       "         -0.08139441,  0.83815694, -0.06334883, -0.04061043, -1.4083842 ,\n",
       "         -1.0479853 ,  1.4667585 , -0.16216806,  0.2871689 , -1.2968209 ,\n",
       "          0.44738424,  1.137081  ,  0.06771982,  0.44236508,  0.26128504,\n",
       "          1.9076096 , -0.05479275,  1.4054909 , -0.48837763,  0.48326677,\n",
       "          0.0554915 ,  1.0067469 ,  0.19573171,  0.08178793, -1.4209036 ,\n",
       "         -0.6273465 ,  0.16033924,  0.41513494,  0.9361944 , -0.64741457,\n",
       "         -0.3508181 , -0.43233982,  0.13551304, -0.990383  , -1.3655506 ,\n",
       "          1.0968257 ,  0.26693165,  0.2992288 , -0.4878189 ,  0.5361877 ,\n",
       "          0.7514933 ,  0.3694579 ,  1.5416545 , -0.47786808,  1.0841135 ,\n",
       "         -0.32841158, -1.4819535 , -0.25318268, -0.09228084,  0.30517486,\n",
       "         -0.947712  , -0.36601377,  0.8697557 , -0.96219397, -1.8463647 ,\n",
       "          0.8626132 , -0.14014101,  0.654409  , -0.46502638,  0.8586214 ,\n",
       "          0.08285124,  0.2427678 , -0.27181068, -0.1884906 , -0.9206421 ,\n",
       "          0.24981752, -0.6211122 ,  0.6154762 ,  0.7102961 , -0.33678898,\n",
       "          1.3109715 ,  0.6368831 ,  1.015096  , -0.27756816, -0.16716368,\n",
       "         -0.12556131,  0.19664241,  0.08360512, -0.1030985 ,  0.2344761 ,\n",
       "         -0.30966803,  0.19796441,  0.93126917, -0.28040844, -0.01932705],\n",
       "        dtype=float32)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display vector_dict output\n",
    "print(vector_dict.keys())\n",
    "# Preview one candidate vector from a candidate pool vectors\n",
    "vector_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[range(0, 3), range(0, 5), range(0, 5), range(0, 5), range(0, 5)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Structure logic to create all combinations of candidates\n",
    "candidate_counts = [range(len(v)) for v in vector_dict.values()]\n",
    "candidate_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, 0, 0, 0),\n",
       " (0, 0, 0, 0, 1),\n",
       " (0, 0, 0, 0, 2),\n",
       " (0, 0, 0, 0, 3),\n",
       " (0, 0, 0, 0, 4),\n",
       " (0, 0, 0, 1, 0),\n",
       " (0, 0, 0, 1, 1),\n",
       " (0, 0, 0, 1, 2),\n",
       " (0, 0, 0, 1, 3),\n",
       " (0, 0, 0, 1, 4)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_combinations_idx = list(product(*candidate_counts))\n",
    "unique_combinations_idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Translate unique combination indexes into list of vector combinations\n",
    "unique_combinations = []\n",
    "for combo in unique_combinations_idx:\n",
    "#     print(combo)\n",
    "    combo_vector = []\n",
    "    for i in range(len(combo)):\n",
    "        combo_vector.append(vector_dict[i][combo[i]])\n",
    "    unique_combinations.append(combo_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate centroids for each unique combination\n",
    "centroids = []\n",
    "for combo in unique_combinations:\n",
    "    centroids.append(sum(combo)) #/len(combo)) if you want mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.131043  , -0.03438118,  2.4980736 , -0.7308637 , -1.1257738 ,\n",
       "       -0.49353868,  1.0083045 , -1.0838606 ,  0.75853443, -5.91596   ,\n",
       "        0.47778386, -1.3803507 ,  2.8838859 , -5.77764   , -1.5809379 ,\n",
       "       -0.7298596 ,  2.0230465 , -0.5698778 ,  1.3996718 , -0.73016936,\n",
       "       -1.5379165 ,  2.231394  , -1.0941744 , -1.3733233 , -2.2880337 ,\n",
       "        1.8583322 ,  2.8878713 , -1.3950173 ,  0.5865395 ,  0.8182961 ,\n",
       "       -0.37736836, -0.1751889 ,  3.4341693 ,  2.48418   ,  1.6804861 ,\n",
       "        0.1854988 ,  1.6437321 ,  1.0341145 ,  0.44050485, -1.1708148 ,\n",
       "        0.7957667 , -1.3546429 ,  0.38562632,  3.6486506 , -0.76347744,\n",
       "       -1.1840131 , -0.9945575 ,  3.122835  , -2.0672047 , -2.3407288 ,\n",
       "        2.0564058 ,  1.6348517 ,  1.4340049 , -2.695025  ,  0.19447258,\n",
       "        0.7308686 ,  2.818136  ,  1.1672243 , -2.6244626 ,  1.1208712 ,\n",
       "        2.4334676 ,  0.36272705, -1.8655688 ,  1.482802  ,  5.2873936 ,\n",
       "       -1.9874624 , -2.7909927 ,  1.2789898 , -2.3831098 , -3.9685295 ,\n",
       "       -1.3055067 ,  0.16041306, -1.5204049 ,  2.215236  , -2.1311655 ,\n",
       "        0.15059692,  1.4126135 , -0.85459715,  0.441755  , -0.65415514,\n",
       "        0.3865388 , -2.1975203 ,  1.040261  , -1.7043724 ,  1.3146981 ,\n",
       "        0.51544535,  1.6908295 , -0.04856205,  1.2496967 , -2.8507175 ,\n",
       "       -3.2187786 , -1.3497958 ,  0.36218208, -1.3739964 ,  1.1698556 ,\n",
       "       -2.0754268 ,  0.50031245,  1.8875923 , -0.58603346, -1.5836864 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each position should now have one\n",
    "centroids[0]              # Leave as is for sum of vectors\n",
    "# np.array(centroids[0])/5  # Divide by mention count for mean of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm we have a centroid for every set\n",
    "assert len(unique_combinations) == len(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity as distance between each candidate and that set's centroid\n",
    "set_distances = []\n",
    "for i in range(len(unique_combinations)):\n",
    "    candidate_distances = []\n",
    "    combination = unique_combinations[i]\n",
    "    centroid = centroids[i]\n",
    "    for candidate in combination:\n",
    "        \n",
    "        # todo which should I be using?\n",
    "        candidate_distance = cosine_similarity(candidate.reshape(-1, 1), centroid.reshape(-1, 1))\n",
    "#         candidate_distance = pairwise.pairwise_distances(candidate.reshape(-1, 1), centroid.reshape(-1, 1), metric='cosine')\n",
    "\n",
    "        candidate_distances.append(candidate_distance)\n",
    "    set_distances.append(candidate_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-1.,  1., -1., ..., -1.,  1.,  1.],\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        ...,\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        [-1.,  1., -1., ..., -1.,  1.,  1.],\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.]], dtype=float32),\n",
       " array([[ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        [-1.,  1., -1., ..., -1.,  1.,  1.],\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        ...,\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        [-1.,  1., -1., ..., -1.,  1.,  1.],\n",
       "        [-1.,  1., -1., ..., -1.,  1.,  1.]], dtype=float32),\n",
       " array([[ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        [-1.,  1., -1., ..., -1.,  1.,  1.],\n",
       "        ...,\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        [-1.,  1., -1., ..., -1.,  1.,  1.]], dtype=float32),\n",
       " array([[ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        [-1.,  1., -1., ..., -1.,  1.,  1.],\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        ...,\n",
       "        [-1.,  1., -1., ..., -1.,  1.,  1.],\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.]], dtype=float32),\n",
       " array([[ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        [-1.,  1., -1., ..., -1.,  1.,  1.],\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        ...,\n",
       "        [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "        [-1.,  1., -1., ..., -1.,  1.,  1.],\n",
       "        [-1.,  1., -1., ..., -1.,  1.,  1.]], dtype=float32)]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_distances[0] # Example combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.,  1., -1., ..., -1.,  1.,  1.],\n",
       "       [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "       [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "       ...,\n",
       "       [ 1., -1.,  1., ...,  1., -1., -1.],\n",
       "       [-1.,  1., -1., ..., -1.,  1.,  1.],\n",
       "       [ 1., -1.,  1., ...,  1., -1., -1.]], dtype=float32)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_distances[0][0] # Example candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_set_distance = [np.mean(combo) for combo in set_distances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0176, -0.00528)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(average_set_distance), min(average_set_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_idx = np.argmin(average_set_distance)\n",
    "select_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3, 3, 0, 0)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_congruent_predictions = unique_combinations_idx[select_idx]\n",
    "most_congruent_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 3, 2: 3, 3: 0, 4: 0}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See what we got done\n",
    "mention_predictions = {}\n",
    "for i in range(len(most_congruent_predictions)):\n",
    "    mention_predictions[i] = most_congruent_predictions[i]\n",
    "mention_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mention', 'full_mention', 'wikipedia_URL', 'wikipedia_page_ID',\n",
       "       'wikipedia_title', 'sentence_id', 'doc_id', 'congruent_mentions',\n",
       "       'norm_full_mention', 'candidate_pool_page_ids',\n",
       "       'candidate_pool_item_ids', 'candidate_pool_titles',\n",
       "       'candidate_pool_likelihoods'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_predictions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Peter Blackburn - True: nan, nan ==? Pred: Peter_Blackburn_(badminton),56783206\n",
      "Text: BRUSSELS - True: Brussels, 3708.0 ==? Pred: Brussels_Airport,269753\n",
      "Text: European Commission - True: European Commission, 9974.0 ==? Pred: European_Commissioner_for_Competition,1549462\n",
      "Text: German - True: Germany, 11867.0 ==? Pred: Germany,11867\n",
      "Text: British - True: United Kingdom, 31717.0 ==? Pred: United_Kingdom,31717\n",
      "*********************************************\n",
      "We predicted 40.0% mentions correctly.\n",
      "The correct answer was present in 80.0% candidate pools.\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = 0\n",
    "answer_present = 0\n",
    "\n",
    "for i in range(len(sentence_predictions)):\n",
    "    row = sentence_predictions.iloc[i]\n",
    "    full_mention = row['full_mention']\n",
    "    wiki_title = row['wikipedia_title']\n",
    "    wiki_page_id = row['wikipedia_page_ID']\n",
    "    candidate_pool_titles = row['candidate_pool_titles']\n",
    "    candidate_pool_page_ids = row['candidate_pool_page_ids']\n",
    "    pred_idx = mention_predictions[i]\n",
    "    pred_title = candidate_pool_titles[pred_idx]\n",
    "    pred_page_id = candidate_pool_page_ids[pred_idx]\n",
    "    print(f\"Text: {full_mention} - True: {wiki_title}, {wiki_page_id} ==? Pred: {pred_title},{pred_page_id}\")\n",
    "    if wiki_page_id == pred_page_id:\n",
    "        correct_predictions += 1\n",
    "    if wiki_page_id in candidate_pool_page_ids:\n",
    "        answer_present += 1\n",
    "\n",
    "print(\"*********************************************\")\n",
    "print(f\"We predicted {round(correct_predictions/len(sentence_predictions)*100,2)}% mentions correctly.\")\n",
    "print(f\"The correct answer was present in {round(answer_present/len(sentence_predictions)*100,2)}% candidate pools.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You've predicted everything!\n"
     ]
    }
   ],
   "source": [
    "print(\"You've predicted everything!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
